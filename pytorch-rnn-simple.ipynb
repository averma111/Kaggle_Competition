{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/averma111/pytorch-rnn-simple?scriptVersionId=129450774\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"import torch\nimport numpy as np\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-13T23:46:38.658976Z","iopub.execute_input":"2023-05-13T23:46:38.660033Z","iopub.status.idle":"2023-05-13T23:46:38.666051Z","shell.execute_reply.started":"2023-05-13T23:46:38.659988Z","shell.execute_reply":"2023-05-13T23:46:38.663892Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"text = ['hey how are you','good i am fine','have a nice day']\nchars = set(''.join(text))\nint2chars = dict(enumerate(chars))\nchar2ints = {char: ind for ind, char in int2chars.items()}","metadata":{"execution":{"iopub.status.busy":"2023-05-13T23:48:56.196629Z","iopub.execute_input":"2023-05-13T23:48:56.197142Z","iopub.status.idle":"2023-05-13T23:48:56.204476Z","shell.execute_reply.started":"2023-05-13T23:48:56.197082Z","shell.execute_reply":"2023-05-13T23:48:56.203054Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"maxlen = len(max(text, key=len))\n\nfor i in range(len(text)):\n    while len(text[i])<maxlen:\n        text[i] += ' '","metadata":{"execution":{"iopub.status.busy":"2023-05-13T23:50:48.055581Z","iopub.execute_input":"2023-05-13T23:50:48.055988Z","iopub.status.idle":"2023-05-13T23:50:48.062452Z","shell.execute_reply.started":"2023-05-13T23:50:48.05595Z","shell.execute_reply":"2023-05-13T23:50:48.061194Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"input_seq = []\ntarget_seq = []\nfor i in range(len(text)):\n    # Remove last character for input sequence\n    input_seq.append(text[i][:-1])\n    target_seq.append(text[i][1:])\nprint(\"Input Sequence: {}\\nTarget Sequence: {}\".format(input_seq[i], target_seq[i]))","metadata":{"execution":{"iopub.status.busy":"2023-05-13T23:51:58.147249Z","iopub.execute_input":"2023-05-13T23:51:58.147703Z","iopub.status.idle":"2023-05-13T23:51:58.157398Z","shell.execute_reply.started":"2023-05-13T23:51:58.147673Z","shell.execute_reply":"2023-05-13T23:51:58.155588Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Input Sequence: have a nice da\nTarget Sequence: ave a nice day\n","output_type":"stream"}]},{"cell_type":"code","source":"for i in range(len(text)):\n    input_seq[i] = [char2ints[character] for character in input_seq[i]]\n    target_seq[i] = [char2ints[character] for character in target_seq[i]]","metadata":{"execution":{"iopub.status.busy":"2023-05-13T23:52:45.724718Z","iopub.execute_input":"2023-05-13T23:52:45.725202Z","iopub.status.idle":"2023-05-13T23:52:45.732606Z","shell.execute_reply.started":"2023-05-13T23:52:45.725162Z","shell.execute_reply":"2023-05-13T23:52:45.731287Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"dict_size = len(char2ints)\nseq_len = maxlen - 1\nbatch_size = len(text)","metadata":{"execution":{"iopub.status.busy":"2023-05-13T23:53:08.06446Z","iopub.execute_input":"2023-05-13T23:53:08.064862Z","iopub.status.idle":"2023-05-13T23:53:08.071456Z","shell.execute_reply.started":"2023-05-13T23:53:08.064831Z","shell.execute_reply":"2023-05-13T23:53:08.069935Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def one_hot_encode(sequence, dict_size, seq_len, batch_size):\n    # Creating a multi-dimensional array of zeros with the desired output shape\n    features = np.zeros((batch_size, seq_len, dict_size), dtype=np.float32)\n    \n    # Replacing the 0 at the relevant character index with a 1 to represent that character\n    for i in range(batch_size):\n        for u in range(seq_len):\n            features[i, u, sequence[i][u]] = 1\n    return features","metadata":{"execution":{"iopub.status.busy":"2023-05-13T23:53:34.335194Z","iopub.execute_input":"2023-05-13T23:53:34.336232Z","iopub.status.idle":"2023-05-13T23:53:34.343278Z","shell.execute_reply.started":"2023-05-13T23:53:34.336178Z","shell.execute_reply":"2023-05-13T23:53:34.341977Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# Input shape --> (Batch Size, Sequence Length, One-Hot Encoding Size)\ninput_seq = one_hot_encode(input_seq, dict_size, seq_len, batch_size)","metadata":{"execution":{"iopub.status.busy":"2023-05-13T23:53:47.296823Z","iopub.execute_input":"2023-05-13T23:53:47.297253Z","iopub.status.idle":"2023-05-13T23:53:47.303149Z","shell.execute_reply.started":"2023-05-13T23:53:47.297222Z","shell.execute_reply":"2023-05-13T23:53:47.301943Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"input_seq = torch.from_numpy(input_seq)\ntarget_seq = torch.Tensor(target_seq)","metadata":{"execution":{"iopub.status.busy":"2023-05-13T23:54:01.473259Z","iopub.execute_input":"2023-05-13T23:54:01.473726Z","iopub.status.idle":"2023-05-13T23:54:01.505438Z","shell.execute_reply.started":"2023-05-13T23:54:01.473691Z","shell.execute_reply":"2023-05-13T23:54:01.503734Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"is_cuda = torch.cuda.is_available()\n\nif is_cuda:\n    device = torch.device(\"cuda\")\n    print(\"GPU is available\")\nelse:\n    device = torch.device(\"cpu\")\n    print(\"GPU not available, CPU used\")","metadata":{"execution":{"iopub.status.busy":"2023-05-13T23:54:34.501277Z","iopub.execute_input":"2023-05-13T23:54:34.50171Z","iopub.status.idle":"2023-05-13T23:54:34.50979Z","shell.execute_reply.started":"2023-05-13T23:54:34.501677Z","shell.execute_reply":"2023-05-13T23:54:34.507827Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"GPU not available, CPU used\n","output_type":"stream"}]},{"cell_type":"code","source":"class RNNModel(torch.nn.Module):\n    def __init__(self, input_size, output_size, hidden_dim, n_layers):\n        super(RNNModel, self).__init__()\n\n        # Defining some parameters\n        self.hidden_dim = hidden_dim\n        self.n_layers = n_layers\n\n        #Defining the layers\n        # RNN Layer\n        self.rnn = torch.nn.RNN(input_size, hidden_dim, n_layers, batch_first=True)   \n        # Fully connected layer\n        self.fc = torch.nn.Linear(hidden_dim, output_size)\n    \n    def forward(self, x):\n        \n        batch_size = x.size(0)\n\n        # Initializing hidden state for first input using method defined below\n        hidden = self.init_hidden(batch_size)\n\n        # Passing in the input and hidden state into the model and obtaining outputs\n        out, hidden = self.rnn(x, hidden)\n        \n        # Reshaping the outputs such that it can be fit into the fully connected layer\n        out = out.contiguous().view(-1, self.hidden_dim)\n        out = self.fc(out)\n        \n        return out, hidden\n    \n    def init_hidden(self, batch_size):\n        # This method generates the first hidden state of zeros which we'll use in the forward pass\n        # We'll send the tensor holding the hidden state to the device we specified earlier as well\n        hidden = torch.zeros(self.n_layers, batch_size, self.hidden_dim)\n        return hidden","metadata":{"execution":{"iopub.status.busy":"2023-05-13T23:55:57.122478Z","iopub.execute_input":"2023-05-13T23:55:57.122886Z","iopub.status.idle":"2023-05-13T23:55:57.133629Z","shell.execute_reply.started":"2023-05-13T23:55:57.122843Z","shell.execute_reply":"2023-05-13T23:55:57.132329Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# Instantiate the model with hyperparameters\nmodel = RNNModel(input_size=dict_size, output_size=dict_size, hidden_dim=12, n_layers=1)\n# We'll also set the model to the device that we defined earlier (default is CPU)\nmodel.to(device)\n\n# Define hyperparameters\nn_epochs = 100\nlr=0.01\n\n# Define Loss, Optimizer\ncriterion = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=lr)","metadata":{"execution":{"iopub.status.busy":"2023-05-13T23:56:35.022444Z","iopub.execute_input":"2023-05-13T23:56:35.02286Z","iopub.status.idle":"2023-05-13T23:56:35.032131Z","shell.execute_reply.started":"2023-05-13T23:56:35.022827Z","shell.execute_reply":"2023-05-13T23:56:35.03046Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# Training Run\nfor epoch in range(1, n_epochs + 1):\n    optimizer.zero_grad() # Clears existing gradients from previous epoch\n    input_seq.to(device)\n    output, hidden = model(input_seq)\n    loss = criterion(output, target_seq.view(-1).long())\n    loss.backward() # Does backpropagation and calculates gradients\n    optimizer.step() # Updates the weights accordingly\n    \n    if epoch%10 == 0:\n        print('Epoch: {}/{}.............'.format(epoch, n_epochs), end=' ')\n        print(\"Loss: {:.4f}\".format(loss.item()))","metadata":{"execution":{"iopub.status.busy":"2023-05-13T23:56:59.432475Z","iopub.execute_input":"2023-05-13T23:56:59.433068Z","iopub.status.idle":"2023-05-13T23:56:59.796134Z","shell.execute_reply.started":"2023-05-13T23:56:59.433026Z","shell.execute_reply":"2023-05-13T23:56:59.79504Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"Epoch: 10/100............. Loss: 2.3822\nEpoch: 20/100............. Loss: 2.0276\nEpoch: 30/100............. Loss: 1.6269\nEpoch: 40/100............. Loss: 1.2749\nEpoch: 50/100............. Loss: 0.9537\nEpoch: 60/100............. Loss: 0.6746\nEpoch: 70/100............. Loss: 0.4613\nEpoch: 80/100............. Loss: 0.3155\nEpoch: 90/100............. Loss: 0.2249\nEpoch: 100/100............. Loss: 0.1702\n","output_type":"stream"}]},{"cell_type":"code","source":"# This function takes in the model and character as arguments and returns the next character prediction and hidden state\ndef predict(model, character):\n    # One-hot encoding our input to fit into the model\n    character = np.array([[char2ints[c] for c in character]])\n    character = one_hot_encode(character, dict_size, character.shape[1], 1)\n    character = torch.from_numpy(character)\n    character.to(device)\n    \n    out, hidden = model(character)\n\n    prob = torch.nn.functional.softmax(out[-1], dim=0).data\n    # Taking the class with the highest probability score from the output\n    char_ind = torch.max(prob, dim=0)[1].item()\n\n    return int2chars[char_ind], hidden","metadata":{"execution":{"iopub.status.busy":"2023-05-13T23:58:22.563475Z","iopub.execute_input":"2023-05-13T23:58:22.563991Z","iopub.status.idle":"2023-05-13T23:58:22.573143Z","shell.execute_reply.started":"2023-05-13T23:58:22.563947Z","shell.execute_reply":"2023-05-13T23:58:22.571883Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"# This function takes the desired output length and input characters as arguments, returning the produced sentence\ndef sample(model, out_len, start='hey'):\n    model.eval() # eval mode\n    start = start.lower()\n    # First off, run through the starting characters\n    chars = [ch for ch in start]\n    size = out_len - len(chars)\n    # Now pass in the previous characters and get a new one\n    for ii in range(size):\n        char, h = predict(model, chars)\n        chars.append(char)\n\n    return ''.join(chars)","metadata":{"execution":{"iopub.status.busy":"2023-05-13T23:58:24.004811Z","iopub.execute_input":"2023-05-13T23:58:24.005871Z","iopub.status.idle":"2023-05-13T23:58:24.014501Z","shell.execute_reply.started":"2023-05-13T23:58:24.005818Z","shell.execute_reply":"2023-05-13T23:58:24.013164Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"sample(model, 15, 'good')","metadata":{"execution":{"iopub.status.busy":"2023-05-13T23:58:24.782603Z","iopub.execute_input":"2023-05-13T23:58:24.783118Z","iopub.status.idle":"2023-05-13T23:58:24.803621Z","shell.execute_reply.started":"2023-05-13T23:58:24.783066Z","shell.execute_reply":"2023-05-13T23:58:24.802349Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"'good i am fine '"},"metadata":{}}]},{"cell_type":"code","source":"sample(model, 15, 'day')","metadata":{"execution":{"iopub.status.busy":"2023-05-13T23:58:39.132591Z","iopub.execute_input":"2023-05-13T23:58:39.133038Z","iopub.status.idle":"2023-05-13T23:58:39.148747Z","shell.execute_reply.started":"2023-05-13T23:58:39.133004Z","shell.execute_reply":"2023-05-13T23:58:39.147591Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"'day fine a nice'"},"metadata":{}}]},{"cell_type":"code","source":"sample(model, 15, 'hey')","metadata":{"execution":{"iopub.status.busy":"2023-05-13T23:58:58.75895Z","iopub.execute_input":"2023-05-13T23:58:58.759433Z","iopub.status.idle":"2023-05-13T23:58:58.77646Z","shell.execute_reply.started":"2023-05-13T23:58:58.759401Z","shell.execute_reply":"2023-05-13T23:58:58.775062Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"'hey how are you'"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}