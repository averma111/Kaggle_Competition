{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/averma111/pytorch-pss3e18-vanilla?scriptVersionId=135313736\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"\nimport random\nimport numpy as np \nimport pandas as pd \nimport os\nimport datetime\nimport seaborn as sns\nfrom tqdm.notebook import tqdm\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader,TensorDataset,random_split,SubsetRandomSampler, ConcatDataset\nfrom torch.nn import functional as F\n\n\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\nplt.style.use('fivethirtyeight')\nimport plotly.express as px\n\nimport warnings\nwarnings.filterwarnings('ignore')\nimport itertools","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-06-30T06:14:46.095905Z","iopub.execute_input":"2023-06-30T06:14:46.096731Z","iopub.status.idle":"2023-06-30T06:14:46.109553Z","shell.execute_reply.started":"2023-06-30T06:14:46.096665Z","shell.execute_reply":"2023-06-30T06:14:46.108284Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"for dirname, _, filenames in os.walk('/kaggle/input/'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"execution":{"iopub.status.busy":"2023-06-30T06:14:46.748631Z","iopub.execute_input":"2023-06-30T06:14:46.749112Z","iopub.status.idle":"2023-06-30T06:14:46.759358Z","shell.execute_reply.started":"2023-06-30T06:14:46.74907Z","shell.execute_reply":"2023-06-30T06:14:46.758067Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"/kaggle/input/playground-series-s3e18/sample_submission.csv\n/kaggle/input/playground-series-s3e18/train.csv\n/kaggle/input/playground-series-s3e18/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"class Datapreparation(object):\n    \n    def __init__(self,root_path):\n        self.root_path = root_path\n        \n    def get_dataframe(self,filename):\n        return pd.read_csv(os.path.join(self.root_path,filename))\n    \n    def summary(self,text, df):\n        summary = pd.DataFrame(df.dtypes, columns=['dtypes'])\n        summary['null'] = df.isnull().sum()\n        summary['unique'] = df.nunique()\n        summary['min'] = df.min()\n        summary['median'] = df.median()\n        summary['max'] = df.max()\n        summary['mean'] = df.mean()\n        summary['std'] = df.std()\n        summary['duplicate'] = df.duplicated().sum()\n        return summary\n    \n    \n    def random_split_data(self,X,y):\n        return train_test_split(X, y,test_size=0.20,random_state=42)\n\n \n    def standardization_data(self,X_data):\n        scaler = StandardScaler()\n        std_X_data = scaler.fit_transform(X_data)\n        return std_X_data\n    \n\n    \ndata = Datapreparation('/kaggle/input/playground-series-s3e18')\ntrain=data.get_dataframe('train.csv')","metadata":{"execution":{"iopub.status.busy":"2023-06-30T06:14:47.572105Z","iopub.execute_input":"2023-06-30T06:14:47.573062Z","iopub.status.idle":"2023-06-30T06:14:47.816329Z","shell.execute_reply.started":"2023-06-30T06:14:47.57302Z","shell.execute_reply":"2023-06-30T06:14:47.814978Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"data.summary('train',train)","metadata":{"execution":{"iopub.status.busy":"2023-06-30T06:14:48.33073Z","iopub.execute_input":"2023-06-30T06:14:48.33119Z","iopub.status.idle":"2023-06-30T06:14:48.464058Z","shell.execute_reply.started":"2023-06-30T06:14:48.331155Z","shell.execute_reply":"2023-06-30T06:14:48.462783Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                    dtypes  null  unique         min       median  \\\nid                   int64     0   14838    0.000000  7418.500000   \nBertzCT            float64     0    2368    0.000000   290.987941   \nChi1               float64     0    1259    0.000000     6.485270   \nChi1n              float64     0    3157    0.000000     4.052701   \nChi1v              float64     0    3306    0.000000     4.392859   \nChi2n              float64     0    3634    0.000000     2.970427   \nChi2v              float64     0    3725    0.000000     3.242775   \nChi3v              float64     0    3448    0.000000     1.948613   \nChi4n              float64     0    2930    0.000000     1.073261   \nEState_VSA1        float64     0     719    0.000000    17.353601   \nEState_VSA2        float64     0     445    0.000000     6.420822   \nExactMolWt         float64     0    1666    1.007276   206.042653   \nFpDensityMorgan1   float64     0     556 -666.000000     1.250000   \nFpDensityMorgan2   float64     0     650 -666.000000     1.865152   \nFpDensityMorgan3   float64     0     654 -666.000000     2.358491   \nHallKierAlpha      float64     0     388   -7.730000    -1.100000   \nHeavyAtomMolWt     float64     0     860    0.000000   194.276500   \nKappa3             float64     0    2245 -104.040000     3.261011   \nMaxAbsEStateIndex  float64     0    2356    0.000000    10.421334   \nMinEStateIndex     float64     0    2142   -6.327514    -1.265370   \nNumHeteroatoms       int64     0      40    0.000000     6.000000   \nPEOE_VSA10         float64     0     250    0.000000     6.041841   \nPEOE_VSA14         float64     0     291    0.000000     5.969305   \nPEOE_VSA6          float64     0     219    0.000000     0.000000   \nPEOE_VSA7          float64     0     262    0.000000     0.000000   \nPEOE_VSA8          float64     0     237    0.000000     0.000000   \nSMR_VSA10          float64     0     409    0.000000    11.752550   \nSMR_VSA5           float64     0     492    0.000000    20.075376   \nSlogP_VSA3         float64     0     217    0.000000     9.589074   \nVSA_EState9        float64     0    1946   -5.430556    41.666667   \nfr_COO               int64     0       8    0.000000     0.000000   \nfr_COO2              int64     0       8    0.000000     0.000000   \nEC1                  int64     0       2    0.000000     1.000000   \nEC2                  int64     0       2    0.000000     1.000000   \nEC3                  int64     0       2    0.000000     0.000000   \nEC4                  int64     0       2    0.000000     0.000000   \nEC5                  int64     0       2    0.000000     0.000000   \nEC6                  int64     0       2    0.000000     0.000000   \n\n                            max         mean          std  duplicate  \nid                 14837.000000  7418.500000  4283.505982          0  \nBertzCT             4069.959780   515.153604   542.456370          0  \nChi1                  69.551167     9.135189     6.819989          0  \nChi1n                 50.174588     5.854307     4.647064          0  \nChi1v                 53.431954     6.738497     5.866444          0  \nChi2n                 32.195368     4.432570     3.760516          0  \nChi2v                 34.579313     5.253221     4.925065          0  \nChi3v                 22.880836     3.418749     3.436208          0  \nChi4n                 16.072810     1.773472     1.865898          0  \nEState_VSA1          363.705954    29.202823    31.728679          0  \nEState_VSA2           99.936429    10.435316    13.651843          0  \nExactMolWt          2237.318490   292.623087   225.384140          0  \nFpDensityMorgan1       3.000000     1.236774     5.491284          0  \nFpDensityMorgan2       3.200000     1.812070     5.495565          0  \nFpDensityMorgan3       3.400000     2.255470     5.501200          0  \nHallKierAlpha          0.820000    -1.207776     0.935314          0  \nHeavyAtomMolWt      2035.133000   274.950211   212.678755          0  \nKappa3              1512.242231     5.874372    45.730226          0  \nMaxAbsEStateIndex     15.630251    10.556443     1.559331          0  \nMinEStateIndex         6.000000    -2.119772     2.066415          0  \nNumHeteroatoms        42.000000     8.584108     7.643769          0  \nPEOE_VSA10            97.663462    11.021644    13.958962          0  \nPEOE_VSA14           482.434223    17.790011    34.561655          0  \nPEOE_VSA6            375.425148     8.962440    19.756727          0  \nPEOE_VSA7            211.501279    11.318811    20.169745          0  \nPEOE_VSA8            100.348416     6.704487    10.865415          0  \nSMR_VSA10             80.742293    15.666766    18.080208          0  \nSMR_VSA5             492.729739    31.066423    33.896638          0  \nSlogP_VSA3           115.406157    13.636941    14.598554          0  \nVSA_EState9          384.450519    49.309959    29.174824          0  \nfr_COO                 8.000000     0.458215     0.667948          0  \nfr_COO2                8.000000     0.459226     0.668111          0  \nEC1                    1.000000     0.667745     0.471038          0  \nEC2                    1.000000     0.798962     0.400790          0  \nEC3                    1.000000     0.313789     0.464047          0  \nEC4                    1.000000     0.279081     0.448562          0  \nEC5                    1.000000     0.144831     0.351942          0  \nEC6                    1.000000     0.151570     0.358616          0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dtypes</th>\n      <th>null</th>\n      <th>unique</th>\n      <th>min</th>\n      <th>median</th>\n      <th>max</th>\n      <th>mean</th>\n      <th>std</th>\n      <th>duplicate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>id</th>\n      <td>int64</td>\n      <td>0</td>\n      <td>14838</td>\n      <td>0.000000</td>\n      <td>7418.500000</td>\n      <td>14837.000000</td>\n      <td>7418.500000</td>\n      <td>4283.505982</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>BertzCT</th>\n      <td>float64</td>\n      <td>0</td>\n      <td>2368</td>\n      <td>0.000000</td>\n      <td>290.987941</td>\n      <td>4069.959780</td>\n      <td>515.153604</td>\n      <td>542.456370</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>Chi1</th>\n      <td>float64</td>\n      <td>0</td>\n      <td>1259</td>\n      <td>0.000000</td>\n      <td>6.485270</td>\n      <td>69.551167</td>\n      <td>9.135189</td>\n      <td>6.819989</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>Chi1n</th>\n      <td>float64</td>\n      <td>0</td>\n      <td>3157</td>\n      <td>0.000000</td>\n      <td>4.052701</td>\n      <td>50.174588</td>\n      <td>5.854307</td>\n      <td>4.647064</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>Chi1v</th>\n      <td>float64</td>\n      <td>0</td>\n      <td>3306</td>\n      <td>0.000000</td>\n      <td>4.392859</td>\n      <td>53.431954</td>\n      <td>6.738497</td>\n      <td>5.866444</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>Chi2n</th>\n      <td>float64</td>\n      <td>0</td>\n      <td>3634</td>\n      <td>0.000000</td>\n      <td>2.970427</td>\n      <td>32.195368</td>\n      <td>4.432570</td>\n      <td>3.760516</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>Chi2v</th>\n      <td>float64</td>\n      <td>0</td>\n      <td>3725</td>\n      <td>0.000000</td>\n      <td>3.242775</td>\n      <td>34.579313</td>\n      <td>5.253221</td>\n      <td>4.925065</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>Chi3v</th>\n      <td>float64</td>\n      <td>0</td>\n      <td>3448</td>\n      <td>0.000000</td>\n      <td>1.948613</td>\n      <td>22.880836</td>\n      <td>3.418749</td>\n      <td>3.436208</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>Chi4n</th>\n      <td>float64</td>\n      <td>0</td>\n      <td>2930</td>\n      <td>0.000000</td>\n      <td>1.073261</td>\n      <td>16.072810</td>\n      <td>1.773472</td>\n      <td>1.865898</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>EState_VSA1</th>\n      <td>float64</td>\n      <td>0</td>\n      <td>719</td>\n      <td>0.000000</td>\n      <td>17.353601</td>\n      <td>363.705954</td>\n      <td>29.202823</td>\n      <td>31.728679</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>EState_VSA2</th>\n      <td>float64</td>\n      <td>0</td>\n      <td>445</td>\n      <td>0.000000</td>\n      <td>6.420822</td>\n      <td>99.936429</td>\n      <td>10.435316</td>\n      <td>13.651843</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>ExactMolWt</th>\n      <td>float64</td>\n      <td>0</td>\n      <td>1666</td>\n      <td>1.007276</td>\n      <td>206.042653</td>\n      <td>2237.318490</td>\n      <td>292.623087</td>\n      <td>225.384140</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>FpDensityMorgan1</th>\n      <td>float64</td>\n      <td>0</td>\n      <td>556</td>\n      <td>-666.000000</td>\n      <td>1.250000</td>\n      <td>3.000000</td>\n      <td>1.236774</td>\n      <td>5.491284</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>FpDensityMorgan2</th>\n      <td>float64</td>\n      <td>0</td>\n      <td>650</td>\n      <td>-666.000000</td>\n      <td>1.865152</td>\n      <td>3.200000</td>\n      <td>1.812070</td>\n      <td>5.495565</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>FpDensityMorgan3</th>\n      <td>float64</td>\n      <td>0</td>\n      <td>654</td>\n      <td>-666.000000</td>\n      <td>2.358491</td>\n      <td>3.400000</td>\n      <td>2.255470</td>\n      <td>5.501200</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>HallKierAlpha</th>\n      <td>float64</td>\n      <td>0</td>\n      <td>388</td>\n      <td>-7.730000</td>\n      <td>-1.100000</td>\n      <td>0.820000</td>\n      <td>-1.207776</td>\n      <td>0.935314</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>HeavyAtomMolWt</th>\n      <td>float64</td>\n      <td>0</td>\n      <td>860</td>\n      <td>0.000000</td>\n      <td>194.276500</td>\n      <td>2035.133000</td>\n      <td>274.950211</td>\n      <td>212.678755</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>Kappa3</th>\n      <td>float64</td>\n      <td>0</td>\n      <td>2245</td>\n      <td>-104.040000</td>\n      <td>3.261011</td>\n      <td>1512.242231</td>\n      <td>5.874372</td>\n      <td>45.730226</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>MaxAbsEStateIndex</th>\n      <td>float64</td>\n      <td>0</td>\n      <td>2356</td>\n      <td>0.000000</td>\n      <td>10.421334</td>\n      <td>15.630251</td>\n      <td>10.556443</td>\n      <td>1.559331</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>MinEStateIndex</th>\n      <td>float64</td>\n      <td>0</td>\n      <td>2142</td>\n      <td>-6.327514</td>\n      <td>-1.265370</td>\n      <td>6.000000</td>\n      <td>-2.119772</td>\n      <td>2.066415</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>NumHeteroatoms</th>\n      <td>int64</td>\n      <td>0</td>\n      <td>40</td>\n      <td>0.000000</td>\n      <td>6.000000</td>\n      <td>42.000000</td>\n      <td>8.584108</td>\n      <td>7.643769</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>PEOE_VSA10</th>\n      <td>float64</td>\n      <td>0</td>\n      <td>250</td>\n      <td>0.000000</td>\n      <td>6.041841</td>\n      <td>97.663462</td>\n      <td>11.021644</td>\n      <td>13.958962</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>PEOE_VSA14</th>\n      <td>float64</td>\n      <td>0</td>\n      <td>291</td>\n      <td>0.000000</td>\n      <td>5.969305</td>\n      <td>482.434223</td>\n      <td>17.790011</td>\n      <td>34.561655</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>PEOE_VSA6</th>\n      <td>float64</td>\n      <td>0</td>\n      <td>219</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>375.425148</td>\n      <td>8.962440</td>\n      <td>19.756727</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>PEOE_VSA7</th>\n      <td>float64</td>\n      <td>0</td>\n      <td>262</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>211.501279</td>\n      <td>11.318811</td>\n      <td>20.169745</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>PEOE_VSA8</th>\n      <td>float64</td>\n      <td>0</td>\n      <td>237</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>100.348416</td>\n      <td>6.704487</td>\n      <td>10.865415</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>SMR_VSA10</th>\n      <td>float64</td>\n      <td>0</td>\n      <td>409</td>\n      <td>0.000000</td>\n      <td>11.752550</td>\n      <td>80.742293</td>\n      <td>15.666766</td>\n      <td>18.080208</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>SMR_VSA5</th>\n      <td>float64</td>\n      <td>0</td>\n      <td>492</td>\n      <td>0.000000</td>\n      <td>20.075376</td>\n      <td>492.729739</td>\n      <td>31.066423</td>\n      <td>33.896638</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>SlogP_VSA3</th>\n      <td>float64</td>\n      <td>0</td>\n      <td>217</td>\n      <td>0.000000</td>\n      <td>9.589074</td>\n      <td>115.406157</td>\n      <td>13.636941</td>\n      <td>14.598554</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>VSA_EState9</th>\n      <td>float64</td>\n      <td>0</td>\n      <td>1946</td>\n      <td>-5.430556</td>\n      <td>41.666667</td>\n      <td>384.450519</td>\n      <td>49.309959</td>\n      <td>29.174824</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>fr_COO</th>\n      <td>int64</td>\n      <td>0</td>\n      <td>8</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>8.000000</td>\n      <td>0.458215</td>\n      <td>0.667948</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>fr_COO2</th>\n      <td>int64</td>\n      <td>0</td>\n      <td>8</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>8.000000</td>\n      <td>0.459226</td>\n      <td>0.668111</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>EC1</th>\n      <td>int64</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.667745</td>\n      <td>0.471038</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>EC2</th>\n      <td>int64</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.798962</td>\n      <td>0.400790</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>EC3</th>\n      <td>int64</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.313789</td>\n      <td>0.464047</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>EC4</th>\n      <td>int64</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.279081</td>\n      <td>0.448562</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>EC5</th>\n      <td>int64</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.144831</td>\n      <td>0.351942</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>EC6</th>\n      <td>int64</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.151570</td>\n      <td>0.358616</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"y1 = train['EC1']\ny2 = train['EC2']\ntrain.drop(columns=['id','EC1','EC2','EC3','EC4','EC5','EC6'],axis=1,inplace=True)\nX = train.copy()","metadata":{"execution":{"iopub.status.busy":"2023-06-30T06:14:49.163668Z","iopub.execute_input":"2023-06-30T06:14:49.16481Z","iopub.status.idle":"2023-06-30T06:14:49.17937Z","shell.execute_reply.started":"2023-06-30T06:14:49.164744Z","shell.execute_reply":"2023-06-30T06:14:49.178017Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"X_train,X_val,y1_train,y1_val = data.random_split_data(X,y1)\nprint('Data splits for EC1 \\n',X_train.shape,X_val.shape,y1_train.shape,y1_val.shape)","metadata":{"execution":{"iopub.status.busy":"2023-06-30T06:14:50.195761Z","iopub.execute_input":"2023-06-30T06:14:50.196156Z","iopub.status.idle":"2023-06-30T06:14:50.211102Z","shell.execute_reply.started":"2023-06-30T06:14:50.196127Z","shell.execute_reply":"2023-06-30T06:14:50.209827Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Data splits for EC1 \n (11870, 31) (2968, 31) (11870,) (2968,)\n","output_type":"stream"}]},{"cell_type":"code","source":"X_train,X_val,y2_train,y2_val = data.random_split_data(X,y2)\nprint('Data splits for EC2 \\n',X_train.shape,X_val.shape,y2_train.shape,y2_val.shape)","metadata":{"execution":{"iopub.status.busy":"2023-06-30T06:14:51.734125Z","iopub.execute_input":"2023-06-30T06:14:51.734584Z","iopub.status.idle":"2023-06-30T06:14:51.749999Z","shell.execute_reply.started":"2023-06-30T06:14:51.734543Z","shell.execute_reply":"2023-06-30T06:14:51.748775Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Data splits for EC2 \n (11870, 31) (2968, 31) (11870,) (2968,)\n","output_type":"stream"}]},{"cell_type":"code","source":"std_X_train = data.standardization_data(X_train)\nstd_X_val = data.standardization_data(X_val)\nprint(std_X_train[0],std_X_val[0])","metadata":{"execution":{"iopub.status.busy":"2023-06-30T06:14:53.118825Z","iopub.execute_input":"2023-06-30T06:14:53.119256Z","iopub.status.idle":"2023-06-30T06:14:53.149018Z","shell.execute_reply.started":"2023-06-30T06:14:53.119225Z","shell.execute_reply":"2023-06-30T06:14:53.147797Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"[-0.6460012  -0.49660398 -0.53250602 -0.57261284 -0.5904852  -0.61753263\n -0.59673579 -0.62771573 -0.91411097  0.56344636 -0.56889535 -0.07305243\n  0.81469479  1.50215144  0.0217275  -0.57591696 -0.08736038 -0.39329628\n  1.34611003 -0.72802128 -0.78622974 -0.51646882  0.1563295   0.31295018\n -0.61487415 -0.5171512  -0.91283104 -0.93428166 -0.94969081 -0.68328343\n -0.68460195] [-0.73157789 -0.89416128 -0.71611727 -0.71782103 -0.74457679 -0.73521665\n -0.8362178  -0.84437652 -0.385045   -0.76779355 -0.74586676  0.06227215\n  0.02884275  0.07397899  0.41849986 -0.75437549 -0.10510849 -0.80384358\n  0.35858918 -0.61099998 -0.3717161  -0.33573224 -0.47165217 -0.56987761\n -0.62586121 -0.22583258 -0.54067893 -0.28699515 -0.54836477  0.78492852\n  0.78337988]\n","output_type":"stream"}]},{"cell_type":"code","source":"class Tensoroperations():\n    \n    def __init__(self):\n        super(Tensoroperations,self).__init__()\n    \n    def convert_to_tensor(self,X,y=None):\n        X_tensor =  torch.from_numpy(X).float()   \n        y_tensor = torch.from_numpy(y).float() \n        return X_tensor,y_tensor\n        \n    def convert_to_test_tesnor(self,X):\n        X_tensor =  torch.from_numpy(X).float()\n        return X_tensor\n    \n    def get_dataloaders(self,train_dataset,val_dataset):\n        train_loaders = DataLoader(train_dataset,batch_size=32,shuffle=True)\n        val_loaders = DataLoader(val_dataset,batch_size=32)\n        return train_loaders,val_loaders\n    \n    def get_test_dataloaders(self,test_dataset,X_test):\n        test_loaders = DataLoader(test_dataset,batch_size=X_test.shape[0])\n        return test_loaders\n        \n        \n    \ntenops = Tensoroperations()","metadata":{"execution":{"iopub.status.busy":"2023-06-30T06:14:54.129166Z","iopub.execute_input":"2023-06-30T06:14:54.129557Z","iopub.status.idle":"2023-06-30T06:14:54.13865Z","shell.execute_reply.started":"2023-06-30T06:14:54.129526Z","shell.execute_reply":"2023-06-30T06:14:54.137781Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    \n    def __init__(self,X_data,y_data=None,is_train=True):\n        super().__init__()\n        if is_train:\n            self.X_data = X_data\n            self.y_data = y_data\n        else:\n            self.X_data=X_train\n            \n    def __getitem__(self,index):\n        return (self.X_data[index],self.y_data[index])\n    \n    def __len__(self):\n        return len(self.X_data)","metadata":{"execution":{"iopub.status.busy":"2023-06-30T06:14:55.616545Z","iopub.execute_input":"2023-06-30T06:14:55.617142Z","iopub.status.idle":"2023-06-30T06:14:55.625528Z","shell.execute_reply.started":"2023-06-30T06:14:55.617097Z","shell.execute_reply":"2023-06-30T06:14:55.62421Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"X_tensor_train,y1_tensor_train = tenops.convert_to_tensor(std_X_train,y1_train.values)\nX_tensor_val,y1_tensor_val = tenops.convert_to_tensor(std_X_val,y1_val.values)\nprint('The training tensor for EC1\\n',X_tensor_train,y1_tensor_train)\nprint('The validation tensor for EC1\\n',X_tensor_val,y1_tensor_val)","metadata":{"execution":{"iopub.status.busy":"2023-06-30T06:15:06.639276Z","iopub.execute_input":"2023-06-30T06:15:06.639777Z","iopub.status.idle":"2023-06-30T06:15:06.766771Z","shell.execute_reply.started":"2023-06-30T06:15:06.639728Z","shell.execute_reply":"2023-06-30T06:15:06.765322Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"The training tensor for EC1\n tensor([[-0.6460, -0.4966, -0.5325,  ..., -0.9497, -0.6833, -0.6846],\n        [-0.7818, -0.9513, -0.8922,  ..., -1.0127,  0.8178,  0.8161],\n        [ 2.1245,  1.5223,  1.7448,  ...,  2.0297, -0.6833, -0.6846],\n        ...,\n        [-0.2776,  0.0232, -0.3406,  ..., -0.6133, -0.6833, -0.6846],\n        [-0.7166, -0.6467, -0.5530,  ..., -0.6577, -0.6833, -0.6846],\n        [-0.8225, -0.8068, -0.8795,  ..., -0.8180, -0.6833, -0.6846]]) tensor([1., 1., 1.,  ..., 0., 0., 1.])\nThe validation tensor for EC1\n tensor([[-0.7316, -0.8942, -0.7161,  ..., -0.5484,  0.7849,  0.7834],\n        [-0.2605,  0.2136,  0.2536,  ..., -0.2027, -0.6970, -0.6985],\n        [-0.4432, -1.0872, -1.1129,  ..., -0.1914,  2.2669,  2.2653],\n        ...,\n        [-0.6615, -0.6798, -0.6762,  ..., -0.3160,  0.7849,  0.7834],\n        [ 0.7218,  0.9378,  0.8351,  ...,  0.2456, -0.6970, -0.6985],\n        [-0.8259, -0.8942, -0.8957,  ..., -0.9963, -0.6970, -0.6985]]) tensor([1., 0., 1.,  ..., 1., 0., 1.])\n","output_type":"stream"}]},{"cell_type":"code","source":"X_tensor_train,y2_tensor_train = tenops.convert_to_tensor(std_X_train,y2_train.values)\nX_tensor_val,y2_tensor_val = tenops.convert_to_tensor(std_X_val,y2_val.values)\nprint('The training tensor EC2\\n',X_tensor_train,y2_tensor_train)\nprint('The validation tensor Ec2\\n',X_tensor_val,y2_tensor_val)","metadata":{"execution":{"iopub.status.busy":"2023-06-30T06:15:07.476542Z","iopub.execute_input":"2023-06-30T06:15:07.477374Z","iopub.status.idle":"2023-06-30T06:15:07.492548Z","shell.execute_reply.started":"2023-06-30T06:15:07.477324Z","shell.execute_reply":"2023-06-30T06:15:07.490821Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"The training tensor EC2\n tensor([[-0.6460, -0.4966, -0.5325,  ..., -0.9497, -0.6833, -0.6846],\n        [-0.7818, -0.9513, -0.8922,  ..., -1.0127,  0.8178,  0.8161],\n        [ 2.1245,  1.5223,  1.7448,  ...,  2.0297, -0.6833, -0.6846],\n        ...,\n        [-0.2776,  0.0232, -0.3406,  ..., -0.6133, -0.6833, -0.6846],\n        [-0.7166, -0.6467, -0.5530,  ..., -0.6577, -0.6833, -0.6846],\n        [-0.8225, -0.8068, -0.8795,  ..., -0.8180, -0.6833, -0.6846]]) tensor([1., 1., 0.,  ..., 1., 1., 1.])\nThe validation tensor Ec2\n tensor([[-0.7316, -0.8942, -0.7161,  ..., -0.5484,  0.7849,  0.7834],\n        [-0.2605,  0.2136,  0.2536,  ..., -0.2027, -0.6970, -0.6985],\n        [-0.4432, -1.0872, -1.1129,  ..., -0.1914,  2.2669,  2.2653],\n        ...,\n        [-0.6615, -0.6798, -0.6762,  ..., -0.3160,  0.7849,  0.7834],\n        [ 0.7218,  0.9378,  0.8351,  ...,  0.2456, -0.6970, -0.6985],\n        [-0.8259, -0.8942, -0.8957,  ..., -0.9963, -0.6970, -0.6985]]) tensor([1., 1., 1.,  ..., 1., 1., 1.])\n","output_type":"stream"}]},{"cell_type":"code","source":"n_input_dim = X_train.shape[1]\n#Layer size\nn_hidden1 = 4  # Number of hidden nodes\nn_hidden2 = 2\nn_output =  1   # Number of output nodes = for binary classifier\n\nclass MultiClassificationNN(torch.nn.Module):\n    \n    def __init__(self):\n        super(MultiClassificationNN, self).__init__()\n        self.layer_1 = torch.nn.Linear(n_input_dim, n_hidden1) \n        self.layer_2 = torch.nn.Linear(n_hidden1, n_hidden2)\n        self.layer_out = torch.nn.Linear(n_hidden2, n_output) \n        \n        \n        self.relu = torch.nn.ReLU()\n        self.sigmoid =  torch.nn.Sigmoid()\n        self.dropout = torch.nn.Dropout(p=0.1)\n        self.batchnorm1 = torch.nn.BatchNorm1d(n_hidden1)\n        self.batchnorm2 = torch.nn.BatchNorm1d(n_hidden2)\n        \n        \n    def forward(self, inputs):\n        x = self.relu(self.layer_1(inputs))\n        x = self.batchnorm1(x)\n        x = self.relu(self.layer_2(x))\n        x = self.batchnorm2(x)\n        x = self.dropout(x)\n        x = self.sigmoid(self.layer_out(x))\n        \n        return x\n    \n\n\nmodel_EC1 = MultiClassificationNN()\nmodel_EC2 = MultiClassificationNN()\nprint(model_EC1.state_dict())\nprint(model_EC2.state_dict())","metadata":{"execution":{"iopub.status.busy":"2023-06-30T06:15:12.687884Z","iopub.execute_input":"2023-06-30T06:15:12.689222Z","iopub.status.idle":"2023-06-30T06:15:12.716876Z","shell.execute_reply.started":"2023-06-30T06:15:12.689161Z","shell.execute_reply":"2023-06-30T06:15:12.715214Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"OrderedDict([('layer_1.weight', tensor([[ 8.2011e-02,  3.2315e-02,  1.9249e-02, -7.8593e-02, -3.6137e-03,\n         -5.9090e-02, -3.2268e-02,  6.5100e-02, -3.0669e-03,  4.5142e-02,\n          1.1615e-01, -4.7788e-02,  1.7272e-01,  5.3252e-02, -3.8916e-02,\n         -1.1752e-01, -1.7290e-01, -1.4131e-01, -2.9494e-02,  1.0121e-01,\n          4.2926e-02,  1.0384e-01,  1.6157e-01,  9.7131e-02, -5.1818e-02,\n         -1.5843e-01,  1.0194e-01,  5.6426e-02,  8.9926e-02,  1.4215e-01,\n         -1.0575e-01],\n        [ 8.4963e-02,  4.6338e-02, -1.7249e-01,  2.7926e-04, -4.2624e-02,\n          5.5870e-02, -8.9300e-03, -1.2896e-01, -6.3465e-02, -1.7108e-01,\n         -1.5602e-01,  9.5728e-02,  1.2824e-01, -1.3064e-01,  6.4507e-02,\n          1.1303e-01, -1.7458e-01, -8.0593e-02,  1.3945e-01, -9.6799e-02,\n         -1.5888e-01, -1.6409e-01, -6.4219e-02, -1.0038e-01,  1.2313e-01,\n          1.6725e-01,  9.2550e-02,  9.2971e-02,  1.0378e-01,  6.3568e-02,\n          1.2819e-02],\n        [ 1.2571e-01, -1.4418e-01,  1.5857e-01,  1.6802e-01, -1.4895e-01,\n         -1.5239e-01,  3.0709e-02,  8.8685e-02, -8.9553e-02,  1.6588e-01,\n          5.9854e-02,  2.3514e-02,  2.5593e-02,  1.5866e-01,  1.2406e-01,\n          1.6440e-01, -4.3132e-02, -9.3490e-02, -1.0889e-01, -4.2114e-02,\n          1.0450e-01,  1.0912e-01, -1.2962e-02, -1.4313e-01, -2.2862e-02,\n         -4.9109e-02, -5.6241e-02, -9.7522e-02,  4.8829e-04,  1.2126e-02,\n          3.7424e-02],\n        [ 4.4759e-02,  1.1335e-01,  3.1032e-02,  1.0803e-01,  9.5201e-02,\n         -1.5326e-01, -8.4634e-03, -1.3122e-01, -4.5197e-02, -5.3345e-02,\n         -1.1542e-01,  1.4042e-01, -1.1119e-01,  6.6336e-02,  1.8568e-02,\n          8.2496e-02,  7.1615e-02, -9.0689e-02, -2.0309e-02, -1.5600e-01,\n          7.5771e-02,  1.3009e-01, -4.7729e-02,  1.0699e-01, -6.1962e-05,\n          6.1167e-02, -1.6547e-01, -1.6537e-01, -6.8598e-03,  1.4440e-01,\n          2.5187e-02]])), ('layer_1.bias', tensor([ 0.1369, -0.0450,  0.0710,  0.1112])), ('layer_2.weight', tensor([[ 0.3887, -0.3524, -0.4854,  0.1920],\n        [ 0.3230, -0.3526, -0.3939,  0.4471]])), ('layer_2.bias', tensor([-0.1136, -0.2672])), ('layer_out.weight', tensor([[0.5726, 0.2441]])), ('layer_out.bias', tensor([0.0805])), ('batchnorm1.weight', tensor([1., 1., 1., 1.])), ('batchnorm1.bias', tensor([0., 0., 0., 0.])), ('batchnorm1.running_mean', tensor([0., 0., 0., 0.])), ('batchnorm1.running_var', tensor([1., 1., 1., 1.])), ('batchnorm1.num_batches_tracked', tensor(0)), ('batchnorm2.weight', tensor([1., 1.])), ('batchnorm2.bias', tensor([0., 0.])), ('batchnorm2.running_mean', tensor([0., 0.])), ('batchnorm2.running_var', tensor([1., 1.])), ('batchnorm2.num_batches_tracked', tensor(0))])\nOrderedDict([('layer_1.weight', tensor([[-0.1077,  0.0366, -0.0226,  0.0215,  0.1541, -0.0084, -0.1194, -0.1371,\n         -0.0410, -0.1177,  0.0602, -0.0834,  0.1705, -0.0744, -0.1571, -0.0724,\n         -0.0459,  0.0130,  0.0455, -0.0627, -0.1259, -0.0038,  0.1789,  0.1415,\n         -0.0269, -0.0893,  0.0727, -0.1628, -0.0802,  0.1413,  0.1374],\n        [ 0.0946, -0.0030,  0.1137,  0.0548,  0.1433,  0.0943,  0.1358, -0.1399,\n         -0.0143, -0.1087,  0.0663,  0.0776, -0.1718, -0.1284,  0.0874,  0.0557,\n          0.1488,  0.1366, -0.0641,  0.1390,  0.0281, -0.0363,  0.0308, -0.1716,\n         -0.1634,  0.1218,  0.1632,  0.0157, -0.1302, -0.1784,  0.0106],\n        [ 0.0846,  0.0677,  0.1062, -0.1009, -0.0107,  0.1381, -0.0299, -0.0711,\n          0.0029,  0.0846, -0.1398,  0.1313, -0.0356,  0.1308,  0.1112, -0.0280,\n         -0.0317,  0.0441,  0.0884,  0.1127,  0.1428, -0.0958, -0.0871,  0.1507,\n          0.0516,  0.0056,  0.1056,  0.0708, -0.0231,  0.1310,  0.0500],\n        [ 0.0786, -0.1751,  0.1635, -0.0597,  0.0509,  0.0102,  0.0415,  0.1523,\n          0.1424, -0.0053, -0.1170,  0.1243,  0.0029,  0.0578, -0.0910, -0.0904,\n         -0.0430, -0.0810,  0.0782,  0.0456,  0.1166, -0.1697,  0.1713, -0.1057,\n          0.0681,  0.0314,  0.1734,  0.1368, -0.0861, -0.1331, -0.1111]])), ('layer_1.bias', tensor([-0.0395, -0.1004,  0.1063,  0.0779])), ('layer_2.weight', tensor([[-0.3964,  0.1699,  0.1323,  0.0331],\n        [ 0.2875,  0.4658,  0.2529,  0.3710]])), ('layer_2.bias', tensor([0.2659, 0.4291])), ('layer_out.weight', tensor([[-0.5118,  0.6109]])), ('layer_out.bias', tensor([0.5266])), ('batchnorm1.weight', tensor([1., 1., 1., 1.])), ('batchnorm1.bias', tensor([0., 0., 0., 0.])), ('batchnorm1.running_mean', tensor([0., 0., 0., 0.])), ('batchnorm1.running_var', tensor([1., 1., 1., 1.])), ('batchnorm1.num_batches_tracked', tensor(0)), ('batchnorm2.weight', tensor([1., 1.])), ('batchnorm2.bias', tensor([0., 0.])), ('batchnorm2.running_mean', tensor([0., 0.])), ('batchnorm2.running_var', tensor([1., 1.])), ('batchnorm2.num_batches_tracked', tensor(0))])\n","output_type":"stream"}]},{"cell_type":"code","source":"train1_dataset = CustomDataset(X_tensor_train,y1_tensor_train)\nval1_dataset = CustomDataset(X_tensor_val,y1_tensor_val)\n\ntrain2_dataset = CustomDataset(X_tensor_train,y2_tensor_train)\nval2_dataset = CustomDataset(X_tensor_val,y2_tensor_val)","metadata":{"execution":{"iopub.status.busy":"2023-06-30T06:15:48.048084Z","iopub.execute_input":"2023-06-30T06:15:48.04866Z","iopub.status.idle":"2023-06-30T06:15:48.055211Z","shell.execute_reply.started":"2023-06-30T06:15:48.048623Z","shell.execute_reply":"2023-06-30T06:15:48.053965Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\ntorch.manual_seed(42)\ncriterion = nn.BCELoss()\n     ","metadata":{"execution":{"iopub.status.busy":"2023-06-30T06:26:15.286367Z","iopub.execute_input":"2023-06-30T06:26:15.286864Z","iopub.status.idle":"2023-06-30T06:26:15.294096Z","shell.execute_reply.started":"2023-06-30T06:26:15.286828Z","shell.execute_reply":"2023-06-30T06:26:15.29285Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"dataset = ConcatDataset([train1_dataset, val1_dataset])\n\nnum_epochs=10\nbatch_size=32\nk=10\nsplits=KFold(n_splits=k,shuffle=True,random_state=42)\nfoldperf={}","metadata":{"execution":{"iopub.status.busy":"2023-06-30T06:26:16.593676Z","iopub.execute_input":"2023-06-30T06:26:16.594111Z","iopub.status.idle":"2023-06-30T06:26:16.600471Z","shell.execute_reply.started":"2023-06-30T06:26:16.594079Z","shell.execute_reply":"2023-06-30T06:26:16.599658Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"class Trainer:\n    \n    def train_epoch(self,model,device,dataloader,loss_fn,optimizer):\n        train_loss,train_correct=0.0,0\n        model.train()\n        for images, labels in dataloader:\n\n            images,labels = images.to(device),labels.to(device)\n            optimizer.zero_grad()\n            output = model(images)\n            loss = loss_fn(output,labels.unsqueeze(1))\n            loss.backward()\n            optimizer.step()\n            train_loss += loss.item() * images.size(0)\n            scores, predictions = torch.max(output.data, 1)\n            train_correct += (predictions == labels).sum().item()\n        return train_loss,train_correct\n\n\n    def valid_epoch(self,model,device,dataloader,loss_fn):\n        valid_loss, val_correct = 0.0, 0\n        model.eval()\n        with torch.no_grad():\n          for images, labels in dataloader:\n              images,labels = images.to(device),labels.to(device)\n              output = model(images)\n              loss=loss_fn(output,labels.unsqueeze(1))\n              valid_loss+=loss.item()*images.size(0)\n              scores, predictions = torch.max(output.data,1)\n              val_correct+=(predictions == labels).sum().item()\n\n        return valid_loss,val_correct\n    \ntrainer = Trainer()","metadata":{"execution":{"iopub.status.busy":"2023-06-30T06:27:42.452141Z","iopub.execute_input":"2023-06-30T06:27:42.452565Z","iopub.status.idle":"2023-06-30T06:27:42.467805Z","shell.execute_reply.started":"2023-06-30T06:27:42.452531Z","shell.execute_reply":"2023-06-30T06:27:42.466207Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"history = {'train_loss': [], 'test_loss': [],'train_acc':[],'test_acc':[]}","metadata":{"execution":{"iopub.status.busy":"2023-06-30T06:27:43.014084Z","iopub.execute_input":"2023-06-30T06:27:43.014519Z","iopub.status.idle":"2023-06-30T06:27:43.022189Z","shell.execute_reply.started":"2023-06-30T06:27:43.014483Z","shell.execute_reply":"2023-06-30T06:27:43.020833Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"class Modeltrain:\n    def  call_train(self,model):\n        \n        for fold, (train_idx,val_idx) in enumerate(splits.split(np.arange(len(dataset)))):\n            \n            print('Fold {}'.format(fold + 1))\n            train_sampler = SubsetRandomSampler(train_idx)\n            test_sampler = SubsetRandomSampler(val_idx)\n            train_loader = DataLoader(dataset, batch_size=batch_size, sampler=train_sampler)\n            test_loader = DataLoader(dataset, batch_size=batch_size, sampler=test_sampler)\n            model.to(device)\n            optimizer = optim.Adam(model.parameters(), lr=0.002)\n            \n            for epoch in tqdm(range(num_epochs)):\n                train_loss, train_correct=trainer.train_epoch(model,device,train_loader,criterion,optimizer)\n                test_loss, test_correct=trainer.valid_epoch(model,device,test_loader,criterion)\n                train_loss = train_loss / len(train_loader.sampler)\n                train_acc = train_correct / len(train_loader.sampler) * 100\n                test_loss = test_loss / len(test_loader.sampler)\n                test_acc = test_correct / len(test_loader.sampler) * 100\n\n            print(\"Epoch:{}/{} AVG Training Loss:{:.3f} AVG Test Loss:{:.3f} AVG Training Acc {:.2f} % AVG Test Acc {:.2f} %\".format(epoch + 1,\n                                                                                                             num_epochs,\n                                                                                                             train_loss,\n                                                                                                             test_loss,\n                                                                                                             train_acc,\n                                                                                                            test_acc))\n        history['train_loss'].append(train_loss)\n        history['test_loss'].append(test_loss)\n        history['train_acc'].append(train_acc)\n        history['test_acc'].append(test_acc)  \n        \n        \nmt = Modeltrain()\nmt.call_train(model_EC1)","metadata":{"execution":{"iopub.status.busy":"2023-06-30T06:30:00.322046Z","iopub.execute_input":"2023-06-30T06:30:00.322499Z","iopub.status.idle":"2023-06-30T06:31:53.007823Z","shell.execute_reply.started":"2023-06-30T06:30:00.322466Z","shell.execute_reply":"2023-06-30T06:31:53.006695Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stdout","text":"Fold 1\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/10 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a367de5cd72e417797e4df03ce75231c"}},"metadata":{}},{"name":"stdout","text":"Epoch:10/10 AVG Training Loss:0.578 AVG Test Loss:0.584 AVG Training Acc 33.17 % AVG Test Acc 33.69 %\nFold 2\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/10 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"48500fd3b9114cb3b0aff8c51bdad4d7"}},"metadata":{}},{"name":"stdout","text":"Epoch:10/10 AVG Training Loss:0.580 AVG Test Loss:0.576 AVG Training Acc 33.32 % AVG Test Acc 32.35 %\nFold 3\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/10 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3d5ff82cbefc4d989b1abcabea96afa2"}},"metadata":{}},{"name":"stdout","text":"Epoch:10/10 AVG Training Loss:0.581 AVG Test Loss:0.558 AVG Training Acc 33.30 % AVG Test Acc 32.55 %\nFold 4\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/10 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ad4892bd406a40fbb0e34ec33716cbc8"}},"metadata":{}},{"name":"stdout","text":"Epoch:10/10 AVG Training Loss:0.575 AVG Test Loss:0.601 AVG Training Acc 33.14 % AVG Test Acc 33.96 %\nFold 5\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/10 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe3a5cf05fe145b6b7be99bbf569b6f4"}},"metadata":{}},{"name":"stdout","text":"Epoch:10/10 AVG Training Loss:0.580 AVG Test Loss:0.577 AVG Training Acc 33.17 % AVG Test Acc 33.76 %\nFold 6\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/10 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"50a6669480c045439947d997948c323f"}},"metadata":{}},{"name":"stdout","text":"Epoch:10/10 AVG Training Loss:0.578 AVG Test Loss:0.577 AVG Training Acc 33.18 % AVG Test Acc 33.63 %\nFold 7\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/10 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"427f24f5eb5345ce9a28b4479e5c205d"}},"metadata":{}},{"name":"stdout","text":"Epoch:10/10 AVG Training Loss:0.577 AVG Test Loss:0.576 AVG Training Acc 33.31 % AVG Test Acc 32.48 %\nFold 8\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/10 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c0dc672812c4b33869b7d682a219317"}},"metadata":{}},{"name":"stdout","text":"Epoch:10/10 AVG Training Loss:0.580 AVG Test Loss:0.568 AVG Training Acc 33.39 % AVG Test Acc 31.74 %\nFold 9\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/10 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fdaf0dabc6c74b149fa9ebbc88486d91"}},"metadata":{}},{"name":"stdout","text":"Epoch:10/10 AVG Training Loss:0.578 AVG Test Loss:0.579 AVG Training Acc 33.08 % AVG Test Acc 34.52 %\nFold 10\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/10 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5fc4ea9b04f44c2a84298b07cc50153b"}},"metadata":{}},{"name":"stdout","text":"Epoch:10/10 AVG Training Loss:0.578 AVG Test Loss:0.577 AVG Training Acc 33.19 % AVG Test Acc 33.58 %\n","output_type":"stream"}]},{"cell_type":"code","source":"avg_train_loss = np.mean(history['train_loss'])\navg_test_loss = np.mean(history['test_loss'])\navg_train_acc = np.mean(history['train_acc'])\navg_test_acc = np.mean(history['test_acc'])\n\nprint('Performance of {} fold cross validation'.format(k))\nprint(\"Average Training Loss: {:.4f} \\t Average Test Loss: {:.4f} \\t Average Training Acc: {:.3f} \\t Average Test Acc: {:.3f}\".format(avg_train_loss,avg_test_loss,avg_train_acc,avg_test_acc))  \n","metadata":{"execution":{"iopub.status.busy":"2023-06-30T06:31:56.885263Z","iopub.execute_input":"2023-06-30T06:31:56.886812Z","iopub.status.idle":"2023-06-30T06:31:56.895235Z","shell.execute_reply.started":"2023-06-30T06:31:56.886759Z","shell.execute_reply":"2023-06-30T06:31:56.893986Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stdout","text":"Performance of 10 fold cross validation\nAverage Training Loss: 0.5784 \t Average Test Loss: 0.5786 \t Average Training Acc: 33.186 \t Average Test Acc: 33.581\n","output_type":"stream"}]},{"cell_type":"code","source":"testl_f,tl_f,testa_f,ta_f=[],[],[],[]\nk=10\nfor f in range(1,k+1):\n\n     tl_f.append(np.mean(foldperf['fold{}'.format(f)]['train_loss']))\n     testl_f.append(np.mean(foldperf['fold{}'.format(f)]['test_loss']))\n\n     ta_f.append(np.mean(foldperf['fold{}'.format(f)]['train_acc']))\n     testa_f.append(np.mean(foldperf['fold{}'.format(f)]['test_acc']))\n\nprint('Performance of {} fold cross validation'.format(k))\nprint(\"Average Training Loss: {:.3f} \\t Average Test Loss: {:.3f} \\t Average Training Acc: {:.2f} \\t Average Test Acc: {:.2f}\".f","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"diz_ep = {'train_loss_ep':[],'test_loss_ep':[],'train_acc_ep':[],'test_acc_ep':[]}\n\nfor i in range(num_epochs):\n      diz_ep['train_loss_ep'].append(np.mean([foldperf['fold{}'.format(f+1)]['train_loss'][i] for f in range(k)]))\n      diz_ep['test_loss_ep'].append(np.mean([foldperf['fold{}'.format(f+1)]['test_loss'][i] for f in range(k)]))\n      diz_ep['train_acc_ep'].append(np.mean([foldperf['fold{}'.format(f+1)]['train_acc'][i] for f in range(k)]))\n      diz_ep['test_acc_ep'].append(np.mean([foldperf['fold{}'.format(f+1)]['test_acc'][i] for f in range(k)]))","metadata":{"execution":{"iopub.status.busy":"2023-06-30T06:33:06.465988Z","iopub.execute_input":"2023-06-30T06:33:06.466452Z","iopub.status.idle":"2023-06-30T06:33:06.567487Z","shell.execute_reply.started":"2023-06-30T06:33:06.466416Z","shell.execute_reply":"2023-06-30T06:33:06.565548Z"},"trusted":true},"execution_count":52,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","Cell \u001b[0;32mIn[52], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m diz_ep \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_loss_ep\u001b[39m\u001b[38;5;124m'\u001b[39m:[],\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_loss_ep\u001b[39m\u001b[38;5;124m'\u001b[39m:[],\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_acc_ep\u001b[39m\u001b[38;5;124m'\u001b[39m:[],\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_acc_ep\u001b[39m\u001b[38;5;124m'\u001b[39m:[]}\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m----> 4\u001b[0m       diz_ep[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_loss_ep\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39mmean([foldperf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfold\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(f\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m'\u001b[39m][i] \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(k)]))\n\u001b[1;32m      5\u001b[0m       diz_ep[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_loss_ep\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39mmean([foldperf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfold\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(f\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_loss\u001b[39m\u001b[38;5;124m'\u001b[39m][i] \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(k)]))\n\u001b[1;32m      6\u001b[0m       diz_ep[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_acc_ep\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39mmean([foldperf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfold\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(f\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_acc\u001b[39m\u001b[38;5;124m'\u001b[39m][i] \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(k)]))\n","Cell \u001b[0;32mIn[52], line 4\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m diz_ep \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_loss_ep\u001b[39m\u001b[38;5;124m'\u001b[39m:[],\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_loss_ep\u001b[39m\u001b[38;5;124m'\u001b[39m:[],\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_acc_ep\u001b[39m\u001b[38;5;124m'\u001b[39m:[],\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_acc_ep\u001b[39m\u001b[38;5;124m'\u001b[39m:[]}\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m----> 4\u001b[0m       diz_ep[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_loss_ep\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39mmean([\u001b[43mfoldperf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfold\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m'\u001b[39m][i] \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(k)]))\n\u001b[1;32m      5\u001b[0m       diz_ep[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_loss_ep\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39mmean([foldperf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfold\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(f\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_loss\u001b[39m\u001b[38;5;124m'\u001b[39m][i] \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(k)]))\n\u001b[1;32m      6\u001b[0m       diz_ep[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_acc_ep\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39mmean([foldperf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfold\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(f\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_acc\u001b[39m\u001b[38;5;124m'\u001b[39m][i] \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(k)]))\n","\u001b[0;31mKeyError\u001b[0m: 'fold1'"],"ename":"KeyError","evalue":"'fold1'","output_type":"error"}]},{"cell_type":"code","source":"# Plot losses\nplt.figure(figsize=(10,8))\nplt.semilogy(diz_ep['train_loss_ep'], label='Train')\nplt.semilogy(diz_ep['val_loss_ep'], label='Vallidation')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\n#plt.grid()\nplt.legend()\nplt.title('EC1 Loss')\nplt.show()\n     ","metadata":{"execution":{"iopub.status.busy":"2023-06-30T06:32:18.140219Z","iopub.execute_input":"2023-06-30T06:32:18.141342Z","iopub.status.idle":"2023-06-30T06:32:18.200647Z","shell.execute_reply.started":"2023-06-30T06:32:18.141286Z","shell.execute_reply":"2023-06-30T06:32:18.199126Z"},"trusted":true},"execution_count":51,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[51], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Plot losses\u001b[39;00m\n\u001b[1;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m8\u001b[39m))\n\u001b[0;32m----> 3\u001b[0m plt\u001b[38;5;241m.\u001b[39msemilogy(\u001b[43mdiz_ep\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_loss_ep\u001b[39m\u001b[38;5;124m'\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39msemilogy(diz_ep[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_loss_ep\u001b[39m\u001b[38;5;124m'\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","\u001b[0;31mNameError\u001b[0m: name 'diz_ep' is not defined"],"ename":"NameError","evalue":"name 'diz_ep' is not defined","output_type":"error"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x800 with 0 Axes>"},"metadata":{}}]},{"cell_type":"code","source":"\n# Plot accuracies\nplt.figure(figsize=(10,8))\nplt.semilogy(diz_ep['train_acc_ep'], label='Train')\nplt.semilogy(diz_ep['val_acc_ep'], label='Validation')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\n#plt.grid()\nplt.legend()\nplt.title('EC1 Accuracy')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]}]}