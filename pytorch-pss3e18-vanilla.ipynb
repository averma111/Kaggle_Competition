{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/averma111/pytorch-pss3e18-vanilla?scriptVersionId=135302069\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"\nimport random\nimport numpy as np \nimport pandas as pd \nimport os\nimport datetime\nimport seaborn as sns\nfrom tqdm.notebook import tqdm\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader,TensorDataset,random_split,SubsetRandomSampler, ConcatDataset\nfrom torch.nn import functional as F\n\n\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\nplt.style.use('fivethirtyeight')\nimport plotly.express as px\n\nimport warnings\nwarnings.filterwarnings('ignore')\nimport itertools","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-06-30T03:28:26.657169Z","iopub.execute_input":"2023-06-30T03:28:26.657641Z","iopub.status.idle":"2023-06-30T03:28:26.670037Z","shell.execute_reply.started":"2023-06-30T03:28:26.657603Z","shell.execute_reply":"2023-06-30T03:28:26.669186Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"for dirname, _, filenames in os.walk('/kaggle/input/'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"execution":{"iopub.status.busy":"2023-06-30T03:28:30.322291Z","iopub.execute_input":"2023-06-30T03:28:30.323402Z","iopub.status.idle":"2023-06-30T03:28:30.332116Z","shell.execute_reply.started":"2023-06-30T03:28:30.323339Z","shell.execute_reply":"2023-06-30T03:28:30.330945Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"/kaggle/input/playground-series-s3e18/sample_submission.csv\n/kaggle/input/playground-series-s3e18/train.csv\n/kaggle/input/playground-series-s3e18/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"class Datapreparation(object):\n    \n    def __init__(self,root_path):\n        self.root_path = root_path\n        \n    def get_dataframe(self,filename):\n        return pd.read_csv(os.path.join(self.root_path,filename))\n    \n    def summary(self,text, df):\n        summary = pd.DataFrame(df.dtypes, columns=['dtypes'])\n        summary['null'] = df.isnull().sum()\n        summary['unique'] = df.nunique()\n        summary['min'] = df.min()\n        summary['median'] = df.median()\n        summary['max'] = df.max()\n        summary['mean'] = df.mean()\n        summary['std'] = df.std()\n        summary['duplicate'] = df.duplicated().sum()\n        return summary\n    \n    \n    def random_split_data(self,X,y):\n        return train_test_split(X, y,test_size=0.20,random_state=42)\n\n \n    def standardization_data(self,X_data):\n        scaler = StandardScaler()\n        std_X_data = scaler.fit_transform(X_data)\n        return std_X_data\n    \n\n    \ndata = Datapreparation('/kaggle/input/playground-series-s3e18')\ntrain=data.get_dataframe('train.csv')","metadata":{"execution":{"iopub.status.busy":"2023-06-30T03:28:31.047886Z","iopub.execute_input":"2023-06-30T03:28:31.048317Z","iopub.status.idle":"2023-06-30T03:28:31.177795Z","shell.execute_reply.started":"2023-06-30T03:28:31.048281Z","shell.execute_reply":"2023-06-30T03:28:31.176485Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"data.summary('train',train)","metadata":{"execution":{"iopub.status.busy":"2023-06-30T03:28:32.54489Z","iopub.execute_input":"2023-06-30T03:28:32.545296Z","iopub.status.idle":"2023-06-30T03:28:32.636847Z","shell.execute_reply.started":"2023-06-30T03:28:32.545265Z","shell.execute_reply":"2023-06-30T03:28:32.635689Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"                    dtypes  null  unique         min       median  \\\nid                   int64     0   14838    0.000000  7418.500000   \nBertzCT            float64     0    2368    0.000000   290.987941   \nChi1               float64     0    1259    0.000000     6.485270   \nChi1n              float64     0    3157    0.000000     4.052701   \nChi1v              float64     0    3306    0.000000     4.392859   \nChi2n              float64     0    3634    0.000000     2.970427   \nChi2v              float64     0    3725    0.000000     3.242775   \nChi3v              float64     0    3448    0.000000     1.948613   \nChi4n              float64     0    2930    0.000000     1.073261   \nEState_VSA1        float64     0     719    0.000000    17.353601   \nEState_VSA2        float64     0     445    0.000000     6.420822   \nExactMolWt         float64     0    1666    1.007276   206.042653   \nFpDensityMorgan1   float64     0     556 -666.000000     1.250000   \nFpDensityMorgan2   float64     0     650 -666.000000     1.865152   \nFpDensityMorgan3   float64     0     654 -666.000000     2.358491   \nHallKierAlpha      float64     0     388   -7.730000    -1.100000   \nHeavyAtomMolWt     float64     0     860    0.000000   194.276500   \nKappa3             float64     0    2245 -104.040000     3.261011   \nMaxAbsEStateIndex  float64     0    2356    0.000000    10.421334   \nMinEStateIndex     float64     0    2142   -6.327514    -1.265370   \nNumHeteroatoms       int64     0      40    0.000000     6.000000   \nPEOE_VSA10         float64     0     250    0.000000     6.041841   \nPEOE_VSA14         float64     0     291    0.000000     5.969305   \nPEOE_VSA6          float64     0     219    0.000000     0.000000   \nPEOE_VSA7          float64     0     262    0.000000     0.000000   \nPEOE_VSA8          float64     0     237    0.000000     0.000000   \nSMR_VSA10          float64     0     409    0.000000    11.752550   \nSMR_VSA5           float64     0     492    0.000000    20.075376   \nSlogP_VSA3         float64     0     217    0.000000     9.589074   \nVSA_EState9        float64     0    1946   -5.430556    41.666667   \nfr_COO               int64     0       8    0.000000     0.000000   \nfr_COO2              int64     0       8    0.000000     0.000000   \nEC1                  int64     0       2    0.000000     1.000000   \nEC2                  int64     0       2    0.000000     1.000000   \nEC3                  int64     0       2    0.000000     0.000000   \nEC4                  int64     0       2    0.000000     0.000000   \nEC5                  int64     0       2    0.000000     0.000000   \nEC6                  int64     0       2    0.000000     0.000000   \n\n                            max         mean          std  duplicate  \nid                 14837.000000  7418.500000  4283.505982          0  \nBertzCT             4069.959780   515.153604   542.456370          0  \nChi1                  69.551167     9.135189     6.819989          0  \nChi1n                 50.174588     5.854307     4.647064          0  \nChi1v                 53.431954     6.738497     5.866444          0  \nChi2n                 32.195368     4.432570     3.760516          0  \nChi2v                 34.579313     5.253221     4.925065          0  \nChi3v                 22.880836     3.418749     3.436208          0  \nChi4n                 16.072810     1.773472     1.865898          0  \nEState_VSA1          363.705954    29.202823    31.728679          0  \nEState_VSA2           99.936429    10.435316    13.651843          0  \nExactMolWt          2237.318490   292.623087   225.384140          0  \nFpDensityMorgan1       3.000000     1.236774     5.491284          0  \nFpDensityMorgan2       3.200000     1.812070     5.495565          0  \nFpDensityMorgan3       3.400000     2.255470     5.501200          0  \nHallKierAlpha          0.820000    -1.207776     0.935314          0  \nHeavyAtomMolWt      2035.133000   274.950211   212.678755          0  \nKappa3              1512.242231     5.874372    45.730226          0  \nMaxAbsEStateIndex     15.630251    10.556443     1.559331          0  \nMinEStateIndex         6.000000    -2.119772     2.066415          0  \nNumHeteroatoms        42.000000     8.584108     7.643769          0  \nPEOE_VSA10            97.663462    11.021644    13.958962          0  \nPEOE_VSA14           482.434223    17.790011    34.561655          0  \nPEOE_VSA6            375.425148     8.962440    19.756727          0  \nPEOE_VSA7            211.501279    11.318811    20.169745          0  \nPEOE_VSA8            100.348416     6.704487    10.865415          0  \nSMR_VSA10             80.742293    15.666766    18.080208          0  \nSMR_VSA5             492.729739    31.066423    33.896638          0  \nSlogP_VSA3           115.406157    13.636941    14.598554          0  \nVSA_EState9          384.450519    49.309959    29.174824          0  \nfr_COO                 8.000000     0.458215     0.667948          0  \nfr_COO2                8.000000     0.459226     0.668111          0  \nEC1                    1.000000     0.667745     0.471038          0  \nEC2                    1.000000     0.798962     0.400790          0  \nEC3                    1.000000     0.313789     0.464047          0  \nEC4                    1.000000     0.279081     0.448562          0  \nEC5                    1.000000     0.144831     0.351942          0  \nEC6                    1.000000     0.151570     0.358616          0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dtypes</th>\n      <th>null</th>\n      <th>unique</th>\n      <th>min</th>\n      <th>median</th>\n      <th>max</th>\n      <th>mean</th>\n      <th>std</th>\n      <th>duplicate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>id</th>\n      <td>int64</td>\n      <td>0</td>\n      <td>14838</td>\n      <td>0.000000</td>\n      <td>7418.500000</td>\n      <td>14837.000000</td>\n      <td>7418.500000</td>\n      <td>4283.505982</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>BertzCT</th>\n      <td>float64</td>\n      <td>0</td>\n      <td>2368</td>\n      <td>0.000000</td>\n      <td>290.987941</td>\n      <td>4069.959780</td>\n      <td>515.153604</td>\n      <td>542.456370</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>Chi1</th>\n      <td>float64</td>\n      <td>0</td>\n      <td>1259</td>\n      <td>0.000000</td>\n      <td>6.485270</td>\n      <td>69.551167</td>\n      <td>9.135189</td>\n      <td>6.819989</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>Chi1n</th>\n      <td>float64</td>\n      <td>0</td>\n      <td>3157</td>\n      <td>0.000000</td>\n      <td>4.052701</td>\n      <td>50.174588</td>\n      <td>5.854307</td>\n      <td>4.647064</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>Chi1v</th>\n      <td>float64</td>\n      <td>0</td>\n      <td>3306</td>\n      <td>0.000000</td>\n      <td>4.392859</td>\n      <td>53.431954</td>\n      <td>6.738497</td>\n      <td>5.866444</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>Chi2n</th>\n      <td>float64</td>\n      <td>0</td>\n      <td>3634</td>\n      <td>0.000000</td>\n      <td>2.970427</td>\n      <td>32.195368</td>\n      <td>4.432570</td>\n      <td>3.760516</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>Chi2v</th>\n      <td>float64</td>\n      <td>0</td>\n      <td>3725</td>\n      <td>0.000000</td>\n      <td>3.242775</td>\n      <td>34.579313</td>\n      <td>5.253221</td>\n      <td>4.925065</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>Chi3v</th>\n      <td>float64</td>\n      <td>0</td>\n      <td>3448</td>\n      <td>0.000000</td>\n      <td>1.948613</td>\n      <td>22.880836</td>\n      <td>3.418749</td>\n      <td>3.436208</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>Chi4n</th>\n      <td>float64</td>\n      <td>0</td>\n      <td>2930</td>\n      <td>0.000000</td>\n      <td>1.073261</td>\n      <td>16.072810</td>\n      <td>1.773472</td>\n      <td>1.865898</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>EState_VSA1</th>\n      <td>float64</td>\n      <td>0</td>\n      <td>719</td>\n      <td>0.000000</td>\n      <td>17.353601</td>\n      <td>363.705954</td>\n      <td>29.202823</td>\n      <td>31.728679</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>EState_VSA2</th>\n      <td>float64</td>\n      <td>0</td>\n      <td>445</td>\n      <td>0.000000</td>\n      <td>6.420822</td>\n      <td>99.936429</td>\n      <td>10.435316</td>\n      <td>13.651843</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>ExactMolWt</th>\n      <td>float64</td>\n      <td>0</td>\n      <td>1666</td>\n      <td>1.007276</td>\n      <td>206.042653</td>\n      <td>2237.318490</td>\n      <td>292.623087</td>\n      <td>225.384140</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>FpDensityMorgan1</th>\n      <td>float64</td>\n      <td>0</td>\n      <td>556</td>\n      <td>-666.000000</td>\n      <td>1.250000</td>\n      <td>3.000000</td>\n      <td>1.236774</td>\n      <td>5.491284</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>FpDensityMorgan2</th>\n      <td>float64</td>\n      <td>0</td>\n      <td>650</td>\n      <td>-666.000000</td>\n      <td>1.865152</td>\n      <td>3.200000</td>\n      <td>1.812070</td>\n      <td>5.495565</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>FpDensityMorgan3</th>\n      <td>float64</td>\n      <td>0</td>\n      <td>654</td>\n      <td>-666.000000</td>\n      <td>2.358491</td>\n      <td>3.400000</td>\n      <td>2.255470</td>\n      <td>5.501200</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>HallKierAlpha</th>\n      <td>float64</td>\n      <td>0</td>\n      <td>388</td>\n      <td>-7.730000</td>\n      <td>-1.100000</td>\n      <td>0.820000</td>\n      <td>-1.207776</td>\n      <td>0.935314</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>HeavyAtomMolWt</th>\n      <td>float64</td>\n      <td>0</td>\n      <td>860</td>\n      <td>0.000000</td>\n      <td>194.276500</td>\n      <td>2035.133000</td>\n      <td>274.950211</td>\n      <td>212.678755</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>Kappa3</th>\n      <td>float64</td>\n      <td>0</td>\n      <td>2245</td>\n      <td>-104.040000</td>\n      <td>3.261011</td>\n      <td>1512.242231</td>\n      <td>5.874372</td>\n      <td>45.730226</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>MaxAbsEStateIndex</th>\n      <td>float64</td>\n      <td>0</td>\n      <td>2356</td>\n      <td>0.000000</td>\n      <td>10.421334</td>\n      <td>15.630251</td>\n      <td>10.556443</td>\n      <td>1.559331</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>MinEStateIndex</th>\n      <td>float64</td>\n      <td>0</td>\n      <td>2142</td>\n      <td>-6.327514</td>\n      <td>-1.265370</td>\n      <td>6.000000</td>\n      <td>-2.119772</td>\n      <td>2.066415</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>NumHeteroatoms</th>\n      <td>int64</td>\n      <td>0</td>\n      <td>40</td>\n      <td>0.000000</td>\n      <td>6.000000</td>\n      <td>42.000000</td>\n      <td>8.584108</td>\n      <td>7.643769</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>PEOE_VSA10</th>\n      <td>float64</td>\n      <td>0</td>\n      <td>250</td>\n      <td>0.000000</td>\n      <td>6.041841</td>\n      <td>97.663462</td>\n      <td>11.021644</td>\n      <td>13.958962</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>PEOE_VSA14</th>\n      <td>float64</td>\n      <td>0</td>\n      <td>291</td>\n      <td>0.000000</td>\n      <td>5.969305</td>\n      <td>482.434223</td>\n      <td>17.790011</td>\n      <td>34.561655</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>PEOE_VSA6</th>\n      <td>float64</td>\n      <td>0</td>\n      <td>219</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>375.425148</td>\n      <td>8.962440</td>\n      <td>19.756727</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>PEOE_VSA7</th>\n      <td>float64</td>\n      <td>0</td>\n      <td>262</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>211.501279</td>\n      <td>11.318811</td>\n      <td>20.169745</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>PEOE_VSA8</th>\n      <td>float64</td>\n      <td>0</td>\n      <td>237</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>100.348416</td>\n      <td>6.704487</td>\n      <td>10.865415</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>SMR_VSA10</th>\n      <td>float64</td>\n      <td>0</td>\n      <td>409</td>\n      <td>0.000000</td>\n      <td>11.752550</td>\n      <td>80.742293</td>\n      <td>15.666766</td>\n      <td>18.080208</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>SMR_VSA5</th>\n      <td>float64</td>\n      <td>0</td>\n      <td>492</td>\n      <td>0.000000</td>\n      <td>20.075376</td>\n      <td>492.729739</td>\n      <td>31.066423</td>\n      <td>33.896638</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>SlogP_VSA3</th>\n      <td>float64</td>\n      <td>0</td>\n      <td>217</td>\n      <td>0.000000</td>\n      <td>9.589074</td>\n      <td>115.406157</td>\n      <td>13.636941</td>\n      <td>14.598554</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>VSA_EState9</th>\n      <td>float64</td>\n      <td>0</td>\n      <td>1946</td>\n      <td>-5.430556</td>\n      <td>41.666667</td>\n      <td>384.450519</td>\n      <td>49.309959</td>\n      <td>29.174824</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>fr_COO</th>\n      <td>int64</td>\n      <td>0</td>\n      <td>8</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>8.000000</td>\n      <td>0.458215</td>\n      <td>0.667948</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>fr_COO2</th>\n      <td>int64</td>\n      <td>0</td>\n      <td>8</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>8.000000</td>\n      <td>0.459226</td>\n      <td>0.668111</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>EC1</th>\n      <td>int64</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.667745</td>\n      <td>0.471038</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>EC2</th>\n      <td>int64</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.798962</td>\n      <td>0.400790</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>EC3</th>\n      <td>int64</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.313789</td>\n      <td>0.464047</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>EC4</th>\n      <td>int64</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.279081</td>\n      <td>0.448562</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>EC5</th>\n      <td>int64</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.144831</td>\n      <td>0.351942</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>EC6</th>\n      <td>int64</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.151570</td>\n      <td>0.358616</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"y1 = train['EC1']\ny2 = train['EC2']\ntrain.drop(columns=['id','EC1','EC2','EC3','EC4','EC5','EC6'],axis=1,inplace=True)\nX = train.copy()","metadata":{"execution":{"iopub.status.busy":"2023-06-30T03:28:36.928329Z","iopub.execute_input":"2023-06-30T03:28:36.928733Z","iopub.status.idle":"2023-06-30T03:28:36.939511Z","shell.execute_reply.started":"2023-06-30T03:28:36.928703Z","shell.execute_reply":"2023-06-30T03:28:36.938231Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"X_train,X_val,y1_train,y1_val = data.random_split_data(X,y1)\nprint(X_train.shape,X_val.shape,y1_train.shape,y1_val.shape)","metadata":{"execution":{"iopub.status.busy":"2023-06-30T03:30:20.543503Z","iopub.execute_input":"2023-06-30T03:30:20.544546Z","iopub.status.idle":"2023-06-30T03:30:20.555762Z","shell.execute_reply.started":"2023-06-30T03:30:20.544512Z","shell.execute_reply":"2023-06-30T03:30:20.554903Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"(11870, 31) (2968, 31) (11870,) (2968,)\n","output_type":"stream"}]},{"cell_type":"code","source":"X_train,X_val,y2_train,y2_val = data.random_split_data(X,y2)\nprint(X_train.shape,X_val.shape,y2_train.shape,y2_val.shape)","metadata":{"execution":{"iopub.status.busy":"2023-06-30T03:30:21.562217Z","iopub.execute_input":"2023-06-30T03:30:21.562855Z","iopub.status.idle":"2023-06-30T03:30:21.572579Z","shell.execute_reply.started":"2023-06-30T03:30:21.562822Z","shell.execute_reply":"2023-06-30T03:30:21.571444Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"(11870, 31) (2968, 31) (11870,) (2968,)\n","output_type":"stream"}]},{"cell_type":"code","source":"std_X_train = data.standardization_data(X_train)\nstd_X_val = data.standardization_data(X_val)\nprint(std_X_train[0],std_X_val[0])","metadata":{"execution":{"iopub.status.busy":"2023-06-30T03:30:53.493608Z","iopub.execute_input":"2023-06-30T03:30:53.494841Z","iopub.status.idle":"2023-06-30T03:30:53.520012Z","shell.execute_reply.started":"2023-06-30T03:30:53.494789Z","shell.execute_reply":"2023-06-30T03:30:53.518871Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"[-0.6460012  -0.49660398 -0.53250602 -0.57261284 -0.5904852  -0.61753263\n -0.59673579 -0.62771573 -0.91411097  0.56344636 -0.56889535 -0.07305243\n  0.81469479  1.50215144  0.0217275  -0.57591696 -0.08736038 -0.39329628\n  1.34611003 -0.72802128 -0.78622974 -0.51646882  0.1563295   0.31295018\n -0.61487415 -0.5171512  -0.91283104 -0.93428166 -0.94969081 -0.68328343\n -0.68460195] [-0.73157789 -0.89416128 -0.71611727 -0.71782103 -0.74457679 -0.73521665\n -0.8362178  -0.84437652 -0.385045   -0.76779355 -0.74586676  0.06227215\n  0.02884275  0.07397899  0.41849986 -0.75437549 -0.10510849 -0.80384358\n  0.35858918 -0.61099998 -0.3717161  -0.33573224 -0.47165217 -0.56987761\n -0.62586121 -0.22583258 -0.54067893 -0.28699515 -0.54836477  0.78492852\n  0.78337988]\n","output_type":"stream"}]},{"cell_type":"code","source":"class Tensoroperations():\n    \n    def __init__(self):\n        super(Tensoroperations,self).__init__()\n    \n    def convert_to_tensor(self,X,y=None):\n        X_tensor =  torch.from_numpy(X).float()   \n        y_tensor = torch.from_numpy(y).float() \n        return X_tensor,y_tensor\n        \n    def convert_to_test_tesnor(self,X):\n        X_tensor =  torch.from_numpy(X).float()\n        return X_tensor\n    \n    def get_dataloaders(self,train_dataset,val_dataset):\n        train_loaders = DataLoader(train_dataset,batch_size=32,shuffle=True)\n        val_loaders = DataLoader(val_dataset,batch_size=32)\n        return train_loaders,val_loaders\n    \n    def get_test_dataloaders(self,test_dataset,X_test):\n        test_loaders = DataLoader(test_dataset,batch_size=X_test.shape[0])\n        return test_loaders\n        \n        \n    \ntenops = Tensoroperations()","metadata":{"execution":{"iopub.status.busy":"2023-06-30T03:31:34.138844Z","iopub.execute_input":"2023-06-30T03:31:34.139969Z","iopub.status.idle":"2023-06-30T03:31:34.149317Z","shell.execute_reply.started":"2023-06-30T03:31:34.139927Z","shell.execute_reply":"2023-06-30T03:31:34.147845Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    \n    def __init__(self,X_data,y_data=None,is_train=True):\n        super().__init__()\n        if is_train:\n            self.X_data = X_data\n            self.y_data = y_data\n        else:\n            self.X_data=X_train\n            \n    def __getitem__(self,index):\n        return (self.X_data[index],self.y_data[index])\n    \n    def __len__(self):\n        return len(self.X_data)","metadata":{"execution":{"iopub.status.busy":"2023-06-30T03:31:45.462841Z","iopub.execute_input":"2023-06-30T03:31:45.463245Z","iopub.status.idle":"2023-06-30T03:31:45.470656Z","shell.execute_reply.started":"2023-06-30T03:31:45.463213Z","shell.execute_reply":"2023-06-30T03:31:45.469679Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"X_tensor_train,y1_tensor_train = tenops.convert_to_tensor(std_X_train,y1_train.values)\nX_tensor_val,y1_tensor_val = tenops.convert_to_tensor(std_X_val,y1_val.values)\nprint('The training tensor for EC1\\n',X_tensor_train,y1_tensor_train)\nprint('The validation tensor for EC1\\n',X_tensor_val,y1_tensor_val)","metadata":{"execution":{"iopub.status.busy":"2023-06-30T03:33:06.072599Z","iopub.execute_input":"2023-06-30T03:33:06.073027Z","iopub.status.idle":"2023-06-30T03:33:06.186969Z","shell.execute_reply.started":"2023-06-30T03:33:06.072996Z","shell.execute_reply":"2023-06-30T03:33:06.186123Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"The training tensor for EC1\n tensor([[-0.6460, -0.4966, -0.5325,  ..., -0.9497, -0.6833, -0.6846],\n        [-0.7818, -0.9513, -0.8922,  ..., -1.0127,  0.8178,  0.8161],\n        [ 2.1245,  1.5223,  1.7448,  ...,  2.0297, -0.6833, -0.6846],\n        ...,\n        [-0.2776,  0.0232, -0.3406,  ..., -0.6133, -0.6833, -0.6846],\n        [-0.7166, -0.6467, -0.5530,  ..., -0.6577, -0.6833, -0.6846],\n        [-0.8225, -0.8068, -0.8795,  ..., -0.8180, -0.6833, -0.6846]]) tensor([1., 1., 1.,  ..., 0., 0., 1.])\nThe validation tensor for EC1\n tensor([[-0.7316, -0.8942, -0.7161,  ..., -0.5484,  0.7849,  0.7834],\n        [-0.2605,  0.2136,  0.2536,  ..., -0.2027, -0.6970, -0.6985],\n        [-0.4432, -1.0872, -1.1129,  ..., -0.1914,  2.2669,  2.2653],\n        ...,\n        [-0.6615, -0.6798, -0.6762,  ..., -0.3160,  0.7849,  0.7834],\n        [ 0.7218,  0.9378,  0.8351,  ...,  0.2456, -0.6970, -0.6985],\n        [-0.8259, -0.8942, -0.8957,  ..., -0.9963, -0.6970, -0.6985]]) tensor([1., 0., 1.,  ..., 1., 0., 1.])\n","output_type":"stream"}]},{"cell_type":"code","source":"X_tensor_train,y2_tensor_train = tenops.convert_to_tensor(std_X_train,y2_train.values)\nX_tensor_val,y2_tensor_val = tenops.convert_to_tensor(std_X_val,y2_val.values)\nprint('The training tensor EC2\\n',X_tensor_train,y2_tensor_train)\nprint('The validation tensor Ec2\\n',X_tensor_val,y2_tensor_val)","metadata":{"execution":{"iopub.status.busy":"2023-06-30T03:33:19.259403Z","iopub.execute_input":"2023-06-30T03:33:19.259793Z","iopub.status.idle":"2023-06-30T03:33:19.271303Z","shell.execute_reply.started":"2023-06-30T03:33:19.259765Z","shell.execute_reply":"2023-06-30T03:33:19.270434Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"The training tensor EC2\n tensor([[-0.6460, -0.4966, -0.5325,  ..., -0.9497, -0.6833, -0.6846],\n        [-0.7818, -0.9513, -0.8922,  ..., -1.0127,  0.8178,  0.8161],\n        [ 2.1245,  1.5223,  1.7448,  ...,  2.0297, -0.6833, -0.6846],\n        ...,\n        [-0.2776,  0.0232, -0.3406,  ..., -0.6133, -0.6833, -0.6846],\n        [-0.7166, -0.6467, -0.5530,  ..., -0.6577, -0.6833, -0.6846],\n        [-0.8225, -0.8068, -0.8795,  ..., -0.8180, -0.6833, -0.6846]]) tensor([1., 1., 0.,  ..., 1., 1., 1.])\nThe validation tensor Ec2\n tensor([[-0.7316, -0.8942, -0.7161,  ..., -0.5484,  0.7849,  0.7834],\n        [-0.2605,  0.2136,  0.2536,  ..., -0.2027, -0.6970, -0.6985],\n        [-0.4432, -1.0872, -1.1129,  ..., -0.1914,  2.2669,  2.2653],\n        ...,\n        [-0.6615, -0.6798, -0.6762,  ..., -0.3160,  0.7849,  0.7834],\n        [ 0.7218,  0.9378,  0.8351,  ...,  0.2456, -0.6970, -0.6985],\n        [-0.8259, -0.8942, -0.8957,  ..., -0.9963, -0.6970, -0.6985]]) tensor([1., 1., 1.,  ..., 1., 1., 1.])\n","output_type":"stream"}]},{"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\ntorch.manual_seed(42)\ncriterion = nn.CrossEntropyLoss()\n     ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = ConcatDataset([train_dataset, test_dataset])\n\nnum_epochs=10\nbatch_size=128\nk=10\nsplits=KFold(n_splits=k,shuffle=True,random_state=42)\nfoldperf={}","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_epoch(model,device,dataloader,loss_fn,optimizer):\n    train_loss,train_correct=0.0,0\n    model.train()\n    for images, labels in dataloader:\n\n        images,labels = images.to(device),labels.to(device)\n        optimizer.zero_grad()\n        output = model(images)\n        loss = loss_fn(output,labels)\n        loss.backward()\n        optimizer.step()\n        train_loss += loss.item() * images.size(0)\n        scores, predictions = torch.max(output.data, 1)\n        train_correct += (predictions == labels).sum().item()\n\n    return train_loss,train_correct","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def valid_epoch(model,device,dataloader,loss_fn):\n    valid_loss, val_correct = 0.0, 0\n    model.eval()\n    with torch.no_grad():\n      for images, labels in dataloader:\n\n          images,labels = images.to(device),labels.to(device)\n          output = model(images)\n          loss=loss_fn(output,labels)\n          valid_loss+=loss.item()*images.size(0)\n          scores, predictions = torch.max(output.data,1)\n          val_correct+=(predictions == labels).sum().item()\n\n    return valid_loss,val_correct","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = {'train_loss': [], 'test_loss': [],'train_acc':[],'test_acc':[]}\n\nfor fold, (train_idx,val_idx) in enumerate(splits.split(np.arange(len(dataset)))):\n\n    print('Fold {}'.format(fold + 1))\n\n    train_sampler = SubsetRandomSampler(train_idx)\n    test_sampler = SubsetRandomSampler(val_idx)\n    train_loader = DataLoader(dataset, batch_size=batch_size, sampler=train_sampler)\n    test_loader = DataLoader(dataset, batch_size=batch_size, sampler=test_sampler)\n    \n    model = ConvNet()\n    model.to(device)\n    optimizer = optim.Adam(model.parameters(), lr=0.002)\n\n    for epoch in range(num_epochs):\n        train_loss, train_correct=train_epoch(model,device,train_loader,criterion,optimizer)\n        test_loss, test_correct=valid_epoch(model,device,test_loader,criterion)\n\n        train_loss = train_loss / len(train_loader.sampler)\n        train_acc = train_correct / len(train_loader.sampler) * 100\n        test_loss = test_loss / len(test_loader.sampler)\n        test_acc = test_correct / len(test_loader.sampler) * 100\n\n        print(\"Epoch:{}/{} AVG Training Loss:{:.3f} AVG Test Loss:{:.3f} AVG Training Acc {:.2f} % AVG Test Acc {:.2f} %\".format(epoch + 1,\n                                                                                                             num_epochs,\n                                                                                                             train_loss,\n                                                                                                             test_loss,\n                                                                                                             train_acc,\n                                                                                                             test_acc))\n        history['train_loss'].append(train_loss)\n        history['test_loss'].append(test_loss)\n        history['train_acc'].append(train_acc)\n        history['test_acc'].append(test_acc)  ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"avg_train_loss = np.mean(history['train_loss'])\navg_test_loss = np.mean(history['test_loss'])\navg_train_acc = np.mean(history['train_acc'])\navg_test_acc = np.mean(history['test_acc'])\n\nprint('Performance of {} fold cross validation'.format(k))\nprint(\"Average Training Loss: {:.4f} \\t Average Test Loss: {:.4f} \\t Average Training Acc: {:.3f} \\t Average Test Acc: {:.3f}\".format(avg_train_loss,avg_test_loss,avg_train_acc,avg_test_acc))  \n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testl_f,tl_f,testa_f,ta_f=[],[],[],[]\nk=10\nfor f in range(1,k+1):\n\n     tl_f.append(np.mean(foldperf['fold{}'.format(f)]['train_loss']))\n     testl_f.append(np.mean(foldperf['fold{}'.format(f)]['test_loss']))\n\n     ta_f.append(np.mean(foldperf['fold{}'.format(f)]['train_acc']))\n     testa_f.append(np.mean(foldperf['fold{}'.format(f)]['test_acc']))\n\nprint('Performance of {} fold cross validation'.format(k))\nprint(\"Average Training Loss: {:.3f} \\t Average Test Loss: {:.3f} \\t Average Training Acc: {:.2f} \\t Average Test Acc: {:.2f}\".f","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"diz_ep = {'train_loss_ep':[],'test_loss_ep':[],'train_acc_ep':[],'test_acc_ep':[]}\n\nfor i in range(num_epochs):\n      diz_ep['train_loss_ep'].append(np.mean([foldperf['fold{}'.format(f+1)]['train_loss'][i] for f in range(k)]))\n      diz_ep['test_loss_ep'].append(np.mean([foldperf['fold{}'.format(f+1)]['test_loss'][i] for f in range(k)]))\n      diz_ep['train_acc_ep'].append(np.mean([foldperf['fold{}'.format(f+1)]['train_acc'][i] for f in range(k)]))\n      diz_ep['test_acc_ep'].append(np.mean([foldperf['fold{}'.format(f+1)]['test_acc'][i] for f in range(k)]))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot losses\nplt.figure(figsize=(10,8))\nplt.semilogy(diz_ep['train_loss_ep'], label='Train')\nplt.semilogy(diz_ep['test_loss_ep'], label='Test')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\n#plt.grid()\nplt.legend()\nplt.title('CNN loss')\nplt.show()\n     ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Plot accuracies\nplt.figure(figsize=(10,8))\nplt.semilogy(diz_ep['train_acc_ep'], label='Train')\nplt.semilogy(diz_ep['test_acc_ep'], label='Test')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\n#plt.grid()\nplt.legend()\nplt.title('CNN accuracy')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]}]}