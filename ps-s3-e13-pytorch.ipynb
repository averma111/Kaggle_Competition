{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/averma111/ps-s3-e13-pytorch?scriptVersionId=127116199\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport torch \nfrom torch.utils.data import Dataset,DataLoader,random_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-25T06:28:31.692092Z","iopub.execute_input":"2023-04-25T06:28:31.692516Z","iopub.status.idle":"2023-04-25T06:28:31.698776Z","shell.execute_reply.started":"2023-04-25T06:28:31.692479Z","shell.execute_reply":"2023-04-25T06:28:31.697596Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"# Dataset Definition\n\nclass CSVDataset(Dataset):\n  # load the dataset\n  def __init__(self,path):\n    train = pd.read_csv(path)\n    train.drop('id',axis=1,inplace=True)\n    # Store the features and labels\n    self.X = train.values[:,:-1]\n    self.y = train.values[:,-1]\n    # Input data is float\n    self.X = self.X.astype('float32')\n    # Encode label\n    self.y = LabelEncoder().fit_transform(self.y)\n    self.y = self.y.astype('float32')\n    self.y = self.y.reshape(len(self.y),1)\n\n  # number of rows in the dataset\n  def __len__(self):\n    return len(self.X)\n\n  # get a row at an index\n  def __getitem__(self, idx):\n    return [self.X[idx], self.y[idx]]\n\n  # get indexes for train and test rows\n  def get_splits(self, n_test=0.33):\n    # determine sizes\n    test_size = round(n_test * len(self.X))\n    train_size = len(self.X) - test_size\n    # calculate the split\n    return random_split(self, [train_size, test_size])","metadata":{"execution":{"iopub.status.busy":"2023-04-25T06:34:46.344871Z","iopub.execute_input":"2023-04-25T06:34:46.346176Z","iopub.status.idle":"2023-04-25T06:34:46.356144Z","shell.execute_reply.started":"2023-04-25T06:34:46.346118Z","shell.execute_reply":"2023-04-25T06:34:46.354853Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"class MLP(torch.nn.Module):\n  # define the model elements\n  def __init__(self,n_inputs):\n    super(MLP, self).__init__()\n    # input to first hidden layer\n    self.hidden1 = torch.nn.Linear(n_inputs, 100)\n    torch.nn.init.kaiming_uniform_(self.hidden1.weight, nonlinearity='relu')\n    self.act1 = torch.nn.ReLU()\n    # second hidden layer\n    self.hidden2 = torch.nn.Linear(100, 8)\n    torch.nn.init.kaiming_uniform_(self.hidden2.weight, nonlinearity='relu')\n    self.act2 = torch.nn.ReLU()\n    # third hidden layer and output\n    self.hidden3 = torch.nn.Linear(8, 1)\n    torch.nn.init.xavier_uniform_(self.hidden3.weight)\n    self.act3 = torch.nn.Sigmoid()\n   # forward propagate input\n  def forward(self, X):\n    # input to first hidden layer\n    X = self.hidden1(X)\n    X = self.act1(X)\n     # second hidden layer\n    X = self.hidden2(X)\n    X = self.act2(X)\n    # third hidden layer and output\n    X = self.hidden3(X)\n    X = self.act3(X)\n    return X","metadata":{"execution":{"iopub.status.busy":"2023-04-25T06:41:18.521335Z","iopub.execute_input":"2023-04-25T06:41:18.522143Z","iopub.status.idle":"2023-04-25T06:41:18.533452Z","shell.execute_reply.started":"2023-04-25T06:41:18.522101Z","shell.execute_reply":"2023-04-25T06:41:18.532001Z"},"trusted":true},"execution_count":100,"outputs":[]},{"cell_type":"code","source":"# prepare the dataset\ndef prepare_data(path):\n    # load the dataset\n    dataset = CSVDataset(path)\n    # calculate split\n    train, test = dataset.get_splits()\n    # prepare data loaders\n    train_dl = DataLoader(train, batch_size=32, shuffle=True)\n    test_dl = DataLoader(test, batch_size=32, shuffle=False)\n    return train_dl, test_dl","metadata":{"execution":{"iopub.status.busy":"2023-04-25T06:41:19.359407Z","iopub.execute_input":"2023-04-25T06:41:19.359799Z","iopub.status.idle":"2023-04-25T06:41:19.366694Z","shell.execute_reply.started":"2023-04-25T06:41:19.359764Z","shell.execute_reply":"2023-04-25T06:41:19.365147Z"},"trusted":true},"execution_count":101,"outputs":[]},{"cell_type":"code","source":"# train the model\ndef train_model(train_dl, model):\n    # define the optimization\n    criterion = torch.nn.BCELoss()\n    optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n    # enumerate epochs\n    for epoch in range(100):\n        # enumerate mini batches\n        for i, (inputs, targets) in enumerate(train_dl):\n            # clear the gradients\n            optimizer.zero_grad()\n            # compute the model output\n            yhat = model(inputs)\n            # calculate loss\n            loss = criterion(yhat, targets)\n            # credit assignment\n            loss.backward()\n            # update model weights\n            optimizer.step()","metadata":{"execution":{"iopub.status.busy":"2023-04-25T06:41:19.838098Z","iopub.execute_input":"2023-04-25T06:41:19.838555Z","iopub.status.idle":"2023-04-25T06:41:19.846764Z","shell.execute_reply.started":"2023-04-25T06:41:19.838514Z","shell.execute_reply":"2023-04-25T06:41:19.845126Z"},"trusted":true},"execution_count":102,"outputs":[]},{"cell_type":"code","source":"# evaluate the model\ndef evaluate_model(test_dl, model):\n    predictions, actuals = list(), list()\n    for i, (inputs, targets) in enumerate(test_dl):\n        # evaluate the model on the test set\n        yhat = model(inputs)\n        # retrieve numpy array\n        yhat = yhat.detach().numpy()\n        actual = targets.numpy()\n        actual = actual.reshape((len(actual), 1))\n        # round to class values\n        yhat = yhat.round()\n        # store\n        predictions.append(yhat)\n        actuals.append(actual)\n    predictions, actuals = np.vstack(predictions), np.vstack(actuals)\n    # calculate accuracy\n    acc = accuracy_score(actuals, predictions)\n    return acc","metadata":{"execution":{"iopub.status.busy":"2023-04-25T06:41:20.351114Z","iopub.execute_input":"2023-04-25T06:41:20.351754Z","iopub.status.idle":"2023-04-25T06:41:20.359528Z","shell.execute_reply.started":"2023-04-25T06:41:20.351718Z","shell.execute_reply":"2023-04-25T06:41:20.358092Z"},"trusted":true},"execution_count":103,"outputs":[]},{"cell_type":"code","source":"# make a class prediction for one row of data\ndef predict(row, model):\n    # convert row to data\n    row = torch.Tensor([row])\n    # make prediction\n    yhat = model(row)\n    # retrieve numpy array\n    yhat = yhat.detach().numpy()\n    return yhat","metadata":{"execution":{"iopub.status.busy":"2023-04-25T06:41:20.852434Z","iopub.execute_input":"2023-04-25T06:41:20.853183Z","iopub.status.idle":"2023-04-25T06:41:20.860066Z","shell.execute_reply.started":"2023-04-25T06:41:20.853128Z","shell.execute_reply":"2023-04-25T06:41:20.858864Z"},"trusted":true},"execution_count":104,"outputs":[]},{"cell_type":"code","source":"ROOT_PATH='/kaggle/input/playground-series-s3e13'\npath = ROOT_PATH+'/train.csv'\ntrain_dl, test_dl = prepare_data(path)","metadata":{"execution":{"iopub.status.busy":"2023-04-25T06:41:21.489974Z","iopub.execute_input":"2023-04-25T06:41:21.49043Z","iopub.status.idle":"2023-04-25T06:41:21.5173Z","shell.execute_reply.started":"2023-04-25T06:41:21.490385Z","shell.execute_reply":"2023-04-25T06:41:21.515976Z"},"trusted":true},"execution_count":105,"outputs":[]},{"cell_type":"code","source":"print(len(train_dl.dataset), len(test_dl.dataset))","metadata":{"execution":{"iopub.status.busy":"2023-04-25T06:41:22.903921Z","iopub.execute_input":"2023-04-25T06:41:22.904405Z","iopub.status.idle":"2023-04-25T06:41:22.910457Z","shell.execute_reply.started":"2023-04-25T06:41:22.904361Z","shell.execute_reply":"2023-04-25T06:41:22.909041Z"},"trusted":true},"execution_count":106,"outputs":[{"name":"stdout","text":"474 233\n","output_type":"stream"}]},{"cell_type":"code","source":"# define the network\nmodel = MLP(64)","metadata":{"execution":{"iopub.status.busy":"2023-04-25T06:41:26.695316Z","iopub.execute_input":"2023-04-25T06:41:26.695879Z","iopub.status.idle":"2023-04-25T06:41:26.702344Z","shell.execute_reply.started":"2023-04-25T06:41:26.695829Z","shell.execute_reply":"2023-04-25T06:41:26.700917Z"},"trusted":true},"execution_count":107,"outputs":[]},{"cell_type":"code","source":"# train the model\ntrain_model(train_dl, model)","metadata":{"execution":{"iopub.status.busy":"2023-04-25T06:41:27.3791Z","iopub.execute_input":"2023-04-25T06:41:27.379534Z","iopub.status.idle":"2023-04-25T06:41:28.985382Z","shell.execute_reply.started":"2023-04-25T06:41:27.379495Z","shell.execute_reply":"2023-04-25T06:41:28.984137Z"},"trusted":true},"execution_count":108,"outputs":[]},{"cell_type":"code","source":"# evaluate the model\nacc = evaluate_model(test_dl, model)\nprint('Accuracy: %.3f' % acc)","metadata":{"execution":{"iopub.status.busy":"2023-04-25T06:41:44.031917Z","iopub.execute_input":"2023-04-25T06:41:44.032361Z","iopub.status.idle":"2023-04-25T06:41:44.045364Z","shell.execute_reply.started":"2023-04-25T06:41:44.032313Z","shell.execute_reply":"2023-04-25T06:41:44.044092Z"},"trusted":true},"execution_count":109,"outputs":[{"name":"stdout","text":"Accuracy: 0.082\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}