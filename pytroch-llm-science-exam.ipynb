{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/averma111/pytroch-llm-science-exam?scriptVersionId=138026597\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom tqdm.notebook import tqdm\nfrom transformers import AutoTokenizer , AutoModel\nimport torch\nfrom IPython.display import IFrame\n\nimport warnings\nwarnings.filterwarnings('ignore')\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \n ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-07-27T03:18:24.406163Z","iopub.execute_input":"2023-07-27T03:18:24.406524Z","iopub.status.idle":"2023-07-27T03:18:24.415074Z","shell.execute_reply.started":"2023-07-27T03:18:24.406496Z","shell.execute_reply":"2023-07-27T03:18:24.414105Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"/kaggle/input/kaggle-llm-science-exam/sample_submission.csv\n/kaggle/input/kaggle-llm-science-exam/train.csv\n/kaggle/input/kaggle-llm-science-exam/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"class DataAcquisition:\n    \n    def __init__(self):\n        pass\n    \n    def prepare_data(self):\n        path = '/kaggle/input/kaggle-llm-science-exam/train.csv'\n        df = pd.read_csv(\n            path, \n            sep=',', \n            low_memory=False\n        )\n        \n        X = df.copy()\n        return X\n    \n    def prepare_data_test(self):\n        path = '/kaggle/input/kaggle-llm-science-exam/test.csv'\n        df = pd.read_csv(\n            path, \n            sep=',', \n            low_memory=False\n        )\n        \n        X = df.copy()\n        return X\n    \n    \n    def new_features(self,df):\n        pass\n    \n    \n    \n    def preprocessing(self,df):\n        for idx in tqdm(range(df.shape[0]) , total = df.shape[0]):\n            df[\"answer\"][idx] = df[df[\"answer\"][idx]][idx]\n        return df\n        \n    def preprocessing_test(self,df):\n        for idx in tqdm(range(df.shape[0]) , total = df.shape[0]):\n            df[\"answer\"][idx] = df[df[\"answer\"][idx]][idx]\n        return df\n    \n        \nacq = DataAcquisition()\n\ntrain_df = acq.prepare_data()\ntest_df = acq.prepare_data_test()","metadata":{"execution":{"iopub.status.busy":"2023-07-27T03:18:24.416696Z","iopub.execute_input":"2023-07-27T03:18:24.417597Z","iopub.status.idle":"2023-07-27T03:18:24.442794Z","shell.execute_reply.started":"2023-07-27T03:18:24.417555Z","shell.execute_reply":"2023-07-27T03:18:24.441941Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-07-27T03:18:24.446302Z","iopub.execute_input":"2023-07-27T03:18:24.446555Z","iopub.status.idle":"2023-07-27T03:18:24.45841Z","shell.execute_reply.started":"2023-07-27T03:18:24.446532Z","shell.execute_reply":"2023-07-27T03:18:24.457549Z"},"trusted":true},"execution_count":42,"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"   id                                             prompt  \\\n0   0  Which of the following statements accurately d...   \n1   1  Which of the following is an accurate definiti...   \n2   2  Which of the following statements accurately d...   \n3   3  What is the significance of regularization in ...   \n4   4  Which of the following statements accurately d...   \n\n                                                   A  \\\n0  MOND is a theory that reduces the observed mis...   \n1  Dynamic scaling refers to the evolution of sel...   \n2  The triskeles symbol was reconstructed as a fe...   \n3  Regularizing the mass-energy of an electron wi...   \n4  The angular spacing of features in the diffrac...   \n\n                                                   B  \\\n0  MOND is a theory that increases the discrepanc...   \n1  Dynamic scaling refers to the non-evolution of...   \n2  The triskeles symbol is a representation of th...   \n3  Regularizing the mass-energy of an electron wi...   \n4  The angular spacing of features in the diffrac...   \n\n                                                   C  \\\n0  MOND is a theory that explains the missing bar...   \n1  Dynamic scaling refers to the evolution of sel...   \n2  The triskeles symbol is a representation of a ...   \n3  Regularizing the mass-energy of an electron wi...   \n4  The angular spacing of features in the diffrac...   \n\n                                                   D  \\\n0  MOND is a theory that reduces the discrepancy ...   \n1  Dynamic scaling refers to the non-evolution of...   \n2  The triskeles symbol represents three interloc...   \n3  Regularizing the mass-energy of an electron wi...   \n4  The angular spacing of features in the diffrac...   \n\n                                                   E answer  \n0  MOND is a theory that eliminates the observed ...      D  \n1  Dynamic scaling refers to the evolution of sel...      A  \n2  The triskeles symbol is a representation of th...      A  \n3  Regularizing the mass-energy of an electron wi...      C  \n4  The angular spacing of features in the diffrac...      D  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>prompt</th>\n      <th>A</th>\n      <th>B</th>\n      <th>C</th>\n      <th>D</th>\n      <th>E</th>\n      <th>answer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Which of the following statements accurately d...</td>\n      <td>MOND is a theory that reduces the observed mis...</td>\n      <td>MOND is a theory that increases the discrepanc...</td>\n      <td>MOND is a theory that explains the missing bar...</td>\n      <td>MOND is a theory that reduces the discrepancy ...</td>\n      <td>MOND is a theory that eliminates the observed ...</td>\n      <td>D</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Which of the following is an accurate definiti...</td>\n      <td>Dynamic scaling refers to the evolution of sel...</td>\n      <td>Dynamic scaling refers to the non-evolution of...</td>\n      <td>Dynamic scaling refers to the evolution of sel...</td>\n      <td>Dynamic scaling refers to the non-evolution of...</td>\n      <td>Dynamic scaling refers to the evolution of sel...</td>\n      <td>A</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Which of the following statements accurately d...</td>\n      <td>The triskeles symbol was reconstructed as a fe...</td>\n      <td>The triskeles symbol is a representation of th...</td>\n      <td>The triskeles symbol is a representation of a ...</td>\n      <td>The triskeles symbol represents three interloc...</td>\n      <td>The triskeles symbol is a representation of th...</td>\n      <td>A</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>What is the significance of regularization in ...</td>\n      <td>Regularizing the mass-energy of an electron wi...</td>\n      <td>Regularizing the mass-energy of an electron wi...</td>\n      <td>Regularizing the mass-energy of an electron wi...</td>\n      <td>Regularizing the mass-energy of an electron wi...</td>\n      <td>Regularizing the mass-energy of an electron wi...</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>Which of the following statements accurately d...</td>\n      <td>The angular spacing of features in the diffrac...</td>\n      <td>The angular spacing of features in the diffrac...</td>\n      <td>The angular spacing of features in the diffrac...</td>\n      <td>The angular spacing of features in the diffrac...</td>\n      <td>The angular spacing of features in the diffrac...</td>\n      <td>D</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_df=acq.preprocessing(train_df)\ntrain_df.drop([\"id\" , \"A\" , \"B\" , \"C\" , \"D\" , \"E\"] , axis = 1 , inplace = True)\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-07-27T03:18:24.459633Z","iopub.execute_input":"2023-07-27T03:18:24.460787Z","iopub.status.idle":"2023-07-27T03:18:24.555681Z","shell.execute_reply.started":"2023-07-27T03:18:24.460713Z","shell.execute_reply":"2023-07-27T03:18:24.554671Z"},"trusted":true},"execution_count":43,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"73dfbac8fdbe428491fecc0cb9f4d783"}},"metadata":{}},{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"                                              prompt  \\\n0  Which of the following statements accurately d...   \n1  Which of the following is an accurate definiti...   \n2  Which of the following statements accurately d...   \n3  What is the significance of regularization in ...   \n4  Which of the following statements accurately d...   \n\n                                              answer  \n0  MOND is a theory that reduces the discrepancy ...  \n1  Dynamic scaling refers to the evolution of sel...  \n2  The triskeles symbol was reconstructed as a fe...  \n3  Regularizing the mass-energy of an electron wi...  \n4  The angular spacing of features in the diffrac...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prompt</th>\n      <th>answer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Which of the following statements accurately d...</td>\n      <td>MOND is a theory that reduces the discrepancy ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Which of the following is an accurate definiti...</td>\n      <td>Dynamic scaling refers to the evolution of sel...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Which of the following statements accurately d...</td>\n      <td>The triskeles symbol was reconstructed as a fe...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>What is the significance of regularization in ...</td>\n      <td>Regularizing the mass-energy of an electron wi...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Which of the following statements accurately d...</td>\n      <td>The angular spacing of features in the diffrac...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"models_dict= {\n    #'rbl':'roberta-large',\n    #'abv2':'albert-base-v2',\n    #'msd':'microsoft/deberta-base',\n    #'ggl':'google/electra-medium-discriminator',\n    #'fb':'facebook/bart-base'\n}","metadata":{"execution":{"iopub.status.busy":"2023-07-27T03:18:24.558062Z","iopub.execute_input":"2023-07-27T03:18:24.558651Z","iopub.status.idle":"2023-07-27T03:18:24.56286Z","shell.execute_reply.started":"2023-07-27T03:18:24.558618Z","shell.execute_reply":"2023-07-27T03:18:24.56184Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"def tokenizer():\n    X = train_df.copy()\n    tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n    model = AutoModel.from_pretrained(\"roberta-base\")\n    for idx in tqdm(range(X.shape[0])):\n        X[\"prompt\"][idx] = tokenizer(X[\"prompt\"][idx] , \n                                       return_tensors = \"pt\")[\"input_ids\"]\n    \n    with torch.no_grad():\n        X[\"answer\"][idx] = model(\n                tokenizer(X[\"answer\"][idx] , \n                return_tensors = \"pt\")[\"input_ids\"])[0][0][0]\n    torch.cuda.empty_cache()\n    return X\n    \n    \nX=tokenizer()","metadata":{"execution":{"iopub.status.busy":"2023-07-27T03:18:24.564328Z","iopub.execute_input":"2023-07-27T03:18:24.56484Z","iopub.status.idle":"2023-07-27T03:18:26.683474Z","shell.execute_reply.started":"2023-07-27T03:18:24.564808Z","shell.execute_reply":"2023-07-27T03:18:26.68244Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stderr","text":"Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias']\n- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"15f4298add33425e8fa4d4bfebdb7c18"}},"metadata":{}}]},{"cell_type":"code","source":"class LLMNNBase(torch.nn.Module):\n    \n    def __init__(self,n_neurons):\n        super(LLMNNBase, self).__init__()\n        self.model_type = AutoModel.from_pretrained(\"roberta-base\")\n\n        self.n_neurons = n_neurons\n        self.linear_1 = torch.nn.Linear(self.n_neurons , self.n_neurons)\n    \n    def forward(self, inputs):\n        inputs = self.model(inputs)[0]\n        inputs = torch.mean(inputs, axis=1)\n        output = self.linear_1(inputs)\n\n        return output\n    \n    \nllmb = LLMNNBase(768)","metadata":{"execution":{"iopub.status.busy":"2023-07-27T03:18:26.684938Z","iopub.execute_input":"2023-07-27T03:18:26.685718Z","iopub.status.idle":"2023-07-27T03:18:28.012621Z","shell.execute_reply.started":"2023-07-27T03:18:26.685683Z","shell.execute_reply":"2023-07-27T03:18:28.011727Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stderr","text":"Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias']\n- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"optim = torch.optim.Adam(llmb.parameters())\ncriterion = torch.nn.MSELoss()\nlosses = []\nfor x , y in tqdm(zip(X[\"prompt\"] , X[\"answer\"]) , total = X.shape[0]):\n    x = torch.tensor(x , dtype = torch.long).to(\"cuda\")\n    y = torch.tensor(y , dtype = torch.float32).to(\"cuda\")\n    x = x.reshape(shape = (1 , x.shape[0]))\n    if x.shape[1] > 512: x = x[: , :512]\n    pred = llmb(x)[0]\n    loss_fun = criterion(pred , y)\n    losses.append(loss_fun)\n    torch.cuda.empty_cache()\n    optim.step","metadata":{"execution":{"iopub.status.busy":"2023-07-27T03:18:28.013949Z","iopub.execute_input":"2023-07-27T03:18:28.014435Z","iopub.status.idle":"2023-07-27T03:18:28.101335Z","shell.execute_reply.started":"2023-07-27T03:18:28.0144Z","shell.execute_reply":"2023-07-27T03:18:28.099931Z"},"trusted":true},"execution_count":47,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e0dd3eb4ebe5441fbe224423404e9d56"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m6\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 3 \u001b[0mlosses = []                                                                                 \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 4 \u001b[0m\u001b[94mfor\u001b[0m x , y \u001b[95min\u001b[0m tqdm(\u001b[96mzip\u001b[0m(X[\u001b[33m\"\u001b[0m\u001b[33mprompt\u001b[0m\u001b[33m\"\u001b[0m] , X[\u001b[33m\"\u001b[0m\u001b[33manswer\u001b[0m\u001b[33m\"\u001b[0m]) , total = X.shape[\u001b[94m0\u001b[0m]):                     \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 5 \u001b[0m\u001b[2m│   \u001b[0mx = torch.tensor(x , dtype = torch.long).to(\u001b[33m\"\u001b[0m\u001b[33mcuda\u001b[0m\u001b[33m\"\u001b[0m)                                     \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 6 \u001b[2m│   \u001b[0my = torch.tensor(y , dtype = torch.float32).to(\u001b[33m\"\u001b[0m\u001b[33mcuda\u001b[0m\u001b[33m\"\u001b[0m)                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 7 \u001b[0m\u001b[2m│   \u001b[0mx = x.reshape(shape = (\u001b[94m1\u001b[0m , x.shape[\u001b[94m0\u001b[0m]))                                                 \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 8 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m x.shape[\u001b[94m1\u001b[0m] > \u001b[94m512\u001b[0m: x = x[: , :\u001b[94m512\u001b[0m]                                                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 9 \u001b[0m\u001b[2m│   \u001b[0mpred = llmb(x)[\u001b[94m0\u001b[0m]                                                                       \u001b[31m│\u001b[0m\n\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n\u001b[1;91mTypeError: \u001b[0m\u001b[1;35mnew\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m: invalid data type \u001b[32m'str'\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">6</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>losses = []                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> x , y <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> tqdm(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">zip</span>(X[<span style=\"color: #808000; text-decoration-color: #808000\">\"prompt\"</span>] , X[<span style=\"color: #808000; text-decoration-color: #808000\">\"answer\"</span>]) , total = X.shape[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>]):                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>x = torch.tensor(x , dtype = torch.long).to(<span style=\"color: #808000; text-decoration-color: #808000\">\"cuda\"</span>)                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 6 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>y = torch.tensor(y , dtype = torch.float32).to(<span style=\"color: #808000; text-decoration-color: #808000\">\"cuda\"</span>)                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 7 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>x = x.reshape(shape = (<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span> , x.shape[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>]))                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 8 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> x.shape[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>] &gt; <span style=\"color: #0000ff; text-decoration-color: #0000ff\">512</span>: x = x[: , :<span style=\"color: #0000ff; text-decoration-color: #0000ff\">512</span>]                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 9 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>pred = llmb(x)[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>]                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">TypeError: </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">new</span><span style=\"font-weight: bold\">()</span>: invalid data type <span style=\"color: #008000; text-decoration-color: #008000\">'str'</span>\n</pre>\n"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}