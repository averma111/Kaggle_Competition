{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/averma111/autogluon-pss3e18?scriptVersionId=135189469\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"%%capture\n!pip install autogluon\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-06-28T23:01:57.441594Z","iopub.execute_input":"2023-06-28T23:01:57.442383Z","iopub.status.idle":"2023-06-28T23:05:50.269487Z","shell.execute_reply.started":"2023-06-28T23:01:57.442344Z","shell.execute_reply":"2023-06-28T23:05:50.267215Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting autogluon\n  Downloading autogluon-0.8.0-py3-none-any.whl (9.7 kB)\nCollecting autogluon.core[all]==0.8.0 (from autogluon)\n  Downloading autogluon.core-0.8.0-py3-none-any.whl (224 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.2/224.2 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting autogluon.features==0.8.0 (from autogluon)\n  Downloading autogluon.features-0.8.0-py3-none-any.whl (61 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.9/61.9 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting autogluon.tabular[all]==0.8.0 (from autogluon)\n  Downloading autogluon.tabular-0.8.0-py3-none-any.whl (285 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m285.6/285.6 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting autogluon.multimodal==0.8.0 (from autogluon)\n  Downloading autogluon.multimodal-0.8.0-py3-none-any.whl (372 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m372.2/372.2 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting autogluon.timeseries[all]==0.8.0 (from autogluon)\n  Downloading autogluon.timeseries-0.8.0-py3-none-any.whl (116 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.2/116.2 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy<1.27,>=1.21 in /opt/conda/lib/python3.10/site-packages (from autogluon.core[all]==0.8.0->autogluon) (1.23.5)\nRequirement already satisfied: scipy<1.12,>=1.5.4 in /opt/conda/lib/python3.10/site-packages (from autogluon.core[all]==0.8.0->autogluon) (1.10.1)\nRequirement already satisfied: scikit-learn<1.3,>=1.0 in /opt/conda/lib/python3.10/site-packages (from autogluon.core[all]==0.8.0->autogluon) (1.2.2)\nRequirement already satisfied: networkx<4,>=3.0 in /opt/conda/lib/python3.10/site-packages (from autogluon.core[all]==0.8.0->autogluon) (3.1)\nRequirement already satisfied: pandas<1.6,>=1.4.1 in /opt/conda/lib/python3.10/site-packages (from autogluon.core[all]==0.8.0->autogluon) (1.5.3)\nRequirement already satisfied: tqdm<5,>=4.38 in /opt/conda/lib/python3.10/site-packages (from autogluon.core[all]==0.8.0->autogluon) (4.64.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from autogluon.core[all]==0.8.0->autogluon) (2.28.2)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from autogluon.core[all]==0.8.0->autogluon) (3.6.3)\nRequirement already satisfied: boto3<2,>=1.10 in /opt/conda/lib/python3.10/site-packages (from autogluon.core[all]==0.8.0->autogluon) (1.26.100)\nCollecting autogluon.common==0.8.0 (from autogluon.core[all]==0.8.0->autogluon)\n  Downloading autogluon.common-0.8.0-py3-none-any.whl (61 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: hyperopt<0.2.8,>=0.2.7 in /opt/conda/lib/python3.10/site-packages (from autogluon.core[all]==0.8.0->autogluon) (0.2.7)\nCollecting ray[tune]<2.4,>=2.3 (from autogluon.core[all]==0.8.0->autogluon)\n  Downloading ray-2.3.1-cp310-cp310-manylinux2014_x86_64.whl (58.5 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.5/58.5 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: Pillow<9.6,>=9.3 in /opt/conda/lib/python3.10/site-packages (from autogluon.multimodal==0.8.0->autogluon) (9.5.0)\nRequirement already satisfied: jsonschema<4.18,>=4.14 in /opt/conda/lib/python3.10/site-packages (from autogluon.multimodal==0.8.0->autogluon) (4.17.3)\nCollecting seqeval<1.3.0,>=1.2.2 (from autogluon.multimodal==0.8.0->autogluon)\n  Downloading seqeval-1.2.2.tar.gz (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting evaluate<0.4.0,>=0.2.2 (from autogluon.multimodal==0.8.0->autogluon)\n  Downloading evaluate-0.3.0-py3-none-any.whl (72 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.9/72.9 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: accelerate<0.17,>=0.9 in /opt/conda/lib/python3.10/site-packages (from autogluon.multimodal==0.8.0->autogluon) (0.12.0)\nRequirement already satisfied: timm<0.10.0,>=0.9.2 in /opt/conda/lib/python3.10/site-packages (from autogluon.multimodal==0.8.0->autogluon) (0.9.2)\nCollecting torch<1.14,>=1.9 (from autogluon.multimodal==0.8.0->autogluon)\n  Downloading torch-1.13.1-cp310-cp310-manylinux1_x86_64.whl (887.5 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m887.5/887.5 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting torchvision<0.15.0 (from autogluon.multimodal==0.8.0->autogluon)\n  Downloading torchvision-0.14.1-cp310-cp310-manylinux1_x86_64.whl (24.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.2/24.2 MB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting fairscale<0.4.14,>=0.4.5 (from autogluon.multimodal==0.8.0->autogluon)\n  Downloading fairscale-0.4.13.tar.gz (266 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.3/266.3 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hCollecting scikit-image<0.20.0,>=0.19.1 (from autogluon.multimodal==0.8.0->autogluon)\n  Downloading scikit_image-0.19.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.9 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.9/13.9 MB\u001b[0m \u001b[31m51.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting pytorch-lightning<1.10.0,>=1.9.0 (from autogluon.multimodal==0.8.0->autogluon)\n  Downloading pytorch_lightning-1.9.5-py3-none-any.whl (829 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m829.5/829.5 kB\u001b[0m \u001b[31m40.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: text-unidecode<1.4,>=1.3 in /opt/conda/lib/python3.10/site-packages (from autogluon.multimodal==0.8.0->autogluon) (1.3)\nRequirement already satisfied: torchmetrics<0.12.0,>=0.11.0 in /opt/conda/lib/python3.10/site-packages (from autogluon.multimodal==0.8.0->autogluon) (0.11.4)\nCollecting transformers<4.27.0,>=4.23.0 (from autogluon.multimodal==0.8.0->autogluon)\n  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m78.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nptyping<2.5.0,>=1.4.4 (from autogluon.multimodal==0.8.0->autogluon)\n  Downloading nptyping-2.4.1-py3-none-any.whl (36 kB)\nCollecting omegaconf<2.3.0,>=2.1.1 (from autogluon.multimodal==0.8.0->autogluon)\n  Downloading omegaconf-2.2.3-py3-none-any.whl (79 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.3/79.3 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: sentencepiece<0.2.0,>=0.1.95 in /opt/conda/lib/python3.10/site-packages (from autogluon.multimodal==0.8.0->autogluon) (0.1.99)\nCollecting pytorch-metric-learning<2.0,>=1.3.0 (from autogluon.multimodal==0.8.0->autogluon)\n  Downloading pytorch_metric_learning-1.7.3-py3-none-any.whl (112 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.2/112.2 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting nlpaug<1.2.0,>=1.1.10 (from autogluon.multimodal==0.8.0->autogluon)\n  Downloading nlpaug-1.1.11-py3-none-any.whl (410 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.5/410.5 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting nltk<4.0.0,>=3.4.5 (from autogluon.multimodal==0.8.0->autogluon)\n  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting openmim<0.4.0,>=0.3.7 (from autogluon.multimodal==0.8.0->autogluon)\n  Downloading openmim-0.3.9-py2.py3-none-any.whl (52 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: defusedxml<0.7.2,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from autogluon.multimodal==0.8.0->autogluon) (0.7.1)\nRequirement already satisfied: jinja2<3.2,>=3.0.3 in /opt/conda/lib/python3.10/site-packages (from autogluon.multimodal==0.8.0->autogluon) (3.1.2)\nRequirement already satisfied: tensorboard<3,>=2.9 in /opt/conda/lib/python3.10/site-packages (from autogluon.multimodal==0.8.0->autogluon) (2.12.3)\nRequirement already satisfied: pytesseract<0.3.11,>=0.3.9 in /opt/conda/lib/python3.10/site-packages (from autogluon.multimodal==0.8.0->autogluon) (0.3.10)\nCollecting PyMuPDF<=1.21.1 (from autogluon.multimodal==0.8.0->autogluon)\n  Downloading PyMuPDF-1.21.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: xgboost<1.8,>=1.6 in /opt/conda/lib/python3.10/site-packages (from autogluon.tabular[all]==0.8.0->autogluon) (1.7.5)\nRequirement already satisfied: lightgbm<3.4,>=3.3 in /opt/conda/lib/python3.10/site-packages (from autogluon.tabular[all]==0.8.0->autogluon) (3.3.2)\nRequirement already satisfied: catboost<1.3,>=1.1 in /opt/conda/lib/python3.10/site-packages (from autogluon.tabular[all]==0.8.0->autogluon) (1.2)\nRequirement already satisfied: fastai<2.8,>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from autogluon.tabular[all]==0.8.0->autogluon) (2.7.12)\nRequirement already satisfied: joblib<2,>=1.1 in /opt/conda/lib/python3.10/site-packages (from autogluon.timeseries[all]==0.8.0->autogluon) (1.2.0)\nRequirement already satisfied: statsmodels<0.15,>=0.13.0 in /opt/conda/lib/python3.10/site-packages (from autogluon.timeseries[all]==0.8.0->autogluon) (0.13.5)\nCollecting gluonts<0.14,>=0.13.1 (from autogluon.timeseries[all]==0.8.0->autogluon)\n  Downloading gluonts-0.13.2-py3-none-any.whl (1.5 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m56.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting statsforecast<1.5,>=1.4.0 (from autogluon.timeseries[all]==0.8.0->autogluon)\n  Downloading statsforecast-1.4.0-py3-none-any.whl (91 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting mlforecast<0.7.4,>=0.7.0 (from autogluon.timeseries[all]==0.8.0->autogluon)\n  Downloading mlforecast-0.7.3-py3-none-any.whl (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: ujson<6,>=5 in /opt/conda/lib/python3.10/site-packages (from autogluon.timeseries[all]==0.8.0->autogluon) (5.8.0)\nRequirement already satisfied: psutil<6,>=5.7.3 in /opt/conda/lib/python3.10/site-packages (from autogluon.common==0.8.0->autogluon.core[all]==0.8.0->autogluon) (5.9.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from autogluon.common==0.8.0->autogluon.core[all]==0.8.0->autogluon) (59.8.0)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate<0.17,>=0.9->autogluon.multimodal==0.8.0->autogluon) (21.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate<0.17,>=0.9->autogluon.multimodal==0.8.0->autogluon) (5.4.1)\nCollecting botocore<1.30.0,>=1.29.100 (from boto3<2,>=1.10->autogluon.core[all]==0.8.0->autogluon)\n  Downloading botocore-1.29.163-py3-none-any.whl (11.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m76.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from boto3<2,>=1.10->autogluon.core[all]==0.8.0->autogluon) (1.0.1)\nRequirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from boto3<2,>=1.10->autogluon.core[all]==0.8.0->autogluon) (0.6.1)\nRequirement already satisfied: graphviz in /opt/conda/lib/python3.10/site-packages (from catboost<1.3,>=1.1->autogluon.tabular[all]==0.8.0->autogluon) (0.20.1)\nRequirement already satisfied: plotly in /opt/conda/lib/python3.10/site-packages (from catboost<1.3,>=1.1->autogluon.tabular[all]==0.8.0->autogluon) (5.14.1)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from catboost<1.3,>=1.1->autogluon.tabular[all]==0.8.0->autogluon) (1.16.0)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate<0.4.0,>=0.2.2->autogluon.multimodal==0.8.0->autogluon) (2.1.0)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate<0.4.0,>=0.2.2->autogluon.multimodal==0.8.0->autogluon) (0.3.6)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate<0.4.0,>=0.2.2->autogluon.multimodal==0.8.0->autogluon) (3.2.0)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate<0.4.0,>=0.2.2->autogluon.multimodal==0.8.0->autogluon) (0.70.14)\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from evaluate<0.4.0,>=0.2.2->autogluon.multimodal==0.8.0->autogluon) (2023.6.0)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate<0.4.0,>=0.2.2->autogluon.multimodal==0.8.0->autogluon) (0.15.1)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from evaluate<0.4.0,>=0.2.2->autogluon.multimodal==0.8.0->autogluon) (0.18.0)\nRequirement already satisfied: pip in /opt/conda/lib/python3.10/site-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.8.0->autogluon) (23.1.2)\nRequirement already satisfied: fastdownload<2,>=0.0.5 in /opt/conda/lib/python3.10/site-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.8.0->autogluon) (0.0.7)\nRequirement already satisfied: fastcore<1.6,>=1.5.29 in /opt/conda/lib/python3.10/site-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.8.0->autogluon) (1.5.29)\nRequirement already satisfied: fastprogress>=0.2.4 in /opt/conda/lib/python3.10/site-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.8.0->autogluon) (1.0.3)\nRequirement already satisfied: spacy<4 in /opt/conda/lib/python3.10/site-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.8.0->autogluon) (3.5.3)\nRequirement already satisfied: pydantic~=1.7 in /opt/conda/lib/python3.10/site-packages (from gluonts<0.14,>=0.13.1->autogluon.timeseries[all]==0.8.0->autogluon) (1.10.7)\nRequirement already satisfied: toolz~=0.10 in /opt/conda/lib/python3.10/site-packages (from gluonts<0.14,>=0.13.1->autogluon.timeseries[all]==0.8.0->autogluon) (0.12.0)\nRequirement already satisfied: typing-extensions~=4.0 in /opt/conda/lib/python3.10/site-packages (from gluonts<0.14,>=0.13.1->autogluon.timeseries[all]==0.8.0->autogluon) (4.5.0)\nRequirement already satisfied: future in /opt/conda/lib/python3.10/site-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==0.8.0->autogluon) (0.18.3)\nRequirement already satisfied: cloudpickle in /opt/conda/lib/python3.10/site-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==0.8.0->autogluon) (2.2.1)\nRequirement already satisfied: py4j in /opt/conda/lib/python3.10/site-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==0.8.0->autogluon) (0.10.9.7)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2<3.2,>=3.0.3->autogluon.multimodal==0.8.0->autogluon) (2.1.2)\nRequirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema<4.18,>=4.14->autogluon.multimodal==0.8.0->autogluon) (23.1.0)\nRequirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema<4.18,>=4.14->autogluon.multimodal==0.8.0->autogluon) (0.19.3)\nRequirement already satisfied: wheel in /opt/conda/lib/python3.10/site-packages (from lightgbm<3.4,>=3.3->autogluon.tabular[all]==0.8.0->autogluon) (0.40.0)\nRequirement already satisfied: numba in /opt/conda/lib/python3.10/site-packages (from mlforecast<0.7.4,>=0.7.0->autogluon.timeseries[all]==0.8.0->autogluon) (0.57.0)\nCollecting window-ops (from mlforecast<0.7.4,>=0.7.0->autogluon.timeseries[all]==0.8.0->autogluon)\n  Downloading window_ops-0.0.14-py3-none-any.whl (14 kB)\nCollecting gdown>=4.0.0 (from nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==0.8.0->autogluon)\n  Downloading gdown-4.7.1-py3-none-any.whl (15 kB)\nRequirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk<4.0.0,>=3.4.5->autogluon.multimodal==0.8.0->autogluon) (8.1.3)\nRequirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.10/site-packages (from nltk<4.0.0,>=3.4.5->autogluon.multimodal==0.8.0->autogluon) (2023.5.5)\nCollecting antlr4-python3-runtime==4.9.* (from omegaconf<2.3.0,>=2.1.1->autogluon.multimodal==0.8.0->autogluon)\n  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==0.8.0->autogluon) (0.4.6)\nCollecting model-index (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==0.8.0->autogluon)\n  Downloading model_index-0.1.11-py3-none-any.whl (34 kB)\nCollecting opendatalab (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==0.8.0->autogluon)\n  Downloading opendatalab-0.0.9-py3-none-any.whl (29 kB)\nRequirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==0.8.0->autogluon) (13.3.5)\nRequirement already satisfied: tabulate in /opt/conda/lib/python3.10/site-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==0.8.0->autogluon) (0.9.0)\nRequirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas<1.6,>=1.4.1->autogluon.core[all]==0.8.0->autogluon) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas<1.6,>=1.4.1->autogluon.core[all]==0.8.0->autogluon) (2023.3)\nRequirement already satisfied: lightning-utilities>=0.6.0.post0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning<1.10.0,>=1.9.0->autogluon.multimodal==0.8.0->autogluon) (0.8.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from ray[tune]<2.4,>=2.3->autogluon.core[all]==0.8.0->autogluon) (3.12.0)\nRequirement already satisfied: msgpack<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from ray[tune]<2.4,>=2.3->autogluon.core[all]==0.8.0->autogluon) (1.0.5)\nRequirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /opt/conda/lib/python3.10/site-packages (from ray[tune]<2.4,>=2.3->autogluon.core[all]==0.8.0->autogluon) (3.20.3)\nRequirement already satisfied: aiosignal in /opt/conda/lib/python3.10/site-packages (from ray[tune]<2.4,>=2.3->autogluon.core[all]==0.8.0->autogluon) (1.3.1)\nRequirement already satisfied: frozenlist in /opt/conda/lib/python3.10/site-packages (from ray[tune]<2.4,>=2.3->autogluon.core[all]==0.8.0->autogluon) (1.3.3)\nRequirement already satisfied: virtualenv>=20.0.24 in /opt/conda/lib/python3.10/site-packages (from ray[tune]<2.4,>=2.3->autogluon.core[all]==0.8.0->autogluon) (20.21.0)\nRequirement already satisfied: grpcio>=1.42.0 in /opt/conda/lib/python3.10/site-packages (from ray[tune]<2.4,>=2.3->autogluon.core[all]==0.8.0->autogluon) (1.51.3)\nRequirement already satisfied: aiohttp>=3.7 in /opt/conda/lib/python3.10/site-packages (from ray[tune]<2.4,>=2.3->autogluon.core[all]==0.8.0->autogluon) (3.8.4)\nRequirement already satisfied: aiohttp-cors in /opt/conda/lib/python3.10/site-packages (from ray[tune]<2.4,>=2.3->autogluon.core[all]==0.8.0->autogluon) (0.7.0)\nRequirement already satisfied: colorful in /opt/conda/lib/python3.10/site-packages (from ray[tune]<2.4,>=2.3->autogluon.core[all]==0.8.0->autogluon) (0.5.5)\nRequirement already satisfied: py-spy>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from ray[tune]<2.4,>=2.3->autogluon.core[all]==0.8.0->autogluon) (0.3.14)\nRequirement already satisfied: gpustat>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from ray[tune]<2.4,>=2.3->autogluon.core[all]==0.8.0->autogluon) (1.0.0)\nRequirement already satisfied: opencensus in /opt/conda/lib/python3.10/site-packages (from ray[tune]<2.4,>=2.3->autogluon.core[all]==0.8.0->autogluon) (0.11.2)\nRequirement already satisfied: prometheus-client>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from ray[tune]<2.4,>=2.3->autogluon.core[all]==0.8.0->autogluon) (0.16.0)\nRequirement already satisfied: smart-open in /opt/conda/lib/python3.10/site-packages (from ray[tune]<2.4,>=2.3->autogluon.core[all]==0.8.0->autogluon) (6.3.0)\nRequirement already satisfied: tensorboardX>=1.9 in /opt/conda/lib/python3.10/site-packages (from ray[tune]<2.4,>=2.3->autogluon.core[all]==0.8.0->autogluon) (2.6)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->autogluon.core[all]==0.8.0->autogluon) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->autogluon.core[all]==0.8.0->autogluon) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->autogluon.core[all]==0.8.0->autogluon) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->autogluon.core[all]==0.8.0->autogluon) (2023.5.7)\nRequirement already satisfied: imageio>=2.4.1 in /opt/conda/lib/python3.10/site-packages (from scikit-image<0.20.0,>=0.19.1->autogluon.multimodal==0.8.0->autogluon) (2.28.1)\nRequirement already satisfied: tifffile>=2019.7.26 in /opt/conda/lib/python3.10/site-packages (from scikit-image<0.20.0,>=0.19.1->autogluon.multimodal==0.8.0->autogluon) (2023.4.12)\nRequirement already satisfied: PyWavelets>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-image<0.20.0,>=0.19.1->autogluon.multimodal==0.8.0->autogluon) (1.4.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn<1.3,>=1.0->autogluon.core[all]==0.8.0->autogluon) (3.1.0)\nRequirement already satisfied: patsy>=0.5.2 in /opt/conda/lib/python3.10/site-packages (from statsmodels<0.15,>=0.13.0->autogluon.timeseries[all]==0.8.0->autogluon) (0.5.3)\nRequirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.10/site-packages (from tensorboard<3,>=2.9->autogluon.multimodal==0.8.0->autogluon) (1.4.0)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<3,>=2.9->autogluon.multimodal==0.8.0->autogluon) (2.17.3)\nRequirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<3,>=2.9->autogluon.multimodal==0.8.0->autogluon) (1.0.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<3,>=2.9->autogluon.multimodal==0.8.0->autogluon) (3.4.3)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<3,>=2.9->autogluon.multimodal==0.8.0->autogluon) (0.7.0)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<3,>=2.9->autogluon.multimodal==0.8.0->autogluon) (2.3.6)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from timm<0.10.0,>=0.9.2->autogluon.multimodal==0.8.0->autogluon) (0.3.1)\nCollecting nvidia-cuda-runtime-cu11==11.7.99 (from torch<1.14,>=1.9->autogluon.multimodal==0.8.0->autogluon)\n  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96 (from torch<1.14,>=1.9->autogluon.multimodal==0.8.0->autogluon)\n  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66 (from torch<1.14,>=1.9->autogluon.multimodal==0.8.0->autogluon)\n  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch<1.14,>=1.9->autogluon.multimodal==0.8.0->autogluon)\n  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers<4.27.0,>=4.23.0->autogluon.multimodal==0.8.0->autogluon) (0.13.3)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->autogluon.core[all]==0.8.0->autogluon) (1.0.7)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->autogluon.core[all]==0.8.0->autogluon) (0.11.0)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->autogluon.core[all]==0.8.0->autogluon) (4.39.3)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->autogluon.core[all]==0.8.0->autogluon) (1.4.4)\nRequirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->autogluon.core[all]==0.8.0->autogluon) (3.0.9)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp>=3.7->ray[tune]<2.4,>=2.3->autogluon.core[all]==0.8.0->autogluon) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp>=3.7->ray[tune]<2.4,>=2.3->autogluon.core[all]==0.8.0->autogluon) (4.0.2)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp>=3.7->ray[tune]<2.4,>=2.3->autogluon.core[all]==0.8.0->autogluon) (1.9.1)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate<0.4.0,>=0.2.2->autogluon.multimodal==0.8.0->autogluon) (9.0.0)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==0.8.0->autogluon) (4.12.2)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.9->autogluon.multimodal==0.8.0->autogluon) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.9->autogluon.multimodal==0.8.0->autogluon) (0.2.7)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.9->autogluon.multimodal==0.8.0->autogluon) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<3,>=2.9->autogluon.multimodal==0.8.0->autogluon) (1.3.1)\nRequirement already satisfied: nvidia-ml-py<=11.495.46,>=11.450.129 in /opt/conda/lib/python3.10/site-packages (from gpustat>=1.0.0->ray[tune]<2.4,>=2.3->autogluon.core[all]==0.8.0->autogluon) (11.495.46)\nRequirement already satisfied: blessed>=1.17.1 in /opt/conda/lib/python3.10/site-packages (from gpustat>=1.0.0->ray[tune]<2.4,>=2.3->autogluon.core[all]==0.8.0->autogluon) (1.20.0)\nRequirement already satisfied: llvmlite<0.41,>=0.40.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba->mlforecast<0.7.4,>=0.7.0->autogluon.timeseries[all]==0.8.0->autogluon) (0.40.0)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.8.0->autogluon) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.8.0->autogluon) (1.0.4)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.8.0->autogluon) (1.0.9)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.8.0->autogluon) (2.0.7)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.8.0->autogluon) (3.0.8)\nRequirement already satisfied: thinc<8.2.0,>=8.1.8 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.8.0->autogluon) (8.1.10)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.8.0->autogluon) (1.1.2)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.8.0->autogluon) (2.4.6)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.8.0->autogluon) (2.0.8)\nRequirement already satisfied: typer<0.8.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.8.0->autogluon) (0.7.0)\nRequirement already satisfied: pathy>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.8.0->autogluon) (0.10.1)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.8.0->autogluon) (3.3.0)\nRequirement already satisfied: distlib<1,>=0.3.6 in /opt/conda/lib/python3.10/site-packages (from virtualenv>=20.0.24->ray[tune]<2.4,>=2.3->autogluon.core[all]==0.8.0->autogluon) (0.3.6)\nRequirement already satisfied: platformdirs<4,>=2.4 in /opt/conda/lib/python3.10/site-packages (from virtualenv>=20.0.24->ray[tune]<2.4,>=2.3->autogluon.core[all]==0.8.0->autogluon) (3.5.0)\nCollecting ordered-set (from model-index->openmim<0.4.0,>=0.3.7->autogluon.multimodal==0.8.0->autogluon)\n  Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\nRequirement already satisfied: opencensus-context>=0.1.3 in /opt/conda/lib/python3.10/site-packages (from opencensus->ray[tune]<2.4,>=2.3->autogluon.core[all]==0.8.0->autogluon) (0.1.3)\nRequirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from opencensus->ray[tune]<2.4,>=2.3->autogluon.core[all]==0.8.0->autogluon) (1.33.2)\nRequirement already satisfied: pycryptodome in /opt/conda/lib/python3.10/site-packages (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==0.8.0->autogluon) (3.18.0)\nRequirement already satisfied: tenacity>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from plotly->catboost<1.3,>=1.1->autogluon.tabular[all]==0.8.0->autogluon) (8.2.2)\nRequirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==0.8.0->autogluon) (2.2.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==0.8.0->autogluon) (2.15.1)\nRequirement already satisfied: wcwidth>=0.1.4 in /opt/conda/lib/python3.10/site-packages (from blessed>=1.17.1->gpustat>=1.0.0->ray[tune]<2.4,>=2.3->autogluon.core[all]==0.8.0->autogluon) (0.2.6)\nRequirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[tune]<2.4,>=2.3->autogluon.core[all]==0.8.0->autogluon) (1.57.1)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==0.8.0->autogluon) (0.1.2)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<3,>=2.9->autogluon.multimodal==0.8.0->autogluon) (0.4.8)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<3,>=2.9->autogluon.multimodal==0.8.0->autogluon) (3.2.2)\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.8.0->autogluon) (0.7.9)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.8.0->autogluon) (0.0.4)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==0.8.0->autogluon) (2.3.2.post1)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from requests->autogluon.core[all]==0.8.0->autogluon) (1.7.1)\nBuilding wheels for collected packages: fairscale, antlr4-python3-runtime, seqeval\n  Building wheel for fairscale (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for fairscale: filename=fairscale-0.4.13-py3-none-any.whl size=332112 sha256=1729fc38391e56a5459d88fc5610d5a5375f5e5e2299f9edf7dfcd28a0d0d3b3\n  Stored in directory: /root/.cache/pip/wheels/78/a4/c0/fb0a7ef03cff161611c3fa40c6cf898f76e58ec421b88e8cb3\n  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144574 sha256=08f9f9b23abd848e1fc64361ff5794359fc4fb7a1b72491abfb5c1972493fe4d\n  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n  Building wheel for seqeval (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16181 sha256=efff2b7dd8af507387195bd081768b370706ad308aa3bae0fc01e8174f3de19c\n  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\nSuccessfully built fairscale antlr4-python3-runtime seqeval\nInstalling collected packages: antlr4-python3-runtime, PyMuPDF, ordered-set, omegaconf, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cublas-cu11, nptyping, nltk, window-ops, scikit-image, ray, nvidia-cudnn-cu11, model-index, botocore, transformers, torch, seqeval, opendatalab, mlforecast, gluonts, gdown, torchvision, statsforecast, pytorch-metric-learning, openmim, nlpaug, fairscale, pytorch-lightning, evaluate, autogluon.common, autogluon.features, autogluon.core, autogluon.tabular, autogluon.multimodal, autogluon.timeseries, autogluon\n  Attempting uninstall: nltk\n    Found existing installation: nltk 3.2.4\n    Uninstalling nltk-3.2.4:\n      Successfully uninstalled nltk-3.2.4\n  Attempting uninstall: scikit-image\n    Found existing installation: scikit-image 0.20.0\n    Uninstalling scikit-image-0.20.0:\n      Successfully uninstalled scikit-image-0.20.0\n  Attempting uninstall: ray\n    Found existing installation: ray 2.4.0\n    Uninstalling ray-2.4.0:\n      Successfully uninstalled ray-2.4.0\n  Attempting uninstall: botocore\n    Found existing installation: botocore 1.29.76\n    Uninstalling botocore-1.29.76:\n      Successfully uninstalled botocore-1.29.76\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.30.1\n    Uninstalling transformers-4.30.1:\n      Successfully uninstalled transformers-4.30.1\n  Attempting uninstall: torch\n    Found existing installation: torch 2.0.0+cpu\n    Uninstalling torch-2.0.0+cpu:\n      Successfully uninstalled torch-2.0.0+cpu\n  Attempting uninstall: torchvision\n    Found existing installation: torchvision 0.15.1+cpu\n    Uninstalling torchvision-0.15.1+cpu:\n      Successfully uninstalled torchvision-0.15.1+cpu\n  Attempting uninstall: pytorch-lightning\n    Found existing installation: pytorch-lightning 2.0.3\n    Uninstalling pytorch-lightning-2.0.3:\n      Successfully uninstalled pytorch-lightning-2.0.3\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\naiobotocore 2.5.0 requires botocore<1.29.77,>=1.29.76, but you have botocore 1.29.163 which is incompatible.\npreprocessing 0.1.13 requires nltk==3.2.4, but you have nltk 3.8.1 which is incompatible.\ntorchaudio 2.0.1+cpu requires torch==2.0.0, but you have torch 1.13.1 which is incompatible.\ntorchdata 0.6.0 requires torch==2.0.0, but you have torch 1.13.1 which is incompatible.\ntorchtext 0.15.1+cpu requires torch==2.0.0, but you have torch 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed PyMuPDF-1.21.1 antlr4-python3-runtime-4.9.3 autogluon-0.8.0 autogluon.common-0.8.0 autogluon.core-0.8.0 autogluon.features-0.8.0 autogluon.multimodal-0.8.0 autogluon.tabular-0.8.0 autogluon.timeseries-0.8.0 botocore-1.29.163 evaluate-0.3.0 fairscale-0.4.13 gdown-4.7.1 gluonts-0.13.2 mlforecast-0.7.3 model-index-0.1.11 nlpaug-1.1.11 nltk-3.8.1 nptyping-2.4.1 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 omegaconf-2.2.3 opendatalab-0.0.9 openmim-0.3.9 ordered-set-4.1.0 pytorch-lightning-1.9.5 pytorch-metric-learning-1.7.3 ray-2.3.1 scikit-image-0.19.3 seqeval-1.2.2 statsforecast-1.4.0 torch-1.13.1 torchvision-0.14.1 transformers-4.26.1 window-ops-0.0.14\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom tqdm.notebook import tqdm\nimport matplotlib.pyplot as plt\nimport os\n\n\nimport torch\nfrom autogluon.tabular import TabularDataset, TabularPredictor\nimport autogluon\nfrom autogluon.common.utils.utils import setup_outputdir\nfrom autogluon.core.utils.loaders import load_pkl\nfrom autogluon.core.utils.savers import save_pkl\nfrom autogluon.common import space\nimport os.path\n\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder,StandardScaler\n\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\nplt.style.use('fivethirtyeight')\nimport plotly.express as px\n\nimport warnings\nwarnings.filterwarnings('ignore')\nimport itertools","metadata":{"execution":{"iopub.status.busy":"2023-06-28T23:23:26.585313Z","iopub.execute_input":"2023-06-28T23:23:26.58577Z","iopub.status.idle":"2023-06-28T23:23:26.599302Z","shell.execute_reply.started":"2023-06-28T23:23:26.585735Z","shell.execute_reply":"2023-06-28T23:23:26.597929Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"train_data = TabularDataset('/kaggle/input/playground-series-s3e18/train.csv')\nsubsample_size = 14838  # subsample subset of data for faster demo, try setting this to much larger values\ntrain_data = train_data.sample(n=subsample_size, random_state=42)\ntrain_data.drop(columns=['EC3', 'EC4', 'EC5', 'EC6'],axis=1,inplace=True)\ntrain_data.head()","metadata":{"execution":{"iopub.status.busy":"2023-06-28T23:39:00.85582Z","iopub.execute_input":"2023-06-28T23:39:00.856369Z","iopub.status.idle":"2023-06-28T23:39:01.010419Z","shell.execute_reply.started":"2023-06-28T23:39:00.856324Z","shell.execute_reply":"2023-06-28T23:39:01.00899Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stderr","text":"Loaded data from: /kaggle/input/playground-series-s3e18/train.csv | Columns = 38 / 38 | Rows = 14838 -> 14838\n","output_type":"stream"},{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"          id     BertzCT       Chi1     Chi1n     Chi1v     Chi2n     Chi2v  \\\n11988  11988  118.000000   3.060660  2.536175  2.536175  1.640774  1.640774   \n13039  13039  378.018438  10.685872  7.066210  7.066210  6.041834  6.041834   \n13637  13637  277.172776   1.732051  0.682574  1.462072  0.886443  0.886443   \n5537    5537  377.203227  11.265362  9.264697  9.264697  6.445092  6.445092   \n8425    8425  315.695337   5.985416  3.473678  3.473678  2.634453  2.634453   \n\n          Chi3v     Chi4n  EState_VSA1  ...  PEOE_VSA7  PEOE_VSA8  SMR_VSA10  \\\n11988  0.548756  0.182919    17.721856  ...   0.000000   0.000000  11.752550   \n13039  4.039540  2.503411    12.514062  ...   0.000000   0.000000  23.468091   \n13637  0.087310  0.000000    24.415866  ...   0.000000   0.000000  11.938611   \n5537   4.308487  2.706995    42.723899  ...   0.000000   0.000000  17.744066   \n8425   1.507705  0.672861     0.000000  ...  17.696186   6.066367   0.000000   \n\n        SMR_VSA5  SlogP_VSA3  VSA_EState9  fr_COO  fr_COO2  EC1  EC2  \n11988  12.841643    9.589074    33.833333       1        1    1    1  \n13039  24.539800   13.825658    44.000000       0        0    0    1  \n13637  19.262465    9.589074    44.333333       2        2    1    1  \n5537   45.448667   28.250470    64.083333       0        0    0    0  \n8425    6.103966    0.000000    37.166667       0        0    1    1  \n\n[5 rows x 34 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>BertzCT</th>\n      <th>Chi1</th>\n      <th>Chi1n</th>\n      <th>Chi1v</th>\n      <th>Chi2n</th>\n      <th>Chi2v</th>\n      <th>Chi3v</th>\n      <th>Chi4n</th>\n      <th>EState_VSA1</th>\n      <th>...</th>\n      <th>PEOE_VSA7</th>\n      <th>PEOE_VSA8</th>\n      <th>SMR_VSA10</th>\n      <th>SMR_VSA5</th>\n      <th>SlogP_VSA3</th>\n      <th>VSA_EState9</th>\n      <th>fr_COO</th>\n      <th>fr_COO2</th>\n      <th>EC1</th>\n      <th>EC2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>11988</th>\n      <td>11988</td>\n      <td>118.000000</td>\n      <td>3.060660</td>\n      <td>2.536175</td>\n      <td>2.536175</td>\n      <td>1.640774</td>\n      <td>1.640774</td>\n      <td>0.548756</td>\n      <td>0.182919</td>\n      <td>17.721856</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>11.752550</td>\n      <td>12.841643</td>\n      <td>9.589074</td>\n      <td>33.833333</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>13039</th>\n      <td>13039</td>\n      <td>378.018438</td>\n      <td>10.685872</td>\n      <td>7.066210</td>\n      <td>7.066210</td>\n      <td>6.041834</td>\n      <td>6.041834</td>\n      <td>4.039540</td>\n      <td>2.503411</td>\n      <td>12.514062</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>23.468091</td>\n      <td>24.539800</td>\n      <td>13.825658</td>\n      <td>44.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>13637</th>\n      <td>13637</td>\n      <td>277.172776</td>\n      <td>1.732051</td>\n      <td>0.682574</td>\n      <td>1.462072</td>\n      <td>0.886443</td>\n      <td>0.886443</td>\n      <td>0.087310</td>\n      <td>0.000000</td>\n      <td>24.415866</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>11.938611</td>\n      <td>19.262465</td>\n      <td>9.589074</td>\n      <td>44.333333</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5537</th>\n      <td>5537</td>\n      <td>377.203227</td>\n      <td>11.265362</td>\n      <td>9.264697</td>\n      <td>9.264697</td>\n      <td>6.445092</td>\n      <td>6.445092</td>\n      <td>4.308487</td>\n      <td>2.706995</td>\n      <td>42.723899</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>17.744066</td>\n      <td>45.448667</td>\n      <td>28.250470</td>\n      <td>64.083333</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8425</th>\n      <td>8425</td>\n      <td>315.695337</td>\n      <td>5.985416</td>\n      <td>3.473678</td>\n      <td>3.473678</td>\n      <td>2.634453</td>\n      <td>2.634453</td>\n      <td>1.507705</td>\n      <td>0.672861</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>17.696186</td>\n      <td>6.066367</td>\n      <td>0.000000</td>\n      <td>6.103966</td>\n      <td>0.000000</td>\n      <td>37.166667</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 34 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"class MultilabelPredictor():\n    \"\"\" Tabular Predictor for predicting multiple columns in table.\n        Creates multiple TabularPredictor objects which you can also use individually.\n        You can access the TabularPredictor for a particular label via: `multilabel_predictor.get_predictor(label_i)`\n\n        Parameters\n        ----------\n        labels : List[str]\n            The ith element of this list is the column (i.e. `label`) predicted by the ith TabularPredictor stored in this object.\n        path : str\n            Path to directory where models and intermediate outputs should be saved.\n            If unspecified, a time-stamped folder called \"AutogluonModels/ag-[TIMESTAMP]\" will be created in the working directory to store all models.\n            Note: To call `fit()` twice and save all results of each fit, you must specify different `path` locations or don't specify `path` at all.\n            Otherwise files from first `fit()` will be overwritten by second `fit()`.\n            Caution: when predicting many labels, this directory may grow large as it needs to store many TabularPredictors.\n        problem_types : List[str]\n            The ith element is the `problem_type` for the ith TabularPredictor stored in this object.\n        eval_metrics : List[str]\n            The ith element is the `eval_metric` for the ith TabularPredictor stored in this object.\n        consider_labels_correlation : bool\n            Whether the predictions of multiple labels should account for label correlations or predict each label independently of the others.\n            If True, the ordering of `labels` may affect resulting accuracy as each label is predicted conditional on the previous labels appearing earlier in this list (i.e. in an auto-regressive fashion).\n            Set to False if during inference you may want to individually use just the ith TabularPredictor without predicting all the other labels.\n        kwargs :\n            Arguments passed into the initialization of each TabularPredictor.\n\n    \"\"\"\n\n    multi_predictor_file = 'multilabel_predictor.pkl'\n\n    def __init__(self, labels, path, problem_types=None, eval_metrics=None, consider_labels_correlation=True, **kwargs):\n        if len(labels) < 2:\n            raise ValueError(\"MultilabelPredictor is only intended for predicting MULTIPLE labels (columns), use TabularPredictor for predicting one label (column).\")\n        self.path = '/kaggle/working/'\n        self.labels = labels\n        self.consider_labels_correlation = consider_labels_correlation\n        self.predictors = {}  # key = label, value = TabularPredictor or str path to the TabularPredictor for this label\n        if eval_metrics is None:\n            self.eval_metrics = {}\n        else:\n            self.eval_metrics = {labels[i] : eval_metrics[i] for i in range(len(labels))}\n        problem_type = None\n        eval_metric = None\n        for i in range(len(labels)):\n            label = labels[i]\n            path_i = self.path + \"Predictor_\" + label\n            if problem_types is not None:\n                problem_type = problem_types[i]\n            if eval_metrics is not None:\n                eval_metric = self.eval_metrics[label]\n            self.predictors[label] = TabularPredictor(label=label, problem_type=problem_type, eval_metric=eval_metric, path=path_i, **kwargs)\n\n    def fit(self, train_data, tuning_data=None, **kwargs):\n        \"\"\" Fits a separate TabularPredictor to predict each of the labels.\n\n            Parameters\n            ----------\n            train_data, tuning_data : str or autogluon.tabular.TabularDataset or pd.DataFrame\n                See documentation for `TabularPredictor.fit()`.\n            kwargs :\n                Arguments passed into the `fit()` call for each TabularPredictor.\n        \"\"\"\n        if isinstance(train_data, str):\n            train_data = TabularDataset(train_data)\n        if tuning_data is not None and isinstance(tuning_data, str):\n            tuning_data = TabularDataset(tuning_data)\n        train_data_og = train_data.copy()\n        if tuning_data is not None:\n            tuning_data_og = tuning_data.copy()\n        else:\n            tuning_data_og = None\n        save_metrics = len(self.eval_metrics) == 0\n        for i in range(len(self.labels)):\n            label = self.labels[i]\n            predictor = self.get_predictor(label)\n            if not self.consider_labels_correlation:\n                labels_to_drop = [l for l in self.labels if l != label]\n            else:\n                labels_to_drop = [self.labels[j] for j in range(i+1, len(self.labels))]\n            train_data = train_data_og.drop(labels_to_drop, axis=1)\n            if tuning_data is not None:\n                tuning_data = tuning_data_og.drop(labels_to_drop, axis=1)\n            print(f\"Fitting TabularPredictor for label: {label} ...\")\n            predictor.fit(train_data=train_data, tuning_data=tuning_data, **kwargs)\n            self.predictors[label] = predictor.path\n            if save_metrics:\n                self.eval_metrics[label] = predictor.eval_metric\n        self.save()\n\n    def predict(self, data, **kwargs):\n        \"\"\" Returns DataFrame with label columns containing predictions for each label.\n\n            Parameters\n            ----------\n            data : str or autogluon.tabular.TabularDataset or pd.DataFrame\n                Data to make predictions for. If label columns are present in this data, they will be ignored. See documentation for `TabularPredictor.predict()`.\n            kwargs :\n                Arguments passed into the predict() call for each TabularPredictor.\n        \"\"\"\n        return self._predict(data, as_proba=False, **kwargs)\n\n    def predict_proba(self, data, **kwargs):\n        \"\"\" Returns dict where each key is a label and the corresponding value is the `predict_proba()` output for just that label.\n\n            Parameters\n            ----------\n            data : str or autogluon.tabular.TabularDataset or pd.DataFrame\n                Data to make predictions for. See documentation for `TabularPredictor.predict()` and `TabularPredictor.predict_proba()`.\n            kwargs :\n                Arguments passed into the `predict_proba()` call for each TabularPredictor (also passed into a `predict()` call).\n        \"\"\"\n        return self._predict(data, as_proba=True, **kwargs)\n\n    def evaluate(self, data, **kwargs):\n        \"\"\" Returns dict where each key is a label and the corresponding value is the `evaluate()` output for just that label.\n\n            Parameters\n            ----------\n            data : str or autogluon.tabular.TabularDataset or pd.DataFrame\n                Data to evalate predictions of all labels for, must contain all labels as columns. See documentation for `TabularPredictor.evaluate()`.\n            kwargs :\n                Arguments passed into the `evaluate()` call for each TabularPredictor (also passed into the `predict()` call).\n        \"\"\"\n        data = self._get_data(data)\n        eval_dict = {}\n        for label in self.labels:\n            print(f\"Evaluating TabularPredictor for label: {label} ...\")\n            predictor = self.get_predictor(label)\n            eval_dict[label] = predictor.evaluate(data, **kwargs)\n            if self.consider_labels_correlation:\n                data[label] = predictor.predict(data, **kwargs)\n        return eval_dict\n\n    def save(self):\n        \"\"\" Save MultilabelPredictor to disk. \"\"\"\n        for label in self.labels:\n            if not isinstance(self.predictors[label], str):\n                self.predictors[label] = self.predictors[label].path\n        save_pkl.save(path=self.path+self.multi_predictor_file, object=self)\n        print(f\"MultilabelPredictor saved to disk. Load with: MultilabelPredictor.load('{self.path}')\")\n\n    @classmethod\n    def load(cls, path):\n        \"\"\" Load MultilabelPredictor from disk `path` previously specified when creating this MultilabelPredictor. \"\"\"\n        path = '/kaggle/working/'\n        if path[-1] != os.path.sep:\n            path = path + os.path.sep\n        return load_pkl.load(path=path+cls.multi_predictor_file)\n\n    def get_predictor(self, label):\n        \"\"\" Returns TabularPredictor which is used to predict this label. \"\"\"\n        predictor = self.predictors[label]\n        if isinstance(predictor, str):\n            return TabularPredictor.load(path=predictor)\n        return predictor\n\n    def _get_data(self, data):\n        if isinstance(data, str):\n            return TabularDataset(data)\n        return data.copy()\n\n    def _predict(self, data, as_proba=False, **kwargs):\n        data = self._get_data(data)\n        if as_proba:\n            predproba_dict = {}\n        for label in self.labels:\n            print(f\"Predicting with TabularPredictor for label: {label} ...\")\n            predictor = self.get_predictor(label)\n            if as_proba:\n                predproba_dict[label] = predictor.predict_proba(data, as_multiclass=True, **kwargs)\n            data[label] = predictor.predict(data, **kwargs)\n        if not as_proba:\n            return data[self.labels]\n        else:\n            return predproba_dict","metadata":{"execution":{"iopub.status.busy":"2023-06-28T23:39:08.836841Z","iopub.execute_input":"2023-06-28T23:39:08.837361Z","iopub.status.idle":"2023-06-28T23:39:08.874678Z","shell.execute_reply.started":"2023-06-28T23:39:08.837324Z","shell.execute_reply":"2023-06-28T23:39:08.873528Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"labels = ['EC1','EC2']  # which columns to predict based on the others\nproblem_types = ['multiclass','binary']  # type of each prediction problem\nsave_path = 'agModels-predictEC1EC2'  # specifies folder to store trained models\ntime_limit =600","metadata":{"execution":{"iopub.status.busy":"2023-06-28T23:43:11.79166Z","iopub.execute_input":"2023-06-28T23:43:11.792138Z","iopub.status.idle":"2023-06-28T23:43:11.798421Z","shell.execute_reply.started":"2023-06-28T23:43:11.792102Z","shell.execute_reply":"2023-06-28T23:43:11.797047Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"multi_predictor = MultilabelPredictor(labels=labels, problem_types=problem_types, path=save_path)\nmulti_predictor.fit(train_data, time_limit=time_limit)","metadata":{"execution":{"iopub.status.busy":"2023-06-28T23:43:12.60444Z","iopub.execute_input":"2023-06-28T23:43:12.60496Z","iopub.status.idle":"2023-06-28T23:45:43.499766Z","shell.execute_reply.started":"2023-06-28T23:43:12.604917Z","shell.execute_reply":"2023-06-28T23:45:43.498663Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stderr","text":"Warning: path already exists! This predictor may overwrite an existing predictor! path=\"/kaggle/working/Predictor_EC1\"\nWarning: path already exists! This predictor may overwrite an existing predictor! path=\"/kaggle/working/Predictor_EC2\"\nBeginning AutoGluon training ... Time limit = 600s\nAutoGluon will save models to \"/kaggle/working/Predictor_EC1/\"\nAutoGluon Version:  0.8.0\nPython Version:     3.10.10\nOperating System:   Linux\nPlatform Machine:   x86_64\nPlatform Version:   #1 SMP Sat Jun 24 10:55:41 UTC 2023\nDisk Space Avail:   20.33 GB / 20.96 GB (97.0%)\nTrain Data Rows:    14838\nTrain Data Columns: 32\nLabel Column: EC1\nPreprocessing data ...\nSelected class <--> label mapping:  class 1 = 1, class 0 = 0\nTrain Data Class Count: 2\nUsing Feature Generators to preprocess the data ...\nFitting AutoMLPipelineFeatureGenerator...\n\tAvailable Memory:                    31583.64 MB\n\tTrain Data (Original)  Memory Usage: 3.8 MB (0.0% of available memory)\n\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n\tStage 1 Generators:\n\t\tFitting AsTypeFeatureGenerator...\n\tStage 2 Generators:\n\t\tFitting FillNaFeatureGenerator...\n\tStage 3 Generators:\n\t\tFitting IdentityFeatureGenerator...\n\tStage 4 Generators:\n\t\tFitting DropUniqueFeatureGenerator...\n\tStage 5 Generators:\n\t\tFitting DropDuplicatesFeatureGenerator...\n","output_type":"stream"},{"name":"stdout","text":"Fitting TabularPredictor for label: EC1 ...\n","output_type":"stream"},{"name":"stderr","text":"\tTypes of features in original data (raw dtype, special dtypes):\n\t\t('float', []) : 28 | ['BertzCT', 'Chi1', 'Chi1n', 'Chi1v', 'Chi2n', ...]\n\t\t('int', [])   :  4 | ['id', 'NumHeteroatoms', 'fr_COO', 'fr_COO2']\n\tTypes of features in processed data (raw dtype, special dtypes):\n\t\t('float', []) : 28 | ['BertzCT', 'Chi1', 'Chi1n', 'Chi1v', 'Chi2n', ...]\n\t\t('int', [])   :  4 | ['id', 'NumHeteroatoms', 'fr_COO', 'fr_COO2']\n\t0.2s = Fit runtime\n\t32 features in original data used to generate 32 features in processed data.\n\tTrain Data (Processed) Memory Usage: 3.8 MB (0.0% of available memory)\nData preprocessing and feature engineering runtime = 0.28s ...\nAutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n\tTo change this, specify the eval_metric parameter of Predictor()\nAutomatically generating train/validation split with holdout_frac=0.1, Train Rows: 13354, Val Rows: 1484\nUser-specified model hyperparameters to be fit:\n{\n\t'NN_TORCH': {},\n\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n\t'CAT': {},\n\t'XGB': {},\n\t'FASTAI': {},\n\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n}\nFitting 13 L1 models ...\nFitting model: KNeighborsUnif ... Training model for up to 599.72s of the 599.72s of remaining time.\n\t0.6388\t = Validation score   (accuracy)\n\t0.04s\t = Training   runtime\n\t0.03s\t = Validation runtime\nFitting model: KNeighborsDist ... Training model for up to 599.63s of the 599.63s of remaining time.\n\t0.6408\t = Validation score   (accuracy)\n\t0.04s\t = Training   runtime\n\t0.04s\t = Validation runtime\nFitting model: LightGBMXT ... Training model for up to 599.54s of the 599.53s of remaining time.\n\t0.6995\t = Validation score   (accuracy)\n\t1.92s\t = Training   runtime\n\t0.01s\t = Validation runtime\nFitting model: LightGBM ... Training model for up to 597.59s of the 597.59s of remaining time.\n\t0.7015\t = Validation score   (accuracy)\n\t1.9s\t = Training   runtime\n\t0.01s\t = Validation runtime\nFitting model: RandomForestGini ... Training model for up to 595.68s of the 595.67s of remaining time.\n\t0.6894\t = Validation score   (accuracy)\n\t6.92s\t = Training   runtime\n\t0.18s\t = Validation runtime\nFitting model: RandomForestEntr ... Training model for up to 588.22s of the 588.22s of remaining time.\n\t0.692\t = Validation score   (accuracy)\n\t7.89s\t = Training   runtime\n\t0.18s\t = Validation runtime\nFitting model: CatBoost ... Training model for up to 579.89s of the 579.89s of remaining time.\n\t0.7035\t = Validation score   (accuracy)\n\t3.38s\t = Training   runtime\n\t0.01s\t = Validation runtime\nFitting model: ExtraTreesGini ... Training model for up to 576.5s of the 576.49s of remaining time.\n\t0.6894\t = Validation score   (accuracy)\n\t2.76s\t = Training   runtime\n\t0.21s\t = Validation runtime\nFitting model: ExtraTreesEntr ... Training model for up to 572.88s of the 572.88s of remaining time.\n\t0.6968\t = Validation score   (accuracy)\n\t3.03s\t = Training   runtime\n\t0.19s\t = Validation runtime\nFitting model: NeuralNetFastAI ... Training model for up to 569.16s of the 569.16s of remaining time.\nNo improvement since epoch 6: early stopping\n\t0.6988\t = Validation score   (accuracy)\n\t20.48s\t = Training   runtime\n\t0.05s\t = Validation runtime\nFitting model: XGBoost ... Training model for up to 548.59s of the 548.58s of remaining time.\n\t0.7015\t = Validation score   (accuracy)\n\t2.9s\t = Training   runtime\n\t0.02s\t = Validation runtime\nFitting model: NeuralNetTorch ... Training model for up to 545.65s of the 545.65s of remaining time.\n\t0.6988\t = Validation score   (accuracy)\n\t12.11s\t = Training   runtime\n\t0.06s\t = Validation runtime\nFitting model: LightGBMLarge ... Training model for up to 533.47s of the 533.47s of remaining time.\n\t0.6974\t = Validation score   (accuracy)\n\t4.69s\t = Training   runtime\n\t0.01s\t = Validation runtime\nFitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 528.73s of remaining time.\n\t0.7082\t = Validation score   (accuracy)\n\t2.18s\t = Training   runtime\n\t0.01s\t = Validation runtime\nAutoGluon training complete, total runtime = 73.53s ... Best model: \"WeightedEnsemble_L2\"\nTabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/kaggle/working/Predictor_EC1/\")\nBeginning AutoGluon training ... Time limit = 600s\nAutoGluon will save models to \"/kaggle/working/Predictor_EC2/\"\nAutoGluon Version:  0.8.0\nPython Version:     3.10.10\nOperating System:   Linux\nPlatform Machine:   x86_64\nPlatform Version:   #1 SMP Sat Jun 24 10:55:41 UTC 2023\nDisk Space Avail:   19.83 GB / 20.96 GB (94.6%)\nTrain Data Rows:    14838\nTrain Data Columns: 33\nLabel Column: EC2\nPreprocessing data ...\nSelected class <--> label mapping:  class 1 = 1, class 0 = 0\nUsing Feature Generators to preprocess the data ...\nFitting AutoMLPipelineFeatureGenerator...\n\tAvailable Memory:                    31580.32 MB\n\tTrain Data (Original)  Memory Usage: 3.92 MB (0.0% of available memory)\n\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n\tStage 1 Generators:\n\t\tFitting AsTypeFeatureGenerator...\n\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n\tStage 2 Generators:\n\t\tFitting FillNaFeatureGenerator...\n\tStage 3 Generators:\n\t\tFitting IdentityFeatureGenerator...\n\tStage 4 Generators:\n\t\tFitting DropUniqueFeatureGenerator...\n\tStage 5 Generators:\n\t\tFitting DropDuplicatesFeatureGenerator...\n","output_type":"stream"},{"name":"stdout","text":"Fitting TabularPredictor for label: EC2 ...\n","output_type":"stream"},{"name":"stderr","text":"\tTypes of features in original data (raw dtype, special dtypes):\n\t\t('float', []) : 28 | ['BertzCT', 'Chi1', 'Chi1n', 'Chi1v', 'Chi2n', ...]\n\t\t('int', [])   :  5 | ['id', 'NumHeteroatoms', 'fr_COO', 'fr_COO2', 'EC1']\n\tTypes of features in processed data (raw dtype, special dtypes):\n\t\t('float', [])     : 28 | ['BertzCT', 'Chi1', 'Chi1n', 'Chi1v', 'Chi2n', ...]\n\t\t('int', [])       :  4 | ['id', 'NumHeteroatoms', 'fr_COO', 'fr_COO2']\n\t\t('int', ['bool']) :  1 | ['EC1']\n\t0.3s = Fit runtime\n\t33 features in original data used to generate 33 features in processed data.\n\tTrain Data (Processed) Memory Usage: 3.81 MB (0.0% of available memory)\nData preprocessing and feature engineering runtime = 0.3s ...\nAutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n\tTo change this, specify the eval_metric parameter of Predictor()\nAutomatically generating train/validation split with holdout_frac=0.1, Train Rows: 13354, Val Rows: 1484\nUser-specified model hyperparameters to be fit:\n{\n\t'NN_TORCH': {},\n\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n\t'CAT': {},\n\t'XGB': {},\n\t'FASTAI': {},\n\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n}\nFitting 13 L1 models ...\nFitting model: KNeighborsUnif ... Training model for up to 599.7s of the 599.7s of remaining time.\n\t0.7682\t = Validation score   (accuracy)\n\t0.04s\t = Training   runtime\n\t0.04s\t = Validation runtime\nFitting model: KNeighborsDist ... Training model for up to 599.6s of the 599.6s of remaining time.\n\t0.7628\t = Validation score   (accuracy)\n\t0.04s\t = Training   runtime\n\t0.04s\t = Validation runtime\nFitting model: LightGBMXT ... Training model for up to 599.51s of the 599.51s of remaining time.\n\t0.7992\t = Validation score   (accuracy)\n\t1.76s\t = Training   runtime\n\t0.01s\t = Validation runtime\nFitting model: LightGBM ... Training model for up to 597.74s of the 597.73s of remaining time.\n\t0.7999\t = Validation score   (accuracy)\n\t2.49s\t = Training   runtime\n\t0.02s\t = Validation runtime\nFitting model: RandomForestGini ... Training model for up to 595.22s of the 595.21s of remaining time.\n\t0.8012\t = Validation score   (accuracy)\n\t6.94s\t = Training   runtime\n\t0.19s\t = Validation runtime\nFitting model: RandomForestEntr ... Training model for up to 587.82s of the 587.81s of remaining time.\n\t0.7999\t = Validation score   (accuracy)\n\t8.27s\t = Training   runtime\n\t0.19s\t = Validation runtime\nFitting model: CatBoost ... Training model for up to 579.12s of the 579.12s of remaining time.\n\t0.7992\t = Validation score   (accuracy)\n\t2.8s\t = Training   runtime\n\t0.01s\t = Validation runtime\nFitting model: ExtraTreesGini ... Training model for up to 576.31s of the 576.31s of remaining time.\n\t0.8005\t = Validation score   (accuracy)\n\t2.68s\t = Training   runtime\n\t0.18s\t = Validation runtime\nFitting model: ExtraTreesEntr ... Training model for up to 572.96s of the 572.96s of remaining time.\n\t0.8012\t = Validation score   (accuracy)\n\t3.04s\t = Training   runtime\n\t0.25s\t = Validation runtime\nFitting model: NeuralNetFastAI ... Training model for up to 569.13s of the 569.12s of remaining time.\n\t0.7999\t = Validation score   (accuracy)\n\t22.59s\t = Training   runtime\n\t0.04s\t = Validation runtime\nFitting model: XGBoost ... Training model for up to 546.46s of the 546.45s of remaining time.\n\t0.8012\t = Validation score   (accuracy)\n\t3.21s\t = Training   runtime\n\t0.02s\t = Validation runtime\nFitting model: NeuralNetTorch ... Training model for up to 543.21s of the 543.2s of remaining time.\n\t0.7992\t = Validation score   (accuracy)\n\t9.94s\t = Training   runtime\n\t0.06s\t = Validation runtime\nFitting model: LightGBMLarge ... Training model for up to 533.19s of the 533.19s of remaining time.\n\t0.8026\t = Validation score   (accuracy)\n\t8.09s\t = Training   runtime\n\t0.05s\t = Validation runtime\nFitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 524.86s of remaining time.\n\t0.8026\t = Validation score   (accuracy)\n\t2.08s\t = Training   runtime\n\t0.01s\t = Validation runtime\nAutoGluon training complete, total runtime = 77.28s ... Best model: \"WeightedEnsemble_L2\"\nTabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/kaggle/working/Predictor_EC2/\")\n","output_type":"stream"},{"name":"stdout","text":"MultilabelPredictor saved to disk. Load with: MultilabelPredictor.load('/kaggle/working/')\n","output_type":"stream"}]},{"cell_type":"code","source":"test_data = TabularDataset('/kaggle/input/playground-series-s3e18/test.csv')\ntest_data = test_data.sample(n=9893, random_state=42)\ntest_data.head()","metadata":{"execution":{"iopub.status.busy":"2023-06-28T23:47:19.032767Z","iopub.execute_input":"2023-06-28T23:47:19.033336Z","iopub.status.idle":"2023-06-28T23:47:19.14346Z","shell.execute_reply.started":"2023-06-28T23:47:19.033292Z","shell.execute_reply":"2023-06-28T23:47:19.141984Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stderr","text":"Loaded data from: /kaggle/input/playground-series-s3e18/test.csv | Columns = 32 / 32 | Rows = 9893 -> 9893\n","output_type":"stream"},{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"         id      BertzCT       Chi1      Chi1n      Chi1v      Chi2n  \\\n2807  17645   327.399591   4.414719   2.618262   2.618262   1.670820   \n5235  20073   292.492090   4.663902   2.767073   2.767073   1.904314   \n6291  21129  1122.912455  16.188780  10.684028  13.674919   8.012199   \n9789  24627  1727.925403  24.910940  15.637880  20.567315  11.722242   \n2868  17706    62.568425   2.642734   1.049739   1.049739   0.504904   \n\n          Chi2v      Chi3v     Chi4n  EState_VSA1  ...  PEOE_VSA14  PEOE_VSA6  \\\n2807   1.670820   1.070620  0.694224    17.282269  ...    0.000000   0.000000   \n5235   1.904314   1.060948  0.361460     5.969305  ...    5.969305   0.000000   \n6291  11.008637   7.199415  3.408511    89.249895  ...   21.335138   0.000000   \n9789  13.672761  11.312963  4.827185    90.658938  ...   23.468091  32.533097   \n2868   0.504904   0.142577  0.000000     5.969305  ...   28.148794   0.000000   \n\n      PEOE_VSA7  PEOE_VSA8  SMR_VSA10   SMR_VSA5  SlogP_VSA3  VSA_EState9  \\\n2807  18.199101   6.544756  10.902925   0.000000    0.000000    23.166667   \n5235   0.000000   6.076020   5.969305   0.000000    0.000000    37.666667   \n6291  13.847474  18.181117  15.645394  69.410022   31.961948    73.715826   \n9789   0.000000  37.099000  69.141353  63.436851   50.697492   119.375115   \n2868   0.000000   0.000000   5.969305   6.544756    4.794537    21.178241   \n\n      fr_COO  fr_COO2  \n2807       0        0  \n5235       1        1  \n6291       0        0  \n9789       0        0  \n2868       1        1  \n\n[5 rows x 32 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>BertzCT</th>\n      <th>Chi1</th>\n      <th>Chi1n</th>\n      <th>Chi1v</th>\n      <th>Chi2n</th>\n      <th>Chi2v</th>\n      <th>Chi3v</th>\n      <th>Chi4n</th>\n      <th>EState_VSA1</th>\n      <th>...</th>\n      <th>PEOE_VSA14</th>\n      <th>PEOE_VSA6</th>\n      <th>PEOE_VSA7</th>\n      <th>PEOE_VSA8</th>\n      <th>SMR_VSA10</th>\n      <th>SMR_VSA5</th>\n      <th>SlogP_VSA3</th>\n      <th>VSA_EState9</th>\n      <th>fr_COO</th>\n      <th>fr_COO2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2807</th>\n      <td>17645</td>\n      <td>327.399591</td>\n      <td>4.414719</td>\n      <td>2.618262</td>\n      <td>2.618262</td>\n      <td>1.670820</td>\n      <td>1.670820</td>\n      <td>1.070620</td>\n      <td>0.694224</td>\n      <td>17.282269</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>18.199101</td>\n      <td>6.544756</td>\n      <td>10.902925</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>23.166667</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5235</th>\n      <td>20073</td>\n      <td>292.492090</td>\n      <td>4.663902</td>\n      <td>2.767073</td>\n      <td>2.767073</td>\n      <td>1.904314</td>\n      <td>1.904314</td>\n      <td>1.060948</td>\n      <td>0.361460</td>\n      <td>5.969305</td>\n      <td>...</td>\n      <td>5.969305</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>6.076020</td>\n      <td>5.969305</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>37.666667</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6291</th>\n      <td>21129</td>\n      <td>1122.912455</td>\n      <td>16.188780</td>\n      <td>10.684028</td>\n      <td>13.674919</td>\n      <td>8.012199</td>\n      <td>11.008637</td>\n      <td>7.199415</td>\n      <td>3.408511</td>\n      <td>89.249895</td>\n      <td>...</td>\n      <td>21.335138</td>\n      <td>0.000000</td>\n      <td>13.847474</td>\n      <td>18.181117</td>\n      <td>15.645394</td>\n      <td>69.410022</td>\n      <td>31.961948</td>\n      <td>73.715826</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9789</th>\n      <td>24627</td>\n      <td>1727.925403</td>\n      <td>24.910940</td>\n      <td>15.637880</td>\n      <td>20.567315</td>\n      <td>11.722242</td>\n      <td>13.672761</td>\n      <td>11.312963</td>\n      <td>4.827185</td>\n      <td>90.658938</td>\n      <td>...</td>\n      <td>23.468091</td>\n      <td>32.533097</td>\n      <td>0.000000</td>\n      <td>37.099000</td>\n      <td>69.141353</td>\n      <td>63.436851</td>\n      <td>50.697492</td>\n      <td>119.375115</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2868</th>\n      <td>17706</td>\n      <td>62.568425</td>\n      <td>2.642734</td>\n      <td>1.049739</td>\n      <td>1.049739</td>\n      <td>0.504904</td>\n      <td>0.504904</td>\n      <td>0.142577</td>\n      <td>0.000000</td>\n      <td>5.969305</td>\n      <td>...</td>\n      <td>28.148794</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>5.969305</td>\n      <td>6.544756</td>\n      <td>4.794537</td>\n      <td>21.178241</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 32 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"multi_predictor = MultilabelPredictor.load(save_path)  \nmulti_predictor.evaluate(train_data)","metadata":{"execution":{"iopub.status.busy":"2023-06-28T23:48:08.434442Z","iopub.execute_input":"2023-06-28T23:48:08.434941Z","iopub.status.idle":"2023-06-28T23:48:14.34933Z","shell.execute_reply.started":"2023-06-28T23:48:08.434872Z","shell.execute_reply":"2023-06-28T23:48:14.347992Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"Evaluating TabularPredictor for label: EC1 ...\n","output_type":"stream"},{"name":"stderr","text":"Evaluation: accuracy on test data: 0.8531473244372557\nEvaluations on test data:\n{\n    \"accuracy\": 0.8531473244372557,\n    \"balanced_accuracy\": 0.7854774472817261,\n    \"mcc\": 0.6691886841310939\n}\n","output_type":"stream"},{"name":"stdout","text":"Evaluating TabularPredictor for label: EC2 ...\n","output_type":"stream"},{"name":"stderr","text":"Evaluation: accuracy on test data: 0.9608437794851058\nEvaluations on test data:\n{\n    \"accuracy\": 0.9608437794851058,\n    \"balanced_accuracy\": 0.9039946594599823,\n    \"mcc\": 0.875912748407303,\n    \"roc_auc\": 0.9714196134343737,\n    \"f1\": 0.9760599942313241,\n    \"precision\": 0.9540840985983567,\n    \"recall\": 0.9990721214677352\n}\n","output_type":"stream"},{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"{'EC1': {'accuracy': 0.8531473244372557,\n  'balanced_accuracy': 0.7854774472817261,\n  'mcc': 0.6691886841310939},\n 'EC2': {'accuracy': 0.9608437794851058,\n  'balanced_accuracy': 0.9039946594599823,\n  'mcc': 0.875912748407303,\n  'roc_auc': 0.9714196134343737,\n  'f1': 0.9760599942313241,\n  'precision': 0.9540840985983567,\n  'recall': 0.9990721214677352}}"},"metadata":{}}]},{"cell_type":"code","source":"predictions = multi_predictor.predict_proba(test_data)\nprint(\"Predictions:  \\n\", predictions)","metadata":{"execution":{"iopub.status.busy":"2023-06-28T23:49:37.023881Z","iopub.execute_input":"2023-06-28T23:49:37.024328Z","iopub.status.idle":"2023-06-28T23:49:40.659936Z","shell.execute_reply.started":"2023-06-28T23:49:37.024294Z","shell.execute_reply":"2023-06-28T23:49:40.658564Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"Predicting with TabularPredictor for label: EC1 ...\nPredicting with TabularPredictor for label: EC2 ...\nPredictions:  \n {'EC1':              0         1\n2807  0.241953  0.758047\n5235  0.238493  0.761507\n6291  0.365012  0.634988\n9789  0.235141  0.764859\n2868  0.196513  0.803487\n...        ...       ...\n5734  0.271537  0.728463\n5191  0.238284  0.761716\n5390  0.618955  0.381045\n860   0.197483  0.802517\n7270  0.505737  0.494263\n\n[9893 rows x 2 columns], 'EC2':              0         1\n2807  0.099513  0.900487\n5235  0.075354  0.924646\n6291  0.481706  0.518294\n9789  0.258135  0.741865\n2868  0.085378  0.914622\n...        ...       ...\n5734  0.154639  0.845361\n5191  0.097134  0.902866\n5390  0.022749  0.977251\n860   0.187148  0.812852\n7270  0.029129  0.970871\n\n[9893 rows x 2 columns]}\n","output_type":"stream"}]},{"cell_type":"code","source":"EC1 = list(predictions.values())\nEC2 = list(predictions.values())","metadata":{"execution":{"iopub.status.busy":"2023-06-28T23:54:52.973414Z","iopub.execute_input":"2023-06-28T23:54:52.973859Z","iopub.status.idle":"2023-06-28T23:54:52.979712Z","shell.execute_reply.started":"2023-06-28T23:54:52.973825Z","shell.execute_reply":"2023-06-28T23:54:52.978439Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"class Submit:\n    \n    def submit_predictions(self,test_data):\n        df_submit = pd.DataFrame(data={'id': test_data['id'],'EC1':EC1[0][1],'EC2':EC2[1][1]})\n        df_submit.to_csv('submission.csv',index=False)\n        print('Submission Completed!!')\n        return df_submit\n        \n        \nsubmit = Submit()\ndf_submit=submit.submit_predictions(test_data)","metadata":{"execution":{"iopub.status.busy":"2023-06-28T23:54:55.302627Z","iopub.execute_input":"2023-06-28T23:54:55.303165Z","iopub.status.idle":"2023-06-28T23:54:55.387486Z","shell.execute_reply.started":"2023-06-28T23:54:55.303125Z","shell.execute_reply":"2023-06-28T23:54:55.386002Z"},"trusted":true},"execution_count":57,"outputs":[{"name":"stdout","text":"Submission Completed!!\n","output_type":"stream"}]},{"cell_type":"code","source":"df_submit","metadata":{"execution":{"iopub.status.busy":"2023-06-28T23:54:59.917741Z","iopub.execute_input":"2023-06-28T23:54:59.918195Z","iopub.status.idle":"2023-06-28T23:54:59.935506Z","shell.execute_reply.started":"2023-06-28T23:54:59.918162Z","shell.execute_reply":"2023-06-28T23:54:59.93408Z"},"trusted":true},"execution_count":58,"outputs":[{"execution_count":58,"output_type":"execute_result","data":{"text/plain":"         id       EC1       EC2\n2807  17645  0.758047  0.900487\n5235  20073  0.761507  0.924646\n6291  21129  0.634988  0.518294\n9789  24627  0.764859  0.741865\n2868  17706  0.803487  0.914622\n...     ...       ...       ...\n5734  20572  0.728463  0.845361\n5191  20029  0.761716  0.902866\n5390  20228  0.381045  0.977251\n860   15698  0.802517  0.812852\n7270  22108  0.494263  0.970871\n\n[9893 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>EC1</th>\n      <th>EC2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2807</th>\n      <td>17645</td>\n      <td>0.758047</td>\n      <td>0.900487</td>\n    </tr>\n    <tr>\n      <th>5235</th>\n      <td>20073</td>\n      <td>0.761507</td>\n      <td>0.924646</td>\n    </tr>\n    <tr>\n      <th>6291</th>\n      <td>21129</td>\n      <td>0.634988</td>\n      <td>0.518294</td>\n    </tr>\n    <tr>\n      <th>9789</th>\n      <td>24627</td>\n      <td>0.764859</td>\n      <td>0.741865</td>\n    </tr>\n    <tr>\n      <th>2868</th>\n      <td>17706</td>\n      <td>0.803487</td>\n      <td>0.914622</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5734</th>\n      <td>20572</td>\n      <td>0.728463</td>\n      <td>0.845361</td>\n    </tr>\n    <tr>\n      <th>5191</th>\n      <td>20029</td>\n      <td>0.761716</td>\n      <td>0.902866</td>\n    </tr>\n    <tr>\n      <th>5390</th>\n      <td>20228</td>\n      <td>0.381045</td>\n      <td>0.977251</td>\n    </tr>\n    <tr>\n      <th>860</th>\n      <td>15698</td>\n      <td>0.802517</td>\n      <td>0.812852</td>\n    </tr>\n    <tr>\n      <th>7270</th>\n      <td>22108</td>\n      <td>0.494263</td>\n      <td>0.970871</td>\n    </tr>\n  </tbody>\n</table>\n<p>9893 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}