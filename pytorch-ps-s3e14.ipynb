{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/averma111/pytorch-ps-s3e14?scriptVersionId=129403866\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nimport torch\nfrom tqdm.notebook import tqdm\nimport torch.nn.functional as F\nfrom sklearn.model_selection import GridSearchCV,RandomizedSearchCV\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data import Dataset, DataLoader\nwarnings.filterwarnings('ignore')\nseed = 42\ntorch.manual_seed(seed)\nnp.random.seed(seed)\n\nsns.set_style(\"darkgrid\")\npd.set_option('mode.chained_assignment',None)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-11T06:57:26.054564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Assigning the directory and file paths","metadata":{}},{"cell_type":"code","source":"train_file = '/kaggle/input/playground-series-s3e14/train.csv'\ntest_file = '/kaggle/input/playground-series-s3e14/test.csv'\noriginal = '/kaggle/input/wild-blueberry-yield-prediction/Data in Brief/Data in Brief/WildBlueberryPollinationSimulationData.csv'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Reading the datasets","metadata":{}},{"cell_type":"code","source":"def get_datasets(filename):\n    df = pd.read_csv(filename)\n    return df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_datasets(train_file).head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_datasets(test_file).head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_datasets(original).head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Drop unwanted columns","metadata":{}},{"cell_type":"code","source":"def drop_columns(col_name,dataframe):\n    dataframe.drop(col_name,axis=1,inplace=True)\n    return dataframe\n\ntrain = drop_columns('id',get_datasets(train_file))\noriginal = drop_columns('Row#',get_datasets(original))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Concate original and train datasets","metadata":{}},{"cell_type":"code","source":"def concat_dataframe(df1,df2):\n    return pd.concat([df1,df2])\n\ndf_full = concat_dataframe(train, original)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Defining the summary function","metadata":{}},{"cell_type":"code","source":"def summary(text, df):\n    print(f'{text} shape: {df.shape}')\n    summ = pd.DataFrame(df.dtypes, columns=['dtypes'])\n    summ['null'] = df.isnull().sum()\n    summ['unique'] = df.nunique()\n    summ['min'] = df.min()\n    summ['median'] = df.median()\n    summ['max'] = df.max()\n    summ['mean'] = df.mean()\n    summ['std'] = df.std()\n    summ['inf'] = np.isinf(df).sum().sum()\n    summ['duplicate'] = df.duplicated().sum()\n    return summ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##  Summary of the trained data","metadata":{}},{"cell_type":"code","source":"summary('full_dataset',df_full)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n* No null values. We therefore dont need to use imputation\n* Categorical data ==> No Categorical data\n* Data types are all float values excluding the target (integer)\n* Data is reasonably small with only 15289 datapoints\n* Duplicates: 7 duplicate","metadata":{}},{"cell_type":"markdown","source":"## Drop duplicates from dataframe","metadata":{}},{"cell_type":"code","source":"def drop_dups(df):\n    return df.drop_duplicates()\ndf_full = drop_dups(df_full)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature Engineering","metadata":{}},{"cell_type":"code","source":"def generate_features(df):\n    df[\"fruit_seed\"] = df[\"fruitset\"] * df[\"seeds\"]\n    df['insects'] = df['honeybee'] + df['bumbles'] + df['andrena'] + df['osmia']\n    df[\"AverageTRange\"]=(df[\"AverageOfUpperTRange\"]+df[\"AverageOfLowerTRange\"])/2\n    return df\n\n\n\ndf_full=generate_features(df_full)\ntest = generate_features(get_datasets(test_file))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Distribution plot  of the full dataset\n\n* Distribution looks fairely normal with -negative skewness","metadata":{}},{"cell_type":"code","source":"sns.kdeplot(df_full,x='yield',color='r')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Distribution of Train vs Test data\n\n* The distribution of Test and Train datasets seem to align","metadata":{}},{"cell_type":"code","source":"def generate_features_labels(df,target_name):\n    if target_name =='yield':\n        label = df[target_name]\n        features=drop_columns(target_name,df)\n        return features,label\n    elif target_name=='test':\n        features=df.loc[:, df.columns != 'id']\n        return features\n\nX,y = generate_features_labels(df_full,'yield')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Distribution of Train and Test look synonimous","metadata":{}},{"cell_type":"code","source":"def plot_kde_train_test(features,test_df):\n    fig,ax = plt.subplots(int(np.ceil(len(features.columns)/4)),4, figsize = (30,25))\n    for i,col in enumerate(features.columns):\n        ax = np.ravel(ax)\n        sns.kdeplot(x= features[col] , label = 'Train', ax = ax[i],color='r')\n        sns.kdeplot(x= test_df[col], label = 'Test', ax = ax[i] ,color='b')\n        ax[i].legend()\n        ax[i].set_title(f\"col\")\n\n    plt.suptitle(\"Distribution of Train vs Test Dataset\",fontsize = 30)\n    plt.tight_layout(pad =3)\n    plt.show()\n    \nplot_kde_train_test(X,test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Correlation Matrix\n\n* Dataset looks highly correlated with target field","metadata":{}},{"cell_type":"code","source":"def  plot_correlation_dataset(df):\n    plt.figure(figsize = (25,12))\n    corr = df.corr()\n    upper_triangle = np.triu(np.ones_like(corr, dtype=bool))\n    sns.heatmap(corr,vmin = -1, vmax = 1, cmap = \"rocket\", annot = True, mask = upper_triangle)\n    plt.title(\"Correlation of all features and target\", fontsize= 18)\n    plt.show()\n    \nplot_correlation_dataset(X)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Outlier Analaysis","metadata":{}},{"cell_type":"code","source":"def show_outlier(features):\n    fig,ax = plt.subplots(int(np.ceil(len(X.columns)/4)),4,figsize = (30,15))\n    ax = np.ravel(ax)\n    for i,col in enumerate(X.columns):\n        sns.boxplot(ax = ax[i], x = X[col], color= \"red\")\n    fig.suptitle(\"Box plots of all data \",fontsize = 20)\n    plt.tight_layout(pad=3)\n    plt.show()\n\nshow_outlier(X)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preprocessing of the datasets","metadata":{}},{"cell_type":"code","source":"def preprocessing(features,label=None):\n    scaler = StandardScaler()\n    num_cols = list(features.select_dtypes(include=['int','float']))\n    features = scaler.fit_transform(features[num_cols].values)\n    if label is not None:\n        return train_test_split(features,label.to_numpy(),test_size=0.2,random_state=42)\n    elif label is None:\n        return features\n\nX_train,X_test,y_train,y_test = preprocessing(X,y)\nprint(X_train.shape,X_test.shape,y_train.shape,y_test.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Converting dataframe to tensors","metadata":{}},{"cell_type":"code","source":"def convert_to_torch(value):\n    return torch.tensor(data=value,dtype=torch.float32,requires_grad=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data class for datasets","metadata":{}},{"cell_type":"code","source":"class Data(Dataset):\n    def __init__(self, X_data, y_data):\n        self.X_data = X_data\n        self.y_data = y_data\n        \n    def __getitem__(self, index):\n            return self.X_data[index], self.y_data[index]\n        \n    def __len__ (self):\n        return len(self.X_data)\n\nX_data = convert_to_torch(X_train)\ny_data = convert_to_torch(y_train)\nX_test = convert_to_torch(X_test)\ny_test = convert_to_torch(y_test)\ntrain_data = Data(X_data,y_data)\ntest_data = Data(X_test,y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Creating the baseline model","metadata":{}},{"cell_type":"code","source":"class RegressionBaseModel(torch.nn.Module):\n    \n    def training_step(self,batch):\n        features,labels = batch\n        out = self(features)\n        loss = F.l1_loss(out,labels.unsqueeze(1))\n        return loss\n    \n    def test_step(self, batch):\n        features, labels = batch \n        out = self(features)                    \n        loss = F.l1_loss(out, labels.unsqueeze(1))          \n        return {'test_loss': loss.detach()}\n        \n    def test_epoch_end(self, outputs):\n        batch_losses = [x['test_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()   \n        return {'test_loss': epoch_loss.item()}\n    \n    \n    def epoch_end(self, epoch, result):\n        if epoch %10 ==0:\n            print(\"Epoch [{}], train_loss: {:.5f}, test_loss: {:.5f}\".format(\n                (epoch+10), result['train_loss'], result['test_loss']))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Pytorch Model","metadata":{}},{"cell_type":"code","source":"class RegressionBlueBerryNNet(RegressionBaseModel):\n    def __init__(self,input_features):\n        super().__init__()\n        self.network = torch.nn.Sequential(\n        torch.nn.Linear(input_features,1),\n        torch.nn.ReLU()\n        )      \n    \n    def forward(self,inputs):\n        return self.network(inputs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Defining the code to run both on CPU and GPU","metadata":{}},{"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Instantiating the model","metadata":{}},{"cell_type":"code","source":"model = RegressionBlueBerryNNet(X_train.shape[1])\nmodel.to(device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Hyper parameter tunning ","metadata":{}},{"cell_type":"code","source":"BATCH_SIZE = 32\nEPOCHS = 100\nLEARNING_RATE = 0.1\nMOMENTUM = 0.9\nOPT_FUNC= torch.optim.SGD","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n## Creating the Dataloader for train and test ","metadata":{}},{"cell_type":"code","source":"def get_dataloaders(dataset_type,batch,shuffle):\n    if shuffle:\n         return DataLoader(dataset=dataset_type, batch_size=batch, shuffle=True)\n    else:\n        return DataLoader(dataset=dataset_type, batch_size=batch,shuffle=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Traning the Model :)","metadata":{}},{"cell_type":"code","source":"@torch.no_grad()\ndef evaluate(model, test_loader):\n    model.eval()\n    outputs = [model.test_step(batch) for batch in test_loader]\n    return model.test_epoch_end(outputs)\n\n  \ndef fit(epochs, lr, model, train_loader, test_loader, opt_func):\n    model.train()\n    history = []\n    optimizer = opt_func(model.parameters(),lr,MOMENTUM)\n    for epoch in tqdm(range(epochs)): \n        train_losses = []\n        for batch in train_loader:\n            optimizer.zero_grad()\n            loss = model.training_step(batch)\n            loss.backward()\n            optimizer.step()\n            train_losses.append(loss)\n            \n        result = evaluate(model, test_loader)\n        result['train_loss'] = torch.stack(train_losses).mean().item()\n        model.epoch_end(epoch, result)\n        history.append(result)\n    print('Training is completed!!')\n    return history","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Fitting the model","metadata":{}},{"cell_type":"code","source":"train_dataloader = get_dataloaders(train_data,BATCH_SIZE,True)\ntest_dataloader = get_dataloaders(test_data,BATCH_SIZE,False)\nhistory = fit(EPOCHS, LEARNING_RATE, model, train_dataloader, test_dataloader,OPT_FUNC)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Plot Loss vs Epoch Curve","metadata":{}},{"cell_type":"code","source":"def plot_losses(history):\n    \"\"\" Plot the losses in each epoch\"\"\"\n    train_losses = [x.get('train_loss') for x in history]\n    test_losses = [x['test_loss'] for x in history]\n    plt.plot(train_losses, '-bx')\n    plt.plot(test_losses, '-rx')\n    plt.xlabel('epoch')\n    plt.ylabel('loss')\n    plt.legend(['Training', 'Testing'])\n    plt.title('Loss vs. No. of epochs');\n\nplot_losses(history)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Saving the model to Output Directory","metadata":{}},{"cell_type":"code","source":"torch.save(model,'/kaggle/working/RegressionBB.pt')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Summary of the test dataset","metadata":{}},{"cell_type":"code","source":"summary('test',test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preprocessing the test dataset ","metadata":{}},{"cell_type":"code","source":"X_val=generate_features_labels(test,'test')\nX_num_test=preprocessing(X_val)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Loading the saved model","metadata":{}},{"cell_type":"code","source":"model_test = torch.load('/kaggle/working/RegressionBB.pt')\nmodel_test.to(device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Defining the Test Dataset class","metadata":{}},{"cell_type":"code","source":"class Data_Test(Dataset):\n    \n    def __init__(self, X_test_data):\n        self.X_test_data = X_test_data\n        \n    def __getitem__(self, index):\n        return self.X_test_data[index]\n        \n    def __len__ (self):\n        return len(self.X_test_data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Generating the yield values for test data","metadata":{}},{"cell_type":"code","source":"def eval_test_data(model,testing_data_dl):\n    yield_target = []\n    model.eval()\n    with torch.no_grad():\n        for X_batch_test in testing_data_dl:\n            X_batch_test = X_batch_test.to(device)\n            y_test_pred = model(X_batch_test)\n            y_pred_tag = torch.round(y_test_pred)\n            yield_target.append(y_pred_tag.cpu().numpy())\n    return [a.squeeze().tolist() for a in yield_target]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Converting test data into Dataloaders ","metadata":{}},{"cell_type":"code","source":"testing_data = Data_Test(convert_to_torch(X_num_test))\ntesting_data_loader = DataLoader(dataset=testing_data, batch_size=BATCH_SIZE)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Creating prediction on test data ","metadata":{}},{"cell_type":"code","source":"def submit_test_data():\n    yield_submission=[]\n    for elements in  eval_test_data(model_test,testing_data_loader):\n        for field in elements:\n            yield_submission.append(field)    \n    return yield_submission","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Saving the file for evaluation","metadata":{}},{"cell_type":"code","source":"yhat = submit_test_data()\ndf_submit = pd.DataFrame(data={'id': test['id'],'yield': yhat})\nconvert_to_torch\nprint('Submission Completed!!')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}