{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/averma111/pss3e17-binary-classification-pytorch?scriptVersionId=134651545\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:#5642C5;\n           font-size:110%;\n           font-family:Verdana;\n           letter-spacing:0.2px\">\n\n<p style=\"padding: 30px;\n              color:white;\">\nBINARY CLASSIFICATION OF MACHINE FAILURES\n</p>\n</div>","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os\nimport datetime\nimport seaborn as sns\nfrom tqdm.notebook import tqdm\n    \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder,StandardScaler\nfrom imblearn.over_sampling import SMOTE,SMOTENC\nfrom sklearn.metrics import confusion_matrix, classification_report, roc_curve, roc_auc_score\n\nimport torch\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader,random_split,Dataset\nfrom torch.utils.tensorboard import SummaryWriter\n\n\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\nplt.style.use('fivethirtyeight')\nimport plotly.express as px\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-06-23T19:28:33.084069Z","iopub.execute_input":"2023-06-23T19:28:33.084503Z","iopub.status.idle":"2023-06-23T19:28:33.097835Z","shell.execute_reply.started":"2023-06-23T19:28:33.08447Z","shell.execute_reply":"2023-06-23T19:28:33.096584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:#5642C5;\n           font-size:110%;\n           font-family:Verdana;\n           letter-spacing:0.2px\">\n\n<p style=\"padding: 30px;\n              color:white;\">\nDIRECTORY LISTING\n</p>\n</div>","metadata":{}},{"cell_type":"code","source":"for dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","metadata":{"execution":{"iopub.status.busy":"2023-06-23T19:28:35.064489Z","iopub.execute_input":"2023-06-23T19:28:35.065366Z","iopub.status.idle":"2023-06-23T19:28:35.074022Z","shell.execute_reply.started":"2023-06-23T19:28:35.065326Z","shell.execute_reply":"2023-06-23T19:28:35.072885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:#5642C5;\n           font-size:110%;\n           font-family:Verdana;\n           letter-spacing:0.2px\">\n\n<p style=\"padding: 30px;\n              color:white;\">\nGENERIC PYTORCH METHODS\n</p>\n</div>","metadata":{}},{"cell_type":"code","source":"class GenericPytorch(object):\n    \n    def __init__(self,model,loss_fun,optimizer):\n        self.model = model\n        self.loss_fun = loss_fun \n        self.optimizer = optimizer\n        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n        self.model.to(self.device)\n        \n        ## Placeholders \n        self.train_loader = None\n        self.val_loader = None\n        self.writer = None\n        \n        #Variables \n        self.losses =[]\n        self.val_losses = []\n        self.total_epoch = 0\n        \n        self.total_correct = 0\n        self.total_samples = 0\n        self.best_loss = np.inf\n        self.patience = 10\n        self.counter = 0\n        \n        #Helper Function\n        self.train_step_fun = self._make_train_step_fun()\n        self.val_step_fun = self._make_val_step_fun()\n        \n        #Metrics\n        self.auc_roc = []\n        \n    def to(self,device):\n        try:\n            self.device = device\n            self.model.to(self.device)\n            \n        except RuntimeError:\n            self.device = ('cuda' if torch.cuda.is_available() else 'cpu')\n            print(f'Could not send it {device}, sending it to {self.device} instead')\n            self.model.to(self.device)\n            \n    \n    def set_loaders(self,train_loader,val_loader=None):\n        self.train_loader = train_loader\n        self.val_loader = val_loader\n        \n        \n    def set_tensorboard(self,name,folder='runs'):\n        suffix = datetime.datetime.now().strftime('%Y%m%d%H%M%S')\n        self.writer = SummaryWriter(f'{folder}/{name}_{suffix}')\n        \n    def _make_train_step_fun(self):\n        \n        def perform_train_step_fun(X,y):\n            # Set the model to train \n            self.model.train()\n            #Step 1 - Forward pass / make  predictions\n            yhat = self.model(X)\n            #Step 2 - Compute loss \n            loss = self.loss_fun(yhat,y)\n            #self._binary_acc(yhat,y)\n            #Step 3 - Compute the gradients\n            loss.backward()\n            #Step 4 - Update the variables and set the gradient to 0\n            self.optimizer.step()\n            self.optimizer.zero_grad()\n            \n            return loss.item()\n        \n        return perform_train_step_fun\n            \n    \n    def _make_val_step_fun(self):\n        \n        def perform_val_step_fun(X,y):\n            # Set the model to train \n            self.model.eval()\n            #Step 1 - Forward pass / make  predictions\n            yhat = self.model(X)\n            #Step 2 - Compute loss \n            loss = self.loss_fun(yhat,y)\n            \n            \n            return loss.item()\n        \n        return perform_val_step_fun\n    \n    \n    def _mini_batch(self,validation=False):\n        \n        if validation:\n            data_loader = self.val_loader\n            step_fun = self.val_step_fun\n        else:\n            data_loader = self.train_loader\n            step_fun = self.train_step_fun\n        \n        if data_loader is None:\n            return None\n        \n        # Loop mini-batch \n        mini_batch_losses =[] \n        for x_batch,y_batch  in data_loader:\n            x_batch = x_batch.to(self.device)\n            y_batch = y_batch.to(self.device)\n            \n            mini_batch_loss = step_fun(x_batch,y_batch.unsqueeze(1))\n            mini_batch_losses.append(mini_batch_loss)\n            loss = np.mean(mini_batch_losses)\n            l2_reg = sum(torch.norm(param) for param in self.model.parameters())\n            loss = loss + 0.001 * l2_reg\n        \n        return loss\n    \n    def set_seed(self,seed=42):\n        torch.backends.cudnn.deterministic = True\n        torch.backends.cudnn.benchmark = False\n        torch.manual_seed(seed)\n        np.random.seed(seed)\n        \n    \n    def train(self,n_epochs,seed=42):\n        #Reproducibility\n        self.set_seed(seed)\n        \n        for epoch in tqdm(range(n_epochs)):\n            self.total_epoch +=1\n            \n            #inner loop perform training using mini_batch\n            loss = self._mini_batch(validation=False)\n            self.losses.append(loss.detach().numpy())\n            \n            #Validation \n            with torch.no_grad():\n                #Perform evaluation using mini-batch\n                val_loss = self._mini_batch(validation=True)\n                self.val_losses.append(val_loss.detach().numpy())\n                \n            #SummaryWriter \n            if self.writer:\n                scalars ={\n                    'training':loss}\n                if val_loss is not None:\n                    scalars.update({'validation':val_loss})\n                    \n            if epoch%10==0:\n                print(f'Epoch=>[{epoch}]||Training Loss:=>{loss:.5f}||Validation Loss:=>{val_loss:.5f}')\n                #Record both losses for each epoch\n                self.writer.add_scalars(main_tag='loss',tag_scalar_dict=scalars,global_step=epoch)\n        \n        print('Training Completed!!')\n                \n                \n        if self.writer:\n            #Flush the writer \n            self.writer.flush()\n        \n    \n    def save_checkpoint(self,filename):\n        #Build the dictionary with all the elements for resuming training\n        checkpoint = {\n            'epoch':self.total_epoch,\n            'model_state_dict':self.model.state_dict(),\n            'optimizer_state_dict': self.optimizer.state_dict(),\n            'loss': self.losses,\n            'val_loss': self.val_losses\n        }\n        \n        torch.save(checkpoint,filename)\n        \n    \n    def load_checkpoint(self, filename):\n        # Loads dictionary\n        checkpoint = torch.load(filename)\n\n        # Restore state for model and optimizer\n        self.model.load_state_dict(checkpoint['model_state_dict'])\n        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n\n        self.total_epochs = checkpoint['epoch']\n        self.losses = checkpoint['loss']\n        self.val_losses = checkpoint['val_loss']\n\n        self.model.train() # always use TRAIN for resuming training   \n\n    def predict(self,model,test_data_dl):\n        \n        probabilities = []\n        with torch.no_grad():\n            for X_batch in test_data_dl:\n                X_batch = X_batch.to(self.device)\n                y_test_pred = model(X_batch)\n                y_test_pred = torch.nn.functional.sigmoid(y_test_pred)\n                y_test_pred = y_test_pred > 0.5\n                y_test_pred = y_test_pred.astype(np.uint8)\n                probabilities.append(y_test_pred.cpu().numpy())\n        return probabilities\n        #return [a.squeeze().tolist() for a in probabilities]\n    \n\n    def plot_losses(self):\n        fig = plt.figure(figsize=(10, 4))\n        plt.plot(self.losses, label='Training Loss', c='b')\n        plt.plot(self.val_losses, label='Validation Loss', c='r')\n        plt.yscale('log')\n        plt.xlabel('Epochs')\n        plt.ylabel('Loss')\n        plt.legend()\n        plt.tight_layout()\n        return fig\n    \n    \n    def get_classification_reprot(self,label,predictions):\n        print(\"Classification Report:\")\n        print(classification_report(label, predictions))\n\n    def get_confusion_matrix(self,label, predictions):\n        self.cm = confusion_matrix(label, predictions)\n        print(\"Confusion Matrix:\")\n        print(self.cm)\n\n    def plot_confusion_matrix(self):\n    # Visualize the confusion matrix\n        plt.figure(figsize=(6, 4))\n        sns.heatmap(self.cm , annot=True, cmap=\"Blues\", fmt=\"d\", cbar=False)\n        plt.title(\"Confusion Matrix\")\n        plt.xlabel(\"Predicted Labels\")\n        plt.ylabel(\"True Labels\")\n        plt.show()\n    \n    def add_graph(self):\n        # Fetches a single mini-batch so we can use add_graph\n        if self.train_loader and self.writer:\n            x_sample, y_sample = next(iter(self.train_loader))\n            self.writer.add_graph(self.model, x_sample.to(self.device))\n        ","metadata":{"execution":{"iopub.status.busy":"2023-06-23T20:20:43.919635Z","iopub.execute_input":"2023-06-23T20:20:43.920103Z","iopub.status.idle":"2023-06-23T20:20:43.964656Z","shell.execute_reply.started":"2023-06-23T20:20:43.920048Z","shell.execute_reply":"2023-06-23T20:20:43.963322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:#5642C5;\n           font-size:110%;\n           font-family:Verdana;\n           letter-spacing:0.2px\">\n\n<p style=\"padding: 30px;\n              color:white;\">\nDATA PREPARATION\n</p>\n</div>","metadata":{}},{"cell_type":"code","source":"class Datapreparation(object):\n    \n    def __init__(self,root_path):\n        self.root_path = root_path\n        \n    def get_dataframe(self,filename):\n        return pd.read_csv(os.path.join(self.root_path,filename))\n    \n    def summary(self,text, df):\n        summary = pd.DataFrame(df.dtypes, columns=['dtypes'])\n        summary['null'] = df.isnull().sum()\n        summary['unique'] = df.nunique()\n        summary['min'] = df.min()\n        summary['median'] = df.median()\n        summary['max'] = df.max()\n        summary['mean'] = df.mean()\n        summary['std'] = df.std()\n        summary['duplicate'] = df.duplicated().sum()\n        return summary\n    \n    def rename_column(self,df):\n        updated_df=df.rename(columns=\n                             {\"Product ID\": \"Product_ID\", \n                              \"Air temperature [K]\": \"Air_temperature\",\n                             \"Process temperature [K]\":\"Process_temperature\",\n                             \"Rotational speed [rpm]\":\"Rotational_speed\",\n                             \"Torque [Nm]\":\"Torque\",\n                             \"Tool wear [min]\":\"Tool_wear\",\n                             \"Machine failure\":\"Machine_failure\"}\n                            )\n        return updated_df\n    \n    def set_label(self,df):\n        self.label = 'Machine_failure'\n        return df[self.label]\n    \n    def set_feature(self,df):\n        #df['TWF'] = df['TWF']+ df['HDF']+df['PWF']+df['OSF']+df['RNF']\n        #encoded_df=pd.get_dummies(df,columns=['Type']) #One-hot encoding\n        encoder = LabelEncoder()\n        df['Type'] = encoder.fit_transform(df['Type'])\n        #df_updated=encoded_df.drop(columns=['HDF','PWF','OSF','RNF'],axis=1)\n        return df\n    \n    \n    def reduce_oversampling(self,X,y):\n        smote_nc = SMOTENC(categorical_features=[0, 6, 7, 8, 9, 10], random_state=42)\n        return smote_nc.fit_resample(X,y)\n\n    \n    \n    def random_split_data(self,X,y):\n        return train_test_split(X, y,test_size=0.20,random_state=42)\n\n \n    def standardization_data(self,X_data):\n        scaler = StandardScaler()\n        std_X_data = scaler.fit_transform(X_data)\n        return std_X_data\n    \n\n    \ndata = Datapreparation('/kaggle/input/playground-series-s3e17')\ntrain=data.get_dataframe('train.csv')\ntrain = data.rename_column(train)\n","metadata":{"execution":{"iopub.status.busy":"2023-06-23T19:28:37.879426Z","iopub.execute_input":"2023-06-23T19:28:37.87984Z","iopub.status.idle":"2023-06-23T19:28:38.128138Z","shell.execute_reply.started":"2023-06-23T19:28:37.87981Z","shell.execute_reply":"2023-06-23T19:28:38.12697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:#5642C5;\n           font-size:110%;\n           font-family:Verdana;\n           letter-spacing:0.2px\">\n\n<p style=\"padding: 30px;\n              color:white;\">\nDATA SUMMARY\n</p>\n</div>","metadata":{}},{"cell_type":"code","source":"data.summary('train',train)","metadata":{"execution":{"iopub.status.busy":"2023-06-23T19:28:39.417768Z","iopub.execute_input":"2023-06-23T19:28:39.418296Z","iopub.status.idle":"2023-06-23T19:28:43.148787Z","shell.execute_reply.started":"2023-06-23T19:28:39.41826Z","shell.execute_reply":"2023-06-23T19:28:43.147493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:#5642C5;\n           font-size:110%;\n           font-family:Verdana;\n           letter-spacing:0.2px\">\n\n<p style=\"padding: 30px;\n              color:white;\">\nEXPLORATORY DATA ANALYSIS\n</p>\n</div>","metadata":{}},{"cell_type":"code","source":"class EDA:\n    \n    def plot_numerical_distributions(self,dataframe, columns_to_plot, num_rows, num_cols):\n        fig, axes = plt.subplots(num_rows, num_cols, figsize=(18, 10))\n        axes = axes.flatten()\n        for i, column in enumerate(columns_to_plot):\n            sns.histplot(data=dataframe, x=column, hue='Type', kde=True, multiple='stack', ax=axes[i])\n            axes[i].set_title(f\"Distribution Plot: {column}\")\n            axes[i].set_xlabel(column)\n            axes[i].legend(title='Type', labels=['L', 'M', 'H'])\n\n        if len(columns_to_plot) < num_rows * num_cols:\n            for j in range(len(columns_to_plot), num_rows * num_cols):\n                fig.delaxes(axes[j])\n        fig.suptitle(\"Distribution Plots for Numerical Features\", fontsize=24, fontweight='bold', y=1.10)\n        fig.tight_layout()\n        plt.show()\n        \n        \n    def plot_machine_reasons(self,trian):\n        reason_columns = ['TWF', 'HDF', 'PWF', 'OSF', 'RNF']\n        failures_data = train[train['Machine_failure'] == 1]\n        reason_counts = failures_data[reason_columns].sum()\n       # Create a colormap\n        cmap = plt.get_cmap('rainbow')\n        colors = cmap(np.linspace(0, 1, len(reason_columns)))\n       # Plot the reason counts\n        plt.figure(figsize=(8, 6))\n        bars = plt.bar(reason_columns, reason_counts, color=colors)\n       # Add count labels on top of each bar\n        for bar in bars:\n            height = bar.get_height()\n            plt.text(bar.get_x() + bar.get_width() / 2, height, str(int(height)), ha='center', va='bottom')\n\n        plt.xlabel('Reasons for Machine Failures')\n        plt.ylabel('Count')\n        plt.title('Reasons for Machine Failures (Machine_failure = 1)')\n        plt.show()\n        \n    def plot_outliers(self,train,numerical_columns):\n        plt.figure(figsize=(12, 8))\n        for i, column in enumerate(numerical_columns):\n            plt.subplot(2, 3, i+1)\n            sns.boxplot(data=train[column])\n            plt.title(f'Boxplot: {column}')\n            plt.xlabel(column)\n        plt.tight_layout()\n        plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-06-23T19:30:11.840607Z","iopub.execute_input":"2023-06-23T19:30:11.841052Z","iopub.status.idle":"2023-06-23T19:30:11.860243Z","shell.execute_reply.started":"2023-06-23T19:30:11.841012Z","shell.execute_reply":"2023-06-23T19:30:11.858825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"eda = EDA()\nnum_rows = 2\nnum_cols = 3\ncolumns_to_plot = ['Air_temperature', 'Process_temperature', 'Rotational_speed', \n                             'Torque', 'Tool_wear']\neda.plot_numerical_distributions(train, columns_to_plot, num_rows, num_cols)","metadata":{"execution":{"iopub.status.busy":"2023-06-23T19:30:12.564823Z","iopub.execute_input":"2023-06-23T19:30:12.565539Z","iopub.status.idle":"2023-06-23T19:30:25.802905Z","shell.execute_reply.started":"2023-06-23T19:30:12.565489Z","shell.execute_reply":"2023-06-23T19:30:25.801482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:#5642C5;\n           font-size:110%;\n           font-family:Verdana;\n           letter-spacing:0.2px\">\n\n<p style=\"padding: 30px;\n              color:white;\">\nREASONS FOR MACHINE FAILURE\n</p>\n</div>","metadata":{}},{"cell_type":"code","source":"eda.plot_machine_reasons(train)","metadata":{"execution":{"iopub.status.busy":"2023-06-23T19:30:39.571462Z","iopub.execute_input":"2023-06-23T19:30:39.571901Z","iopub.status.idle":"2023-06-23T19:30:39.838697Z","shell.execute_reply.started":"2023-06-23T19:30:39.571866Z","shell.execute_reply":"2023-06-23T19:30:39.837158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n\n<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:#5642C5;\n           font-size:110%;\n           font-family:Verdana;\n           letter-spacing:0.2px\">\n\n<p style=\"padding: 30px;\n              color:white;\">\nOUTLIERS\n</p>\n</div>","metadata":{}},{"cell_type":"code","source":"eda.plot_outliers(train,columns_to_plot)","metadata":{"execution":{"iopub.status.busy":"2023-06-23T19:30:47.383083Z","iopub.execute_input":"2023-06-23T19:30:47.383575Z","iopub.status.idle":"2023-06-23T19:30:48.323133Z","shell.execute_reply.started":"2023-06-23T19:30:47.383543Z","shell.execute_reply":"2023-06-23T19:30:48.32179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:#5642C5;\n           font-size:110%;\n           font-family:Verdana;\n           letter-spacing:0.2px\">\n\n<p style=\"padding: 30px;\n              color:white;\">\nFEATURES EXTRACTION\n</p>\n</div>","metadata":{}},{"cell_type":"code","source":"train_updated = data.set_feature(train)\ntrain_updated.drop(columns=['id','Product_ID'],axis=1,inplace=True)\ntrain_updated.head()","metadata":{"execution":{"iopub.status.busy":"2023-06-23T19:31:47.373704Z","iopub.execute_input":"2023-06-23T19:31:47.374108Z","iopub.status.idle":"2023-06-23T19:31:47.443737Z","shell.execute_reply.started":"2023-06-23T19:31:47.374078Z","shell.execute_reply":"2023-06-23T19:31:47.442538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:#5642C5;\n           font-size:110%;\n           font-family:Verdana;\n           letter-spacing:0.2px\">\n\n<p style=\"padding: 30px;\n              color:white;\">\nDATASET SPLITS\n</p>\n</div>","metadata":{}},{"cell_type":"code","source":"y = data.set_label(train)\nX_resampled,y_resampled = data.reduce_oversampling(train_updated,y)\nX_train,X_val,y_train,y_val = data.random_split_data(X_resampled,y_resampled)\nprint(X_train.shape,X_val.shape,y_train.shape,y_val.shape)","metadata":{"execution":{"iopub.status.busy":"2023-06-23T19:31:48.716787Z","iopub.execute_input":"2023-06-23T19:31:48.717273Z","iopub.status.idle":"2023-06-23T19:32:11.829922Z","shell.execute_reply.started":"2023-06-23T19:31:48.717237Z","shell.execute_reply":"2023-06-23T19:32:11.82885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:#5642C5;\n           font-size:110%;\n           font-family:Verdana;\n           letter-spacing:0.2px\">\n\n<p style=\"padding: 30px;\n              color:white;\">\nDATA STANDARDIZATION\n</p>\n</div>","metadata":{}},{"cell_type":"code","source":"std_X_train = data.standardization_data(X_train)\nstd_X_val = data.standardization_data(X_val)\nprint(std_X_train[0],std_X_val[0])","metadata":{"execution":{"iopub.status.busy":"2023-06-23T19:32:37.085545Z","iopub.execute_input":"2023-06-23T19:32:37.085949Z","iopub.status.idle":"2023-06-23T19:32:37.153341Z","shell.execute_reply.started":"2023-06-23T19:32:37.08592Z","shell.execute_reply":"2023-06-23T19:32:37.152152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:#5642C5;\n           font-size:110%;\n           font-family:Verdana;\n           letter-spacing:0.2px\">\n\n<p style=\"padding: 30px;\n              color:white;\">\nGENERIC TENSOR OPERATIONS\n</p>\n</div>","metadata":{}},{"cell_type":"code","source":"class Tensoroperations():\n    \n    def __init__(self):\n        super(Tensoroperations,self).__init__()\n    \n    def convert_to_tensor(self,X,y=None):\n        X_tensor = torch.tensor(X,dtype=torch.float32)\n        y_tensor = torch.tensor(y,dtype=torch.float32)\n        return X_tensor,y_tensor\n        \n    def convert_to_test_tesnor(self,X):\n        X_tensor =  torch.tensor(X,dtype=torch.float32)\n        return X_tensor\n    \n    def get_dataloaders(self,train_dataset,val_dataset):\n        train_loaders = DataLoader(train_dataset,batch_size=256,shuffle=True)\n        val_loaders = DataLoader(val_dataset,batch_size=32)\n        return train_loaders,val_loaders\n    \n    def get_test_dataloaders(self,test_dataset,X_test):\n        test_loaders = DataLoader(test_dataset,batch_size=X_test.shape[0])\n        return test_loaders\n        \n        \n    \ntenops = Tensoroperations()    ","metadata":{"execution":{"iopub.status.busy":"2023-06-23T19:32:38.851106Z","iopub.execute_input":"2023-06-23T19:32:38.851869Z","iopub.status.idle":"2023-06-23T19:32:38.861428Z","shell.execute_reply.started":"2023-06-23T19:32:38.85183Z","shell.execute_reply":"2023-06-23T19:32:38.86051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:#5642C5;\n           font-size:110%;\n           font-family:Verdana;\n           letter-spacing:0.2px\">\n\n<p style=\"padding: 30px;\n              color:white;\">\nCUSTOM DATASETS\n</p>\n</div>","metadata":{}},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    \n    def __init__(self,X_data,y_data=None,is_train=True):\n        super().__init__()\n        if is_train:\n            self.X_data = X_data\n            self.y_data = y_data\n        else:\n            self.X_data=X_train\n            \n    def __getitem__(self,index):\n        return (self.X_data[index],self.y_data[index])\n    \n    def __len__(self):\n        return len(self.X_data)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-06-23T19:32:39.786359Z","iopub.execute_input":"2023-06-23T19:32:39.787003Z","iopub.status.idle":"2023-06-23T19:32:39.793948Z","shell.execute_reply.started":"2023-06-23T19:32:39.786969Z","shell.execute_reply":"2023-06-23T19:32:39.792923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:#5642C5;\n           font-size:110%;\n           font-family:Verdana;\n           letter-spacing:0.2px\">\n\n<p style=\"padding: 30px;\n              color:white;\">\nTENSOR PREPARATION\n</p>\n</div>","metadata":{}},{"cell_type":"code","source":"X_tensor_train,y_tensor_train = tenops.convert_to_tensor(std_X_train,y_train.values)\nX_tensor_val,y_tensor_val = tenops.convert_to_tensor(std_X_val,y_val.values)\nprint('The training tensor\\n',X_tensor_train,y_tensor_train)\nprint('The validation tensor\\n',X_tensor_val,y_tensor_val)","metadata":{"execution":{"iopub.status.busy":"2023-06-23T19:32:41.931392Z","iopub.execute_input":"2023-06-23T19:32:41.93201Z","iopub.status.idle":"2023-06-23T19:32:41.947577Z","shell.execute_reply.started":"2023-06-23T19:32:41.931963Z","shell.execute_reply":"2023-06-23T19:32:41.945989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = CustomDataset(X_tensor_train,y_tensor_train)\nval_dataset = CustomDataset(X_tensor_val,y_tensor_val)","metadata":{"execution":{"iopub.status.busy":"2023-06-23T19:32:46.604634Z","iopub.execute_input":"2023-06-23T19:32:46.605146Z","iopub.status.idle":"2023-06-23T19:32:46.611552Z","shell.execute_reply.started":"2023-06-23T19:32:46.605095Z","shell.execute_reply":"2023-06-23T19:32:46.610366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:#5642C5;\n           font-size:110%;\n           font-family:Verdana;\n           letter-spacing:0.2px\">\n\n<p style=\"padding: 30px;\n              color:white;\">\nDATA LOADERS\n</p>\n</div>","metadata":{}},{"cell_type":"code","source":"train_loaders,val_loaders=tenops.get_dataloaders(train_dataset,val_dataset)\nprint(next(iter(train_loaders)))","metadata":{"execution":{"iopub.status.busy":"2023-06-23T19:32:49.486527Z","iopub.execute_input":"2023-06-23T19:32:49.487475Z","iopub.status.idle":"2023-06-23T19:32:49.521523Z","shell.execute_reply.started":"2023-06-23T19:32:49.487437Z","shell.execute_reply":"2023-06-23T19:32:49.52029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:#5642C5;\n           font-size:110%;\n           font-family:Verdana;\n           letter-spacing:0.2px\">\n\n<p style=\"padding: 30px;\n              color:white;\">\nBINARY CLASSIFICATION DEEP MODEL\n</p>\n</div>","metadata":{}},{"cell_type":"code","source":"class BinaryClassificationNN(torch.nn.Module):\n    \n    def __init__(self,in_features,out_features):\n        super(BinaryClassificationNN, self).__init__()\n        self.model = torch.nn.Sequential(\n            torch.nn.Linear(in_features, 32),\n            torch.nn.ReLU(),\n            torch.nn.Linear(32, 16),\n            torch.nn.ReLU(),\n            torch.nn.Linear(16, 8),\n            torch.nn.ReLU(),\n            torch.nn.Linear(8, 4),\n            torch.nn.ReLU(),\n            torch.nn.Linear(4, out_features),\n            torch.nn.Sigmoid()\n)\n    def forward(self, X):\n        y = self.model(X)\n        return y\n    \n\nbinary_model = BinaryClassificationNN(X_train.shape[1],1)\nprint(binary_model.state_dict())","metadata":{"execution":{"iopub.status.busy":"2023-06-23T19:32:58.72709Z","iopub.execute_input":"2023-06-23T19:32:58.727501Z","iopub.status.idle":"2023-06-23T19:32:58.753497Z","shell.execute_reply.started":"2023-06-23T19:32:58.727471Z","shell.execute_reply":"2023-06-23T19:32:58.752657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:#5642C5;\n           font-size:110%;\n           font-family:Verdana;\n           letter-spacing:0.2px\">\n\n<p style=\"padding: 30px;\n              color:white;\">\nTRAINING MODE\n</p>\n</div>","metadata":{}},{"cell_type":"code","source":"torch.manual_seed(42)\nloss_fun = torch.nn.BCELoss()\noptimizer = torch.optim.Adam(binary_model.parameters(), lr=1e-4)\n\n\ngpy = GenericPytorch(binary_model,loss_fun,optimizer)\ngpy.set_loaders(train_loaders,val_loaders)","metadata":{"execution":{"iopub.status.busy":"2023-06-23T20:21:13.899732Z","iopub.execute_input":"2023-06-23T20:21:13.900924Z","iopub.status.idle":"2023-06-23T20:21:13.909177Z","shell.execute_reply.started":"2023-06-23T20:21:13.900876Z","shell.execute_reply":"2023-06-23T20:21:13.907784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(gpy.model)","metadata":{"execution":{"iopub.status.busy":"2023-06-23T20:21:15.05474Z","iopub.execute_input":"2023-06-23T20:21:15.055189Z","iopub.status.idle":"2023-06-23T20:21:15.061115Z","shell.execute_reply.started":"2023-06-23T20:21:15.055156Z","shell.execute_reply":"2023-06-23T20:21:15.059728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:#5642C5;\n           font-size:110%;\n           font-family:Verdana;\n           letter-spacing:0.2px\">\n\n<p style=\"padding: 30px;\n              color:white;\">\nBINARY CLASSIFICATION MODEL TRAININIG\n</p>\n</div>","metadata":{}},{"cell_type":"code","source":"gpy.train(n_epochs=100)","metadata":{"execution":{"iopub.status.busy":"2023-06-23T19:33:12.722498Z","iopub.execute_input":"2023-06-23T19:33:12.722933Z","iopub.status.idle":"2023-06-23T19:43:40.762988Z","shell.execute_reply.started":"2023-06-23T19:33:12.722902Z","shell.execute_reply":"2023-06-23T19:43:40.76186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:#5642C5;\n           font-size:110%;\n           font-family:Verdana;\n           letter-spacing:0.2px\">\n\n<p style=\"padding: 30px;\n              color:white;\">\nLOSS PLOT\n</p>\n</div>","metadata":{}},{"cell_type":"code","source":"fig= gpy.plot_losses()","metadata":{"execution":{"iopub.status.busy":"2023-06-23T19:07:12.630605Z","iopub.execute_input":"2023-06-23T19:07:12.631722Z","iopub.status.idle":"2023-06-23T19:07:13.321552Z","shell.execute_reply.started":"2023-06-23T19:07:12.631669Z","shell.execute_reply":"2023-06-23T19:07:13.320279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:#5642C5;\n           font-size:110%;\n           font-family:Verdana;\n           letter-spacing:0.2px\">\n\n<p style=\"padding: 30px;\n              color:white;\">\nSAVING MODEL CHECKPOINT\n</p>\n</div>","metadata":{}},{"cell_type":"code","source":"gpy.save_checkpoint('model_checkpoint.pth')","metadata":{"execution":{"iopub.status.busy":"2023-06-23T19:07:13.329707Z","iopub.execute_input":"2023-06-23T19:07:13.330942Z","iopub.status.idle":"2023-06-23T19:07:13.35632Z","shell.execute_reply.started":"2023-06-23T19:07:13.33089Z","shell.execute_reply":"2023-06-23T19:07:13.355087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:#5642C5;\n           font-size:110%;\n           font-family:Verdana;\n           letter-spacing:0.2px\">\n\n<p style=\"padding: 30px;\n              color:white;\">\nLOADING MODEL CHECKPOINT\n</p>\n</div>","metadata":{}},{"cell_type":"code","source":"gpy.load_checkpoint('model_checkpoint.pth')","metadata":{"execution":{"iopub.status.busy":"2023-06-23T19:07:13.357984Z","iopub.execute_input":"2023-06-23T19:07:13.358395Z","iopub.status.idle":"2023-06-23T19:07:13.374671Z","shell.execute_reply.started":"2023-06-23T19:07:13.358361Z","shell.execute_reply":"2023-06-23T19:07:13.373078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:#5642C5;\n           font-size:110%;\n           font-family:Verdana;\n           letter-spacing:0.2px\">\n\n<p style=\"padding: 30px;\n              color:white;\">\nTEST DATA PREPARATION\n</p>\n</div>","metadata":{}},{"cell_type":"code","source":"test=data.get_dataframe('test.csv')\ntest = data.rename_column(test)\ntest.head()","metadata":{"execution":{"iopub.status.busy":"2023-06-23T19:45:37.434793Z","iopub.execute_input":"2023-06-23T19:45:37.435256Z","iopub.status.idle":"2023-06-23T19:45:37.584762Z","shell.execute_reply.started":"2023-06-23T19:45:37.435222Z","shell.execute_reply":"2023-06-23T19:45:37.583513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:#5642C5;\n           font-size:110%;\n           font-family:Verdana;\n           letter-spacing:0.2px\">\n\n<p style=\"padding: 30px;\n              color:white;\">\nTEST DATASET SUMMARY\n</p>\n</div>","metadata":{}},{"cell_type":"code","source":"data.summary('test',test)","metadata":{"execution":{"iopub.status.busy":"2023-06-23T19:45:39.63298Z","iopub.execute_input":"2023-06-23T19:45:39.633387Z","iopub.status.idle":"2023-06-23T19:45:41.376291Z","shell.execute_reply.started":"2023-06-23T19:45:39.633356Z","shell.execute_reply":"2023-06-23T19:45:41.374907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_updated = data.set_feature(test)\ntest_updated.drop(columns=['Product_ID'],axis=1,inplace=True)\ntest_updated","metadata":{"execution":{"iopub.status.busy":"2023-06-23T19:45:41.378682Z","iopub.execute_input":"2023-06-23T19:45:41.379833Z","iopub.status.idle":"2023-06-23T19:45:41.440536Z","shell.execute_reply.started":"2023-06-23T19:45:41.379785Z","shell.execute_reply":"2023-06-23T19:45:41.43907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.summary('test',test_updated)","metadata":{"execution":{"iopub.status.busy":"2023-06-23T19:45:41.442182Z","iopub.execute_input":"2023-06-23T19:45:41.443239Z","iopub.status.idle":"2023-06-23T19:45:41.537846Z","shell.execute_reply.started":"2023-06-23T19:45:41.443176Z","shell.execute_reply":"2023-06-23T19:45:41.536811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:#5642C5;\n           font-size:110%;\n           font-family:Verdana;\n           letter-spacing:0.2px\">\n\n<p style=\"padding: 30px;\n              color:white;\">\nTEST DATA NORMALIZATION\n</p>\n</div>","metadata":{}},{"cell_type":"code","source":"std_X_test = data.standardization_data(test_updated)\nprint(std_X_test[0])","metadata":{"execution":{"iopub.status.busy":"2023-06-23T19:45:43.083976Z","iopub.execute_input":"2023-06-23T19:45:43.084465Z","iopub.status.idle":"2023-06-23T19:45:43.113064Z","shell.execute_reply.started":"2023-06-23T19:45:43.084431Z","shell.execute_reply":"2023-06-23T19:45:43.111825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:#5642C5;\n           font-size:110%;\n           font-family:Verdana;\n           letter-spacing:0.2px\">\n\n<p style=\"padding: 30px;\n              color:white;\">\nTEST TENSOR OPERATIONS\n</p>\n</div>","metadata":{}},{"cell_type":"code","source":"X_tensor_test = tenops.convert_to_test_tesnor(std_X_test)\nprint('The training tensor\\n',X_tensor_train)\n","metadata":{"execution":{"iopub.status.busy":"2023-06-23T19:45:44.754162Z","iopub.execute_input":"2023-06-23T19:45:44.754596Z","iopub.status.idle":"2023-06-23T19:45:44.763311Z","shell.execute_reply.started":"2023-06-23T19:45:44.754562Z","shell.execute_reply":"2023-06-23T19:45:44.761757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CustomDatasetTest(Dataset):\n    \n    def __init__(self,X_data):\n        super().__init__()\n        self.X_data=X_data\n            \n    def __getitem__(self,index):\n        return self.X_data[index]\n    \n    def __len__(self):\n        return len(self.X_data)","metadata":{"execution":{"iopub.status.busy":"2023-06-23T19:45:46.148036Z","iopub.execute_input":"2023-06-23T19:45:46.148458Z","iopub.status.idle":"2023-06-23T19:45:46.15525Z","shell.execute_reply.started":"2023-06-23T19:45:46.148423Z","shell.execute_reply":"2023-06-23T19:45:46.154103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:#5642C5;\n           font-size:110%;\n           font-family:Verdana;\n           letter-spacing:0.2px\">\n\n<p style=\"padding: 30px;\n              color:white;\">\nTEST DATASET AND DATA LOADER\n</p>\n</div>","metadata":{}},{"cell_type":"code","source":"test_dataset = CustomDatasetTest(X_tensor_train)\ntest_loaders=tenops.get_test_dataloaders(test_dataset,std_X_test)\nprint(next(iter(test_loaders)))","metadata":{"execution":{"iopub.status.busy":"2023-06-23T19:45:47.390294Z","iopub.execute_input":"2023-06-23T19:45:47.390724Z","iopub.status.idle":"2023-06-23T19:45:48.211238Z","shell.execute_reply.started":"2023-06-23T19:45:47.39069Z","shell.execute_reply":"2023-06-23T19:45:48.209679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:#5642C5;\n           font-size:110%;\n           font-family:Verdana;\n           letter-spacing:0.2px\">\n\n<p style=\"padding: 40px;\n              color:white;\">\nSUBMISSIONS\n</p>\n</div>","metadata":{}},{"cell_type":"code","source":"class Submit:\n    \n    def submit_predictions(self):\n        probability = gpy.predict(gpy.model,test_loaders) \n        df_submit = pd.DataFrame(data={'id': test_updated['id'],'Machine Failure': probability[0]})\n        df_submit.to_csv('submission.csv',index=False)\n        print('Submission Completed!!')\n        return df_submit\n        \n        \nsubmit = Submit()\ndf_submit=submit.submit_predictions()","metadata":{"execution":{"iopub.status.busy":"2023-06-23T19:07:23.61752Z","iopub.execute_input":"2023-06-23T19:07:23.617953Z","iopub.status.idle":"2023-06-23T19:07:25.173507Z","shell.execute_reply.started":"2023-06-23T19:07:23.617919Z","shell.execute_reply":"2023-06-23T19:07:25.172295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:#5642C5;\n           font-size:110%;\n           font-family:Verdana;\n           letter-spacing:0.2px\">\n\n<p style=\"padding: 30px;\n              color:white;\">\nSUBMISSION VERIFICATIONS\n</p>\n</div>","metadata":{}},{"cell_type":"code","source":"df_submit.head()","metadata":{"execution":{"iopub.status.busy":"2023-06-23T19:07:25.175099Z","iopub.execute_input":"2023-06-23T19:07:25.175528Z","iopub.status.idle":"2023-06-23T19:07:25.185926Z","shell.execute_reply.started":"2023-06-23T19:07:25.175498Z","shell.execute_reply":"2023-06-23T19:07:25.18502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}