{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/averma111/pss3e17-binary-classification-pytorch?scriptVersionId=134187374\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"%%capture \n!pip install torchmetrics","metadata":{"execution":{"iopub.status.busy":"2023-06-20T02:20:42.176058Z","iopub.execute_input":"2023-06-20T02:20:42.176444Z","iopub.status.idle":"2023-06-20T02:20:53.178868Z","shell.execute_reply.started":"2023-06-20T02:20:42.176412Z","shell.execute_reply":"2023-06-20T02:20:53.177482Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os\nimport datetime\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\nimport torch\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader,random_split,Dataset\nfrom torch.utils.tensorboard import SummaryWriter\nfrom torchmetrics import AUROC\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\nplt.style.use('fivethirtyeight')\nimport plotly.express as px\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-06-20T02:20:53.181665Z","iopub.execute_input":"2023-06-20T02:20:53.18237Z","iopub.status.idle":"2023-06-20T02:20:53.194448Z","shell.execute_reply.started":"2023-06-20T02:20:53.182282Z","shell.execute_reply":"2023-06-20T02:20:53.193251Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"markdown","source":"### Directory listing","metadata":{}},{"cell_type":"code","source":"for dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","metadata":{"execution":{"iopub.status.busy":"2023-06-20T02:20:53.196187Z","iopub.execute_input":"2023-06-20T02:20:53.197074Z","iopub.status.idle":"2023-06-20T02:20:53.208826Z","shell.execute_reply.started":"2023-06-20T02:20:53.197039Z","shell.execute_reply":"2023-06-20T02:20:53.207938Z"},"trusted":true},"execution_count":61,"outputs":[{"name":"stdout","text":"/kaggle/input/playground-series-s3e17/sample_submission.csv\n/kaggle/input/playground-series-s3e17/train.csv\n/kaggle/input/playground-series-s3e17/test.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Generic Pytorch Methods","metadata":{}},{"cell_type":"code","source":"class GenericPytorch(object):\n    \n    def __init__(self,model,loss_fun,optimizer):\n        self.model = model\n        self.loss_fun = loss_fun \n        self.optimizer = optimizer\n        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n        self.model.to(self.device)\n        \n        ## Placeholders \n        self.train_loader = None\n        self.val_loader = None\n        self.writer = None\n        \n        #Variables \n        self.losses =[]\n        self.val_losses = []\n        self.total_epoch = 0\n        \n        #Helper Function\n        self.train_step_fun = self._make_train_step_fun()\n        self.val_step_fun = self._make_val_step_fun()\n        \n        #Metrics\n        self.auc_roc = []\n        \n    def to(self,device):\n        try:\n            self.device = device\n            self.model.to(self.device)\n            \n        except RuntimeError:\n            self.device = ('cuda' if torch.cuda.is_available() else 'cpu')\n            print(f'Could not send it {device}, sending it to {self.device} instead')\n            self.model.to(self.device)\n            \n    \n    def set_loaders(self,train_loader,val_loader=None):\n        self.train_loader = train_loader\n        self.val_loader = val_loader\n        \n        \n    def set_tensorboard(self,name,folder='runs'):\n        suffix = datetime.datetime.now().strftime('%Y%m%d%H%M%S')\n        self.writer = SummaryWriter(f'{folder}/{name}_{suffix}')\n        \n    def _make_train_step_fun(self):\n        \n        def perform_train_step_fun(X,y):\n            # Set the model to train \n            self.model.train()\n            #Step 1 - Forward pass / make  predictions\n            yhat = self.model(X)\n            #Step 2 - Compute loss \n            loss = self.loss_fun(yhat,y)\n            #Step 3 - Compute the gradients\n            loss.backward()\n            #Step 4 - Update the variables and set the gradient to 0\n            self.optimizer.step()\n            self.optimizer.zero_grad()\n            \n            return loss.item()\n        \n        return perform_train_step_fun\n            \n    \n    def _make_val_step_fun(self):\n        \n        def perform_val_step_fun(X,y):\n            # Set the model to train \n            self.model.eval()\n            #Step 1 - Forward pass / make  predictions\n            yhat = self.model(X)\n            #Step 2 - Compute loss \n            loss = self.loss_fun(yhat,y)\n            \n            self._auc_roc_metrics(yhat,y)\n            \n            return loss.item()\n        \n        return perform_val_step_fun\n    \n    \n    def _mini_batch(self,validation=False):\n        \n        if validation:\n            data_loader = self.val_loader\n            step_fun = self.val_step_fun\n        else:\n            data_loader = self.train_loader\n            step_fun = self.train_step_fun\n        \n        if data_loader is None:\n            return None\n        \n        # Loop mini-batch \n        mini_batch_losses =[] \n        for x_batch,y_batch  in data_loader:\n            x_batch = x_batch.to(self.device)\n            y_batch = y_batch.to(self.device)\n            \n            mini_batch_loss = step_fun(x_batch,y_batch.unsqueeze(1))\n            mini_batch_losses.append(mini_batch_loss)\n            \n        loss = np.mean(mini_batch_losses)\n        \n        return loss\n    \n    def set_seed(self,seed=42):\n        torch.backends.cudnn.deterministic = True\n        torch.backends.cudnn.benchmark = False\n        torch.manual_seed(seed)\n        np.random.seed(seed)\n        \n    \n    def train(self,n_epochs,seed=42):\n        #Reproducibility\n        self.set_seed(seed)\n        \n        for epoch in range(n_epochs):\n            self.total_epoch +=1\n            \n            #inner loop perform training using mini_batch\n            loss = self._mini_batch(validation=False)\n            self.losses.append(loss)\n            \n            #Validation \n            with torch.no_grad():\n                #Perform evaluation using mini-batch\n                val_loss = self._mini_batch(validation=True)\n                self.val_losses.append(val_loss)\n                \n            #SummaryWriter \n            if self.writer:\n                scalars ={\n                    'training':loss}\n                if val_loss is not None:\n                    scalars.update({'validation':val_loss})\n                    \n                #Record both losses for each epoch\n                self.writer.add_scalars(main_tag='loss',tag_scalar_dict=scalars,global_step=epoch)\n                \n                \n        if self.writer:\n            #Flush the writer \n            self.writer.flush()\n        \n    \n    def save_checkpoint(self,filename):\n        #Build the dictionary with all the elements for resuming training\n        checkpoint = {\n            'epoch':self.total_epoch,\n            'model_state_dict':self.model.state_dict(),\n            'optimizer_state_dict': self.optimizer.state_dict(),\n            'loss': self.losses,\n            'val_loss': self.val_losses\n        }\n        \n        torch.save(checkpoint,filename)\n        \n    \n    def load_checkpoint(self, filename):\n        # Loads dictionary\n        checkpoint = torch.load(filename)\n\n        # Restore state for model and optimizer\n        self.model.load_state_dict(checkpoint['model_state_dict'])\n        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n\n        self.total_epochs = checkpoint['epoch']\n        self.losses = checkpoint['loss']\n        self.val_losses = checkpoint['val_loss']\n\n        self.model.train() # always use TRAIN for resuming training   \n\n    def predict(self,model,test_data_dl):\n        probabilities = []\n        model.eval()\n        with torch.no_grad():\n            for X_batch_test in test_data_dl:\n                X_batch_test = X_batch_test.to(self.device)\n                y_test_pred = model(X_batch_test)\n                probabilities.append(y_test_pred.cpu().round(decimals=1).numpy())\n                \n        return probabilities\n\n    def plot_losses(self):\n        fig = plt.figure(figsize=(10, 4))\n        plt.plot(self.losses, label='Training Loss', c='b')\n        plt.plot(self.val_losses, label='Validation Loss', c='r')\n        plt.yscale('log')\n        plt.xlabel('Epochs')\n        plt.ylabel('Loss')\n        plt.legend()\n        plt.tight_layout()\n        return fig\n    \n    def _auc_roc_metrics(self,preds,target):\n        auroc = AUROC(task=\"binary\")\n        self.auc_roc.append(auroc(preds, target).cpu())\n     \n    \n    def plot_metrics(self):\n        fig = plt.figure(figsize=(8, 2))\n        plt.plot(self.auc_roc, label='AUR_ROC', c='b')\n        plt.xlabel('Accuracy')\n        plt.ylabel('Epochs')\n        plt.legend()\n        plt.tight_layout()\n        \n        \n\n    def add_graph(self):\n        # Fetches a single mini-batch so we can use add_graph\n        if self.train_loader and self.writer:\n            x_sample, y_sample = next(iter(self.train_loader))\n            self.writer.add_graph(self.model, x_sample.to(self.device))\n        ","metadata":{"execution":{"iopub.status.busy":"2023-06-20T02:20:53.212456Z","iopub.execute_input":"2023-06-20T02:20:53.21287Z","iopub.status.idle":"2023-06-20T02:20:53.246748Z","shell.execute_reply.started":"2023-06-20T02:20:53.212843Z","shell.execute_reply":"2023-06-20T02:20:53.245826Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"markdown","source":"###  Data preparation","metadata":{}},{"cell_type":"code","source":"class Datapreparation(object):\n    \n    def __init__(self,root_path):\n        self.root_path = root_path\n        \n    def get_dataframe(self,filename):\n        return pd.read_csv(os.path.join(self.root_path,filename))\n    \n    def summary(self,text, df):\n        summary = pd.DataFrame(df.dtypes, columns=['dtypes'])\n        summary['null'] = df.isnull().sum()\n        summary['unique'] = df.nunique()\n        summary['min'] = df.min()\n        summary['median'] = df.median()\n        summary['max'] = df.max()\n        summary['mean'] = df.mean()\n        summary['std'] = df.std()\n        summary['duplicate'] = df.duplicated().sum()\n        return summary\n    \n    def rename_column(self,df):\n        updated_df=df.rename(columns=\n                             {\"Product ID\": \"Product_ID\", \n                              \"Air temperature [K]\": \"Air_temperature\",\n                             \"Process temperature [K]\":\"Process_temperature\",\n                             \"Rotational speed [rpm]\":\"Rotational_speed\",\n                             \"Torque [Nm]\":\"Torque\",\n                             \"Tool wear [min]\":\"Tool_wear\",\n                             \"Machine failure\":\"Machine_failure\"}\n                            )\n        return updated_df\n    \n    def set_label(self,df):\n        self.label = 'Machine_failure'\n        return df[self.label]\n    \n    def set_feature(self,df):\n        df['TWF'] = df['TWF']+ df['HDF']+df['PWF']+df['OSF']+df['RNF']\n        encoded_df=pd.get_dummies(df,columns=['Type']) #One-hot encoding\n        df_updated=encoded_df.drop(columns=['HDF','PWF','OSF','RNF'],axis=1)\n        return df_updated\n    \n    \n    def random_split_data(self,X,y):\n        return train_test_split(X, y,test_size=0.20,random_state=42)\n\n \n    def standardization_data(self,X_data):\n        scaler = StandardScaler()\n        std_X_data = scaler.fit_transform(X_data)\n        return std_X_data\n    \n\n    \ndata = Datapreparation('/kaggle/input/playground-series-s3e17')\ntrain=data.get_dataframe('train.csv')\ntrain = data.rename_column(train)\n","metadata":{"execution":{"iopub.status.busy":"2023-06-20T02:20:53.248249Z","iopub.execute_input":"2023-06-20T02:20:53.248619Z","iopub.status.idle":"2023-06-20T02:20:53.448753Z","shell.execute_reply.started":"2023-06-20T02:20:53.248589Z","shell.execute_reply":"2023-06-20T02:20:53.447738Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"markdown","source":"### Data Summary","metadata":{}},{"cell_type":"code","source":"data.summary('train',train)","metadata":{"execution":{"iopub.status.busy":"2023-06-20T02:20:53.450362Z","iopub.execute_input":"2023-06-20T02:20:53.450709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Distribution Plots","metadata":{}},{"cell_type":"code","source":"class Plotdata(object):\n    \n    def plot_kde_data(self,df,field):\n        sns.kdeplot(data=df[field])\n        \n    def count_plot(self,df,field):\n        sns.countplot(x=df[field])\n        \n \nplot = Plotdata()\nplot.plot_kde_data(train,'Air_temperature')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot.plot_kde_data(train,'Process_temperature')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot.plot_kde_data(train,'Rotational_speed')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot.plot_kde_data(train,'Torque')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot.plot_kde_data(train,'Tool_wear')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Count Plots","metadata":{}},{"cell_type":"code","source":"plot.count_plot(train,'Type')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot.count_plot(train,'Machine_failure')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot.count_plot(train,'TWF')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot.count_plot(train,'HDF')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot.count_plot(train,'PWF')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot.count_plot(train,'OSF')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot.count_plot(train,'RNF')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_updated = data.set_feature(train)\ntrain_updated.drop(columns=['id','Product_ID','Machine_failure'],axis=1,inplace=True)\ntrain_updated.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = data.set_label(train)\nX_train,X_val,y_train,y_val = data.random_split_data(train_updated,y)\nprint(X_train.shape,X_val.shape,y_train.shape,y_val.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data Standardization","metadata":{}},{"cell_type":"code","source":"std_X_train = data.standardization_data(X_train)\nstd_X_val = data.standardization_data(X_val)\nprint(std_X_train[0],std_X_val[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Generic Tensor operations","metadata":{}},{"cell_type":"code","source":"class Tensoroperations():\n    \n    def __init__(self):\n        super(Tensoroperations,self).__init__()\n    \n    def convert_to_tensor(self,X,y=None):\n        X_tensor = torch.as_tensor(X).float()\n        y_tensor = torch.as_tensor(y).float()\n        return X_tensor,y_tensor\n        \n    def convert_to_test_tesnor(self,X):\n        X_tensor = torch.as_tensor(X).float()\n        return X_tensor\n    \n    def get_dataloaders(self,train_dataset,val_dataset):\n        train_loaders = DataLoader(train_dataset,batch_size=32,shuffle=True)\n        val_loaders = DataLoader(val_dataset,batch_size=32)\n        return train_loaders,val_loaders\n    \n    def get_test_dataloaders(self,test_dataset,X_test):\n        test_loaders = DataLoader(test_dataset,batch_size=X_test.shape[0])\n        return test_loaders\n        \n        \n    \ntenops = Tensoroperations()    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    \n    def __init__(self,X_data,y_data=None,is_train=True):\n        super().__init__()\n        if is_train:\n            self.X_data = X_data\n            self.y_data = y_data\n        else:\n            self.X_data=X_train\n            \n    def __getitem__(self,index):\n        return (self.X_data[index],self.y_data[index])\n    \n    def __len__(self):\n        return len(self.X_data)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Preparing tensors","metadata":{}},{"cell_type":"code","source":"X_tensor_train,y_tensor_train = tenops.convert_to_tensor(std_X_train,y_train.values)\nX_tensor_val,y_tensor_val = tenops.convert_to_tensor(std_X_val,y_val.values)\nprint('The training tensor\\n',X_tensor_train,y_tensor_train)\nprint('The validation tensor\\n',X_tensor_val,y_tensor_val)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = CustomDataset(X_tensor_train,y_tensor_train)\nval_dataset = CustomDataset(X_tensor_val,y_tensor_val)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data Loaders","metadata":{}},{"cell_type":"code","source":"train_loaders,val_loaders=tenops.get_dataloaders(train_dataset,val_dataset)\nprint(next(iter(train_loaders)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model","metadata":{}},{"cell_type":"code","source":"class BinaryClassificationNN(torch.nn.Module):\n    \n    def __init__(self,in_features,out_label):\n        super().__init__()\n        self.layer1 = torch.nn.Linear(in_features, 16)\n        self.act1 = torch.nn.ReLU()\n        self.layer2 = torch.nn.Linear(16, 16)\n        self.act2 = torch.nn.ReLU()\n        self.layer3 = torch.nn.Linear(16, 16)\n        self.act3 = torch.nn.ReLU()\n        self.output = torch.nn.Linear(16, out_label)\n        self.sigmoid = torch.nn.Sigmoid()\n        #self.softmax = torch.nn.Softmax()\n \n    def forward(self, x):\n        x = self.act1(self.layer1(x))\n        x = self.act2(self.layer2(x))\n        x = self.act3(self.layer3(x))\n        x = self.sigmoid(self.output(x))\n        return x\n    \n\nbinary_model = BinaryClassificationNN(X_train.shape[1],1)\nprint(binary_model.state_dict())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Setting model to training mode","metadata":{}},{"cell_type":"code","source":"torch.manual_seed(42)\nloss_fun = torch.nn.BCELoss()\noptimizer = torch.optim.Adam(binary_model.parameters(), lr=0.0001)\n\n\ngpy = GenericPytorch(binary_model,loss_fun,optimizer)\ngpy.set_loaders(train_loaders,val_loaders)\ngpy.set_tensorboard('Binary_Classification')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(gpy.model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Traning Model","metadata":{}},{"cell_type":"code","source":"gpy.train(n_epochs=100)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Plotting the losses","metadata":{}},{"cell_type":"code","source":"fig= gpy.plot_losses()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Plotting Accuracy","metadata":{}},{"cell_type":"code","source":"gpy.plot_metrics()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Saving the model checkpoint","metadata":{}},{"cell_type":"code","source":"gpy.save_checkpoint('model_checkpoint.pth')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Loading the model checkpoint","metadata":{}},{"cell_type":"code","source":"gpy.load_checkpoint('model_checkpoint.pth')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Adding Tensorboard graphs","metadata":{}},{"cell_type":"code","source":"gpy.add_graph()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Loading Tensorboard extensions","metadata":{}},{"cell_type":"code","source":"%load_ext tensorboard\n%tensorboard --logdir runs --host localhost","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model Evaluation","metadata":{}},{"cell_type":"code","source":"test=data.get_dataframe('test.csv')\ntest = data.rename_column(test)\ntest.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Test data summary","metadata":{}},{"cell_type":"code","source":"data.summary('test',test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_updated = data.set_feature(test)\ntest_updated.drop(columns=['Product_ID'],axis=1,inplace=True)\ntest_updated.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Test Data normalization","metadata":{}},{"cell_type":"code","source":"std_X_test = data.standardization_data(test_updated)\nprint(std_X_test[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Tensor operation","metadata":{}},{"cell_type":"code","source":"X_tensor_test = tenops.convert_to_test_tesnor(std_X_test)\nprint('The training tensor\\n',X_tensor_train)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CustomDatasetTest(Dataset):\n    \n    def __init__(self,X_data):\n        super().__init__()\n        self.X_data=X_data\n            \n    def __getitem__(self,index):\n        return self.X_data[index]\n    \n    def __len__(self):\n        return len(self.X_data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Test Dataseta and DataLoader","metadata":{}},{"cell_type":"code","source":"test_dataset = CustomDatasetTest(X_tensor_train)\ntest_loaders=tenops.get_test_dataloaders(test_dataset,std_X_test)\nprint(next(iter(test_loaders)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Predictions","metadata":{}},{"cell_type":"code","source":"predictions = gpy.predict(gpy.model,test_loaders)\npreictions","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Submission","metadata":{}},{"cell_type":"code","source":"submission = pd.DataFrame([{'id':test['id'],'Machine failure':predictions[0]}])\nsubmission.to_csv('submission.csv',index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}