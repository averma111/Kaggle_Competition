{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/averma111/raytune-pytorch-sample?scriptVersionId=132151091\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"%%capture\n!pip install ray torch torchvision","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-06-03T17:52:08.419516Z","iopub.execute_input":"2023-06-03T17:52:08.420117Z","iopub.status.idle":"2023-06-03T17:52:21.322211Z","shell.execute_reply.started":"2023-06-03T17:52:08.420086Z","shell.execute_reply":"2023-06-03T17:52:21.320827Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport os\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom filelock import FileLock\nfrom torch.utils.data import random_split\nimport torchvision\nimport torchvision.transforms as transforms\nimport ray\nfrom ray import tune\nfrom ray.air import session\nfrom ray.air.checkpoint import Checkpoint\nfrom ray.tune.schedulers import ASHAScheduler","metadata":{"execution":{"iopub.status.busy":"2023-06-03T17:52:44.397423Z","iopub.execute_input":"2023-06-03T17:52:44.397841Z","iopub.status.idle":"2023-06-03T17:52:49.686682Z","shell.execute_reply.started":"2023-06-03T17:52:44.397806Z","shell.execute_reply":"2023-06-03T17:52:49.685554Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"def load_data(data_dir=\"./data\"):\n    transform = transforms.Compose([\n        transforms.ToTensor(),\n        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n    ])\n\n    # We add FileLock here because multiple workers will want to\n    # download data, and this may cause overwrites since\n    # DataLoader is not threadsafe.\n    with FileLock(os.path.expanduser(\"~/.data.lock\")):\n        trainset = torchvision.datasets.CIFAR10(\n            root=data_dir, train=True, download=True, transform=transform)\n\n        testset = torchvision.datasets.CIFAR10(\n            root=data_dir, train=False, download=True, transform=transform)\n\n    return trainset, testset","metadata":{"execution":{"iopub.status.busy":"2023-06-03T17:52:49.688378Z","iopub.execute_input":"2023-06-03T17:52:49.68893Z","iopub.status.idle":"2023-06-03T17:52:49.694964Z","shell.execute_reply.started":"2023-06-03T17:52:49.68889Z","shell.execute_reply":"2023-06-03T17:52:49.694017Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"class Net(nn.Module):\n    def __init__(self, l1=120, l2=84):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(3, 6, 5)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.fc1 = nn.Linear(16 * 5 * 5, l1)\n        self.fc2 = nn.Linear(l1, l2)\n        self.fc3 = nn.Linear(l2, 10)\n\n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = x.view(-1, 16 * 5 * 5)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2023-06-03T17:52:53.712051Z","iopub.execute_input":"2023-06-03T17:52:53.712401Z","iopub.status.idle":"2023-06-03T17:52:53.720153Z","shell.execute_reply.started":"2023-06-03T17:52:53.712374Z","shell.execute_reply":"2023-06-03T17:52:53.719134Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def train_cifar(config):\n    net = Net(config[\"l1\"], config[\"l2\"])\n\n    device = \"cpu\"\n    if torch.cuda.is_available():\n        device = \"cuda:0\"\n        if torch.cuda.device_count() > 1:\n            net = nn.DataParallel(net)\n    net.to(device)\n\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.SGD(net.parameters(), lr=config[\"lr\"], momentum=0.9)\n\n    # To restore a checkpoint, use `session.get_checkpoint()`.\n    loaded_checkpoint = session.get_checkpoint()\n    if loaded_checkpoint:\n        with loaded_checkpoint.as_directory() as loaded_checkpoint_dir:\n           model_state, optimizer_state = torch.load(os.path.join(loaded_checkpoint_dir, \"checkpoint.pt\"))\n        net.load_state_dict(model_state)\n        optimizer.load_state_dict(optimizer_state)\n\n    data_dir = os.path.abspath(\"./data\")\n    trainset, testset = load_data(data_dir)\n\n    test_abs = int(len(trainset) * 0.8)\n    train_subset, val_subset = random_split(\n        trainset, [test_abs, len(trainset) - test_abs])\n\n    trainloader = torch.utils.data.DataLoader(\n        train_subset,\n        batch_size=int(config[\"batch_size\"]),\n        shuffle=True,\n        num_workers=8)\n    valloader = torch.utils.data.DataLoader(\n        val_subset,\n        batch_size=int(config[\"batch_size\"]),\n        shuffle=True,\n        num_workers=8)\n\n    for epoch in range(10):  # loop over the dataset multiple times\n        running_loss = 0.0\n        epoch_steps = 0\n        for i, data in enumerate(trainloader, 0):\n            # get the inputs; data is a list of [inputs, labels]\n            inputs, labels = data\n            inputs, labels = inputs.to(device), labels.to(device)\n\n            # zero the parameter gradients\n            optimizer.zero_grad()\n\n            # forward + backward + optimize\n            outputs = net(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            # print statistics\n            running_loss += loss.item()\n            epoch_steps += 1\n            if i % 2000 == 1999:  # print every 2000 mini-batches\n                print(\"[%d, %5d] loss: %.3f\" % (epoch + 1, i + 1,\n                                                running_loss / epoch_steps))\n                running_loss = 0.0\n\n        # Validation loss\n        val_loss = 0.0\n        val_steps = 0\n        total = 0\n        correct = 0\n        for i, data in enumerate(valloader, 0):\n            with torch.no_grad():\n                inputs, labels = data\n                inputs, labels = inputs.to(device), labels.to(device)\n\n                outputs = net(inputs)\n                _, predicted = torch.max(outputs.data, 1)\n                total += labels.size(0)\n                correct += (predicted == labels).sum().item()\n\n                loss = criterion(outputs, labels)\n                val_loss += loss.cpu().numpy()\n                val_steps += 1\n\n        # Here we save a checkpoint. It is automatically registered with\n        # Ray Tune and can be accessed through `session.get_checkpoint()`\n        # API in future iterations.\n        os.makedirs(\"my_model\", exist_ok=True)\n        torch.save(\n            (net.state_dict(), optimizer.state_dict()), \"my_model/checkpoint.pt\")\n        checkpoint = Checkpoint.from_directory(\"my_model\")\n        session.report({\"loss\": (val_loss / val_steps), \"accuracy\": correct / total}, checkpoint=checkpoint)\n    print(\"Finished Training\")","metadata":{"execution":{"iopub.status.busy":"2023-06-03T17:53:14.770003Z","iopub.execute_input":"2023-06-03T17:53:14.770395Z","iopub.status.idle":"2023-06-03T17:53:14.786829Z","shell.execute_reply.started":"2023-06-03T17:53:14.77036Z","shell.execute_reply":"2023-06-03T17:53:14.785627Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def test_best_model(best_result):\n    best_trained_model = Net(best_result.config[\"l1\"], best_result.config[\"l2\"])\n    device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n    best_trained_model.to(device)\n\n    checkpoint_path = os.path.join(best_result.checkpoint.to_directory(), \"checkpoint.pt\")\n\n    model_state, optimizer_state = torch.load(checkpoint_path)\n    best_trained_model.load_state_dict(model_state)\n\n    trainset, testset = load_data()\n\n    testloader = torch.utils.data.DataLoader(\n        testset, batch_size=4, shuffle=False, num_workers=2)\n\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for data in testloader:\n            images, labels = data\n            images, labels = images.to(device), labels.to(device)\n            outputs = best_trained_model(images)\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n\n    print(\"Best trial test set accuracy: {}\".format(correct / total))","metadata":{"execution":{"iopub.status.busy":"2023-06-03T17:53:23.719512Z","iopub.execute_input":"2023-06-03T17:53:23.719913Z","iopub.status.idle":"2023-06-03T17:53:23.728747Z","shell.execute_reply.started":"2023-06-03T17:53:23.719881Z","shell.execute_reply":"2023-06-03T17:53:23.727374Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"config = {\n    \"l1\": tune.sample_from(lambda _: 2**np.random.randint(2, 9)),\n    \"l2\": tune.sample_from(lambda _: 2**np.random.randint(2, 9)),\n    \"lr\": tune.loguniform(1e-4, 1e-1),\n    \"batch_size\": tune.choice([2, 4, 8, 16]),\n}","metadata":{"execution":{"iopub.status.busy":"2023-06-03T17:53:31.58397Z","iopub.execute_input":"2023-06-03T17:53:31.584479Z","iopub.status.idle":"2023-06-03T17:53:31.59122Z","shell.execute_reply.started":"2023-06-03T17:53:31.584434Z","shell.execute_reply":"2023-06-03T17:53:31.590201Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def main(num_samples=10, max_num_epochs=10, gpus_per_trial=2):\n    config = {\n        \"l1\": tune.sample_from(lambda _: 2 ** np.random.randint(2, 9)),\n        \"l2\": tune.sample_from(lambda _: 2 ** np.random.randint(2, 9)),\n        \"lr\": tune.loguniform(1e-4, 1e-1),\n        \"batch_size\": tune.choice([2, 4, 8, 16])\n    }\n    scheduler = ASHAScheduler(\n        max_t=max_num_epochs,\n        grace_period=1,\n        reduction_factor=2)\n    \n    tuner = tune.Tuner(\n        tune.with_resources(\n            tune.with_parameters(train_cifar),\n            resources={\"cpu\": 2, \"gpu\": gpus_per_trial}\n        ),\n        tune_config=tune.TuneConfig(\n            metric=\"loss\",\n            mode=\"min\",\n            scheduler=scheduler,\n            num_samples=num_samples,\n        ),\n        param_space=config,\n    )\n    results = tuner.fit()\n    \n    best_result = results.get_best_result(\"loss\", \"min\")\n\n    print(\"Best trial config: {}\".format(best_result.config))\n    print(\"Best trial final validation loss: {}\".format(\n        best_result.metrics[\"loss\"]))\n    print(\"Best trial final validation accuracy: {}\".format(\n        best_result.metrics[\"accuracy\"]))\n\n    test_best_model(best_result)\n\nmain(num_samples=2, max_num_epochs=2, gpus_per_trial=0)","metadata":{"execution":{"iopub.status.busy":"2023-06-03T17:53:43.725607Z","iopub.execute_input":"2023-06-03T17:53:43.726057Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"2023-06-03 17:53:47,554\tINFO worker.py:1616 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n2023-06-03 17:53:50,338\tINFO tune.py:218 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `Tuner(...)`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<div class=\"tuneStatus\">\n  <div style=\"display: flex;flex-direction: row\">\n    <div style=\"display: flex;flex-direction: column;\">\n      <h3>Tune Status</h3>\n      <table>\n<tbody>\n<tr><td>Current time:</td><td>2023-06-03 17:54:12</td></tr>\n<tr><td>Running for: </td><td>00:00:21.71        </td></tr>\n<tr><td>Memory:      </td><td>2.2/31.4 GiB       </td></tr>\n</tbody>\n</table>\n    </div>\n    <div class=\"vDivider\"></div>\n    <div class=\"systemInfo\">\n      <h3>System Info</h3>\n      Using AsyncHyperBand: num_stopped=0<br>Bracket: Iter 2.000: None | Iter 1.000: None<br>Logical resource usage: 4.0/4 CPUs, 0/0 GPUs\n    </div>\n    \n  </div>\n  <div class=\"hDivider\"></div>\n  <div class=\"trialStatus\">\n    <h3>Trial Status</h3>\n    <table>\n<thead>\n<tr><th>Trial name             </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">        lr</th></tr>\n</thead>\n<tbody>\n<tr><td>train_cifar_98b74_00000</td><td>RUNNING </td><td>172.19.2.2:444</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">0.00216057</td></tr>\n<tr><td>train_cifar_98b74_00001</td><td>RUNNING </td><td>172.19.2.2:497</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">0.00112302</td></tr>\n</tbody>\n</table>\n  </div>\n</div>\n<style>\n.tuneStatus {\n  color: var(--jp-ui-font-color1);\n}\n.tuneStatus .systemInfo {\n  display: flex;\n  flex-direction: column;\n}\n.tuneStatus td {\n  white-space: nowrap;\n}\n.tuneStatus .trialStatus {\n  display: flex;\n  flex-direction: column;\n}\n.tuneStatus h3 {\n  font-weight: bold;\n}\n.tuneStatus .hDivider {\n  border-bottom-width: var(--jp-border-width);\n  border-bottom-color: var(--jp-border-color0);\n  border-bottom-style: solid;\n}\n.tuneStatus .vDivider {\n  border-left-width: var(--jp-border-width);\n  border-left-color: var(--jp-border-color0);\n  border-left-style: solid;\n  margin: 0.5em 1em 0.5em 1em;\n}\n</style>\n"},"metadata":{}},{"name":"stdout","text":"\u001b[2m\u001b[36m(train_cifar pid=444)\u001b[0m Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /root/ray_results/train_cifar_2023-06-03_17-53-43/train_cifar_98b74_00000_0_batch_size=16,lr=0.0022_2023-06-03_17-53-50/data/cifar-10-python.tar.gz\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/170498071 [00:00<?, ?it/s]\n  0%|          | 32768/170498071 [00:00<14:44, 192670.71it/s]\n  0%|          | 65536/170498071 [00:00<14:51, 191097.08it/s]\n  0%|          | 98304/170498071 [00:00<14:52, 190849.55it/s]\n  0%|          | 229376/170498071 [00:00<06:49, 415851.23it/s]\n  0%|          | 458752/170498071 [00:00<03:47, 745862.12it/s]\n  1%|          | 917504/170498071 [00:01<02:01, 1397118.15it/s]\n  1%|          | 1835008/170498071 [00:01<01:02, 2679795.92it/s]\n  2%|▏         | 3702784/170498071 [00:01<00:31, 5272177.71it/s]\n  4%|▍         | 6815744/170498071 [00:01<00:17, 9266244.52it/s]\n  6%|▌         | 9928704/170498071 [00:01<00:13, 11972679.19it/s]\n  8%|▊         | 13041664/170498071 [00:01<00:11, 13797166.53it/s]\n  9%|▉         | 16154624/170498071 [00:02<00:10, 15082569.18it/s]\n 11%|█▏        | 19300352/170498071 [00:02<00:09, 15998361.38it/s]\n 13%|█▎        | 22413312/170498071 [00:02<00:08, 16650616.72it/s]\n 15%|█▍        | 25427968/170498071 [00:02<00:08, 16944873.34it/s]\n 17%|█▋        | 28573696/170498071 [00:02<00:08, 17240042.19it/s]\n 19%|█▊        | 31686656/170498071 [00:02<00:07, 17471518.32it/s]\n 20%|██        | 34799616/170498071 [00:03<00:07, 17733145.54it/s]\n 22%|██▏       | 37912576/170498071 [00:03<00:07, 17669203.88it/s]\n 24%|██▎       | 40435712/170498071 [00:03<00:06, 19162738.31it/s]\n 25%|██▍       | 42434560/170498071 [00:03<00:07, 17612726.50it/s]\n 26%|██▌       | 44269568/170498071 [00:03<00:07, 16698321.40it/s]\n 27%|██▋       | 46465024/170498071 [00:03<00:07, 15874531.16it/s]\n 29%|██▉       | 49250304/170498071 [00:03<00:06, 18551811.27it/s]\n 30%|███       | 51216384/170498071 [00:04<00:07, 16714044.27it/s]\n 31%|███       | 52985856/170498071 [00:04<00:07, 15888324.84it/s]\n 32%|███▏      | 55115776/170498071 [00:04<00:07, 15294022.33it/s]\n 34%|███▍      | 57966592/170498071 [00:04<00:07, 15640213.17it/s]\n 36%|███▌      | 60882944/170498071 [00:04<00:06, 15950431.48it/s]\n 37%|███▋      | 63143936/170498071 [00:04<00:06, 17340998.45it/s]\n 38%|███▊      | 64946176/170498071 [00:04<00:06, 16713326.93it/s]\n 39%|███▉      | 66715648/170498071 [00:05<00:06, 15530898.87it/s]\n 40%|████      | 68943872/170498071 [00:05<00:05, 17134318.97it/s]\n 41%|████▏     | 70746112/170498071 [00:05<00:06, 16292183.16it/s]\n 42%|████▏     | 72450048/170498071 [00:05<00:06, 15420407.92it/s]\n 44%|████▍     | 74645504/170498071 [00:05<00:05, 17008717.11it/s]\n 45%|████▍     | 76414976/170498071 [00:05<00:05, 16244163.84it/s]\n 46%|████▌     | 78184448/170498071 [00:05<00:05, 15396071.75it/s]\n 47%|████▋     | 80379904/170498071 [00:05<00:05, 17001369.45it/s]\n 48%|████▊     | 82149376/170498071 [00:05<00:05, 15791872.86it/s]\n 49%|████▉     | 83886080/170498071 [00:06<00:05, 15378837.89it/s]\n 50%|█████     | 85852160/170498071 [00:06<00:05, 16350113.77it/s]\n 51%|█████▏    | 87523328/170498071 [00:06<00:05, 15742357.14it/s]\n 52%|█████▏    | 89423872/170498071 [00:06<00:04, 16510268.21it/s]\n 53%|█████▎    | 91127808/170498071 [00:06<00:04, 16086723.83it/s]\n 54%|█████▍    | 92766208/170498071 [00:06<00:04, 15692752.60it/s]\n 55%|█████▌    | 94601216/170498071 [00:06<00:04, 16399239.69it/s]\n 56%|█████▋    | 96272384/170498071 [00:06<00:04, 15930587.32it/s]\n 58%|█████▊    | 98107392/170498071 [00:06<00:04, 16588678.52it/s]\n 59%|█████▊    | 99778560/170498071 [00:07<00:04, 16048651.16it/s]\n 59%|█████▉    | 101416960/170498071 [00:07<00:04, 15522589.52it/s]\n 61%|██████    | 103383040/170498071 [00:07<00:04, 16538381.47it/s]\n 62%|██████▏   | 105054208/170498071 [00:07<00:04, 16139477.82it/s]\n 63%|██████▎   | 106758144/170498071 [00:07<00:04, 15465605.87it/s]\n 64%|██████▍   | 108724224/170498071 [00:07<00:03, 16503007.61it/s]\n 65%|██████▍   | 110395392/170498071 [00:07<00:03, 15888036.02it/s]\n 66%|██████▌   | 112295936/170498071 [00:07<00:03, 16710660.97it/s]\n 67%|██████▋   | 113999872/170498071 [00:07<00:03, 16079911.13it/s]\n 68%|██████▊   | 115638272/170498071 [00:08<00:03, 15660771.99it/s]\n 69%|██████▉   | 117473280/170498071 [00:08<00:03, 16370855.26it/s]\n 70%|██████▉   | 119144448/170498071 [00:08<00:03, 15983439.32it/s]\n 71%|███████   | 120979456/170498071 [00:08<00:02, 16642143.36it/s]\n 72%|███████▏  | 122683392/170498071 [00:08<00:02, 16020515.06it/s]\n 73%|███████▎  | 124321792/170498071 [00:08<00:02, 15623535.08it/s]\n 74%|███████▍  | 126189568/170498071 [00:08<00:02, 16465922.84it/s]\n 75%|███████▍  | 127860736/170498071 [00:08<00:02, 16005999.06it/s]\n 76%|███████▌  | 129630208/170498071 [00:08<00:02, 15474895.09it/s]\n 77%|███████▋  | 131563520/170498071 [00:09<00:02, 16438765.36it/s]\n 78%|███████▊  | 133234688/170498071 [00:09<00:02, 15936351.58it/s]\n 79%|███████▉  | 135135232/170498071 [00:09<00:02, 16675400.83it/s]\n 80%|████████  | 136839168/170498071 [00:09<00:02, 16047776.39it/s]\n 81%|████████  | 138477568/170498071 [00:09<00:02, 15590893.05it/s]\n 82%|████████▏ | 140378112/170498071 [00:09<00:01, 16532852.06it/s]\n 83%|████████▎ | 142049280/170498071 [00:09<00:01, 15937466.10it/s]\n 84%|████████▍ | 143884288/170498071 [00:09<00:01, 15464993.33it/s]\n 86%|████████▌ | 145784832/170498071 [00:09<00:01, 16378287.47it/s]\n 86%|████████▋ | 147456000/170498071 [00:10<00:01, 15866798.69it/s]\n 88%|████████▊ | 149356544/170498071 [00:10<00:01, 16622356.31it/s]\n 89%|████████▊ | 151060480/170498071 [00:10<00:01, 16051310.90it/s]\n 90%|████████▉ | 152698880/170498071 [00:10<00:01, 15723661.12it/s]\n 91%|█████████ | 154796032/170498071 [00:10<00:00, 17120901.61it/s]\n 92%|█████████▏| 156532736/170498071 [00:10<00:00, 16635548.65it/s]\n 93%|█████████▎| 158236672/170498071 [00:10<00:00, 15416755.39it/s]\n 94%|█████████▍| 160595968/170498071 [00:10<00:00, 17624986.23it/s]\n 95%|█████████▌| 162398208/170498071 [00:10<00:00, 17362667.31it/s]\n 96%|█████████▋| 164233216/170498071 [00:11<00:00, 15423668.26it/s]\n 98%|█████████▊| 166428672/170498071 [00:11<00:00, 17096430.56it/s]\n 99%|█████████▊| 168230912/170498071 [00:11<00:00, 17141907.49it/s]\n100%|█████████▉| 170000384/170498071 [00:11<00:00, 15136477.86it/s]\n100%|██████████| 170498071/170498071 [00:11<00:00, 14885340.85it/s]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[2m\u001b[36m(train_cifar pid=444)\u001b[0m Extracting /root/ray_results/train_cifar_2023-06-03_17-53-43/train_cifar_98b74_00000_0_batch_size=16,lr=0.0022_2023-06-03_17-53-50/data/cifar-10-python.tar.gz to /root/ray_results/train_cifar_2023-06-03_17-53-43/train_cifar_98b74_00000_0_batch_size=16,lr=0.0022_2023-06-03_17-53-50/data\n\u001b[2m\u001b[36m(train_cifar pid=444)\u001b[0m Files already downloaded and verified\n","output_type":"stream"},{"name":"stderr","text":"\u001b[2m\u001b[36m(train_cifar pid=444)\u001b[0m /opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n\u001b[2m\u001b[36m(train_cifar pid=444)\u001b[0m   warnings.warn(_create_warning_msg(\n","output_type":"stream"},{"name":"stdout","text":"\u001b[2m\u001b[36m(train_cifar pid=497)\u001b[0m Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /root/ray_results/train_cifar_2023-06-03_17-53-43/train_cifar_98b74_00001_1_batch_size=16,lr=0.0011_2023-06-03_17-53-56/data/cifar-10-python.tar.gz\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/170498071 [00:00<?, ?it/s]\n  0%|          | 32768/170498071 [00:00<14:40, 193552.00it/s]\n  0%|          | 65536/170498071 [00:00<14:49, 191569.26it/s]\n  0%|          | 98304/170498071 [00:00<14:51, 191103.22it/s]\n  0%|          | 229376/170498071 [00:00<06:49, 415569.54it/s]\n  0%|          | 458752/170498071 [00:00<03:48, 742790.35it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}