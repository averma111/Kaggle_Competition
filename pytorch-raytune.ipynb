{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/averma111/pytorch-raytune?scriptVersionId=128575349\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"import numpy as np\nimport os\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom filelock import FileLock\nfrom torch.utils.data import random_split\nimport torchvision\nimport torchvision.transforms as transforms\nimport ray\nfrom ray import tune\nfrom ray.tune.schedulers import ASHAScheduler\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_data(data_dir=\"./data\"):\n    transform = transforms.Compose([\n        transforms.ToTensor(),\n        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n    ])\n\n    # We add FileLock here because multiple workers will want to\n    # download data, and this may cause overwrites since\n    # DataLoader is not threadsafe.\n    with FileLock(os.path.expanduser(\"~/.data.lock\")):\n        trainset = torchvision.datasets.CIFAR10(\n            root=data_dir, train=True, download=True, transform=transform)\n\n        testset = torchvision.datasets.CIFAR10(\n            root=data_dir, train=False, download=True, transform=transform)\n\n    return trainset, testset","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_cifar(config, checkpoint_dir=None):\n    net = Net(config[\"l1\"], config[\"l2\"])\n\n    device = \"cpu\"\n    if torch.cuda.is_available():\n        device = \"cuda:0\"\n        if torch.cuda.device_count() > 1:\n            net = nn.DataParallel(net)\n    net.to(device)\n\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.SGD(net.parameters(), lr=config[\"lr\"], momentum=0.9)\n\n    # The `checkpoint_dir` parameter gets passed by Ray Tune when a checkpoint\n    # should be restored.\n    if checkpoint_dir:\n        checkpoint = os.path.join(checkpoint_dir, \"checkpoint\")\n        model_state, optimizer_state = torch.load(checkpoint)\n        net.load_state_dict(model_state)\n        optimizer.load_state_dict(optimizer_state)\n\n    data_dir = os.path.abspath(\"./data\")\n    trainset, testset = load_data(data_dir)\n\n    test_abs = int(len(trainset) * 0.8)\n    train_subset, val_subset = random_split(\n        trainset, [test_abs, len(trainset) - test_abs])\n\n    trainloader = torch.utils.data.DataLoader(\n        train_subset,\n        batch_size=int(config[\"batch_size\"]),\n        shuffle=True,\n        num_workers=8)\n    valloader = torch.utils.data.DataLoader(\n        val_subset,\n        batch_size=int(config[\"batch_size\"]),\n        shuffle=True,\n        num_workers=8)\n\n    for epoch in range(10):  # loop over the dataset multiple times\n        running_loss = 0.0\n        epoch_steps = 0\n        for i, data in enumerate(trainloader, 0):\n            # get the inputs; data is a list of [inputs, labels]\n            inputs, labels = data\n            inputs, labels = inputs.to(device), labels.to(device)\n\n            # zero the parameter gradients\n            optimizer.zero_grad()\n\n            # forward + backward + optimize\n            outputs = net(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            # print statistics\n            running_loss += loss.item()\n            epoch_steps += 1\n            if i % 2000 == 1999:  # print every 2000 mini-batches\n                print(\"[%d, %5d] loss: %.3f\" % (epoch + 1, i + 1,\n                                                running_loss / epoch_steps))\n                running_loss = 0.0\n\n        # Validation loss\n        val_loss = 0.0\n        val_steps = 0\n        total = 0\n        correct = 0\n        for i, data in enumerate(valloader, 0):\n            with torch.no_grad():\n                inputs, labels = data\n                inputs, labels = inputs.to(device), labels.to(device)\n\n                outputs = net(inputs)\n                _, predicted = torch.max(outputs.data, 1)\n                total += labels.size(0)\n                correct += (predicted == labels).sum().item()\n\n                loss = criterion(outputs, labels)\n                val_loss += loss.cpu().numpy()\n                val_steps += 1\n\n        # Here we save a checkpoint. It is automatically registered with\n        # Ray Tune and will potentially be passed as the `checkpoint_dir`\n        # parameter in future iterations.\n        with tune.checkpoint_dir(step=epoch) as checkpoint_dir:\n            path = os.path.join(checkpoint_dir, \"checkpoint\")\n            torch.save(\n                (net.state_dict(), optimizer.state_dict()), path)\n\n        tune.report(loss=(val_loss / val_steps), accuracy=correct / total)\n    print(\"Finished Training\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test_best_model(best_trial):\n    best_trained_model = Net(best_trial.config[\"l1\"], best_trial.config[\"l2\"])\n    device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n    best_trained_model.to(device)\n\n    checkpoint_path = os.path.join(best_trial.checkpoint.value, \"checkpoint\")\n\n    model_state, optimizer_state = torch.load(checkpoint_path)\n    best_trained_model.load_state_dict(model_state)\n\n    trainset, testset = load_data()\n\n    testloader = torch.utils.data.DataLoader(\n        testset, batch_size=4, shuffle=False, num_workers=2)\n\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for data in testloader:\n            images, labels = data\n            images, labels = images.to(device), labels.to(device)\n            outputs = best_trained_model(images)\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n\n    print(\"Best trial test set accuracy: {}\".format(correct / total))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"config = {\n    \"l1\": tune.sample_from(lambda _: 2**np.random.randint(2, 9)),\n    \"l2\": tune.sample_from(lambda _: 2**np.random.randint(2, 9)),\n    \"lr\": tune.loguniform(1e-4, 1e-1),\n    \"batch_size\": tune.choice([2, 4, 8, 16]),\n}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def main(num_samples=10, max_num_epochs=10, gpus_per_trial=2):\n    config = {\n        \"l1\": tune.sample_from(lambda _: 2 ** np.random.randint(2, 9)),\n        \"l2\": tune.sample_from(lambda _: 2 ** np.random.randint(2, 9)),\n        \"lr\": tune.loguniform(1e-4, 1e-1),\n        \"batch_size\": tune.choice([2, 4, 8, 16])\n    }\n    scheduler = ASHAScheduler(\n        max_t=max_num_epochs,\n        grace_period=1,\n        reduction_factor=2)\n    result = tune.run(\n        tune.with_parameters(train_cifar),\n        resources_per_trial={\"cpu\": 2, \"gpu\": gpus_per_trial},\n        config=config,\n        metric=\"loss\",\n        mode=\"min\",\n        num_samples=num_samples,\n        scheduler=scheduler\n    )\n\n    best_trial = result.get_best_trial(\"loss\", \"min\", \"last\")\n    print(\"Best trial config: {}\".format(best_trial.config))\n    print(\"Best trial final validation loss: {}\".format(\n        best_trial.last_result[\"loss\"]))\n    print(\"Best trial final validation accuracy: {}\".format(\n        best_trial.last_result[\"accuracy\"]))\n\n    if ray.util.client.ray.is_connected():\n        # If using Ray Client, we want to make sure checkpoint access\n        # happens on the server. So we wrap `test_best_model` in a Ray task.\n        # We have to make sure it gets executed on the same node that\n        # ``tune.run`` is called on.\n        from ray.util.ml_utils.node import force_on_current_node\n        remote_fn = force_on_current_node(ray.remote(test_best_model))\n        ray.get(remote_fn.remote(best_trial))\n    else:\n        test_best_model(best_trial)\n\nmain(num_samples=2, max_num_epochs=2, gpus_per_trial=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}