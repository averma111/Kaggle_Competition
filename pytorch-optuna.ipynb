{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/averma111/pytorch-optuna?scriptVersionId=128497003\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"import os\n\nimport optuna\nfrom optuna.trial import TrialState\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torch.utils.data\nfrom torchvision import datasets\nfrom torchvision import transforms\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-06T05:44:42.545035Z","iopub.execute_input":"2023-05-06T05:44:42.546323Z","iopub.status.idle":"2023-05-06T05:44:48.256872Z","shell.execute_reply.started":"2023-05-06T05:44:42.546275Z","shell.execute_reply":"2023-05-06T05:44:48.255939Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"DEVICE = torch.device('cpu')\nBATCHSIZE = 128\nCLASSES = 10\nDIR = os.getcwd()\nEPOCHS = 10\nN_TRAIN_EXAMPLES = BATCHSIZE * 30\nN_VALID_EXAMPLES = BATCHSIZE * 10","metadata":{"execution":{"iopub.status.busy":"2023-05-06T05:45:43.560081Z","iopub.execute_input":"2023-05-06T05:45:43.560662Z","iopub.status.idle":"2023-05-06T05:45:43.568191Z","shell.execute_reply.started":"2023-05-06T05:45:43.56062Z","shell.execute_reply":"2023-05-06T05:45:43.566923Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"def define_model(trial):\n    # We optimize the number of layers, hidden units and dropout ratio in each layer.\n    n_layers = trial.suggest_int(\"n_layers\", 1, 3)\n    layers = []\n\n    in_features = 28*28\n    for i in range(n_layers):\n        out_features = trial.suggest_int(\"n_units_l{}\".format(i), 4, 128)\n        layers.append(torch.nn.Linear(in_features, out_features))\n        layers.append(torch.nn.ReLU())\n        p = trial.suggest_float(\"dropout_l{}\".format(i), 0.2, 0.5)\n        layers.append(torch.nn.Dropout(p))\n\n\n        in_features = out_features\n    layers.append(torch.nn.Linear(in_features, CLASSES))\n    layers.append(torch.nn.LogSoftmax(dim=1))\n\n    return torch.nn.Sequential(*layers)","metadata":{"execution":{"iopub.status.busy":"2023-05-06T05:45:46.112645Z","iopub.execute_input":"2023-05-06T05:45:46.113636Z","iopub.status.idle":"2023-05-06T05:45:46.122444Z","shell.execute_reply.started":"2023-05-06T05:45:46.113592Z","shell.execute_reply":"2023-05-06T05:45:46.121253Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def get_mnist():\n    # Load FashionMNIST dataset.\n    train_loader = torch.utils.data.DataLoader(\n        datasets.FashionMNIST(DIR, train=True, download=True, transform=transforms.ToTensor()),\n        batch_size=BATCHSIZE,\n        shuffle=True,\n    )\n    valid_loader = torch.utils.data.DataLoader(\n        datasets.FashionMNIST(DIR, train=False, transform=transforms.ToTensor()),\n        batch_size=BATCHSIZE,\n        shuffle=True,\n    )\n\n    return train_loader, valid_loader","metadata":{"execution":{"iopub.status.busy":"2023-05-06T05:45:48.608917Z","iopub.execute_input":"2023-05-06T05:45:48.60933Z","iopub.status.idle":"2023-05-06T05:45:48.617801Z","shell.execute_reply.started":"2023-05-06T05:45:48.609299Z","shell.execute_reply":"2023-05-06T05:45:48.616051Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def objective(trial):\n    # Generate the model.\n    model = define_model(trial).to(DEVICE)\n\n    # Generate the optimizers.\n    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"])\n    lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n    optimizer = getattr(torch.optim, optimizer_name)(model.parameters(), lr=lr)\n\n    # Get the FashionMNIST dataset.\n    train_loader, valid_loader = get_mnist()\n\n    # Training of the model.\n    for epoch in range(EPOCHS):\n        model.train()\n        for batch_idx, (data, target) in enumerate(train_loader):\n            # Limiting training data for faster epochs.\n            if batch_idx * BATCHSIZE >= N_TRAIN_EXAMPLES:\n                break\n\n            data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE)\n\n            optimizer.zero_grad()\n            output = model(data)\n            loss = F.nll_loss(output, target)\n            loss.backward()\n            optimizer.step()\n\n        # Validation of the model.\n        model.eval()\n        correct = 0\n        with torch.no_grad():\n            for batch_idx, (data, target) in enumerate(valid_loader):\n                # Limiting validation data.\n                if batch_idx * BATCHSIZE >= N_VALID_EXAMPLES:\n                    break\n                data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE)\n                output = model(data)\n                # Get the index of the max log-probability.\n                pred = output.argmax(dim=1, keepdim=True)\n                correct += pred.eq(target.view_as(pred)).sum().item()\n\n        accuracy = correct / min(len(valid_loader.dataset), N_VALID_EXAMPLES)\n\n        trial.report(accuracy, epoch)\n\n        # Handle pruning based on the intermediate value.\n        if trial.should_prune():\n            raise optuna.exceptions.TrialPruned()\n\n    return accuracy\n","metadata":{"execution":{"iopub.status.busy":"2023-05-06T05:45:51.663988Z","iopub.execute_input":"2023-05-06T05:45:51.664404Z","iopub.status.idle":"2023-05-06T05:45:51.67841Z","shell.execute_reply.started":"2023-05-06T05:45:51.664374Z","shell.execute_reply":"2023-05-06T05:45:51.677273Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"study = optuna.create_study(direction=\"maximize\")\nstudy.optimize(objective, n_trials=100, timeout=600)\n\npruned_trials = study.get_trials(deepcopy=False, states=[optuna.trial.TrialState.PRUNED])\ncomplete_trials = study.get_trials(deepcopy=False, states=[optuna.trial.TrialState.COMPLETE])\n\nprint(\"Study statistics: \")\nprint(\"  Number of finished trials: \", len(study.trials))\nprint(\"  Number of pruned trials: \", len(pruned_trials))\nprint(\"  Number of complete trials: \", len(complete_trials))\n\nprint(\"Best trial:\")\ntrial = study.best_trial\nprint(\"  Value: \", trial.value)\n\nprint(\"  Params: \")\nfor key, value in trial.params.items():\n    print(\"    {}: {}\".format(key, value))","metadata":{"execution":{"iopub.status.busy":"2023-05-06T05:45:54.616931Z","iopub.execute_input":"2023-05-06T05:45:54.617341Z","iopub.status.idle":"2023-05-06T05:51:31.118586Z","shell.execute_reply.started":"2023-05-06T05:45:54.61731Z","shell.execute_reply":"2023-05-06T05:51:31.117373Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"\u001b[32m[I 2023-05-06 05:45:54,621]\u001b[0m A new study created in memory with name: no-name-6e0e7ef7-acbb-47f5-ab88-28652dd554fe\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to /kaggle/working/FashionMNIST/raw/train-images-idx3-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 26421880/26421880 [00:14<00:00, 1807964.74it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting /kaggle/working/FashionMNIST/raw/train-images-idx3-ubyte.gz to /kaggle/working/FashionMNIST/raw\n\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to /kaggle/working/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 29515/29515 [00:00<00:00, 122276.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting /kaggle/working/FashionMNIST/raw/train-labels-idx1-ubyte.gz to /kaggle/working/FashionMNIST/raw\n\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to /kaggle/working/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 4422102/4422102 [00:09<00:00, 481960.34it/s] \n","output_type":"stream"},{"name":"stdout","text":"Extracting /kaggle/working/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to /kaggle/working/FashionMNIST/raw\n\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\nDownloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to /kaggle/working/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 5148/5148 [00:00<00:00, 20963375.72it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting /kaggle/working/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to /kaggle/working/FashionMNIST/raw\n\n","output_type":"stream"},{"name":"stderr","text":"\u001b[32m[I 2023-05-06 05:46:30,724]\u001b[0m Trial 0 finished with value: 0.36328125 and parameters: {'n_layers': 1, 'n_units_l0': 101, 'dropout_l0': 0.3005738158990566, 'optimizer': 'SGD', 'lr': 0.0012309586840644922}. Best is trial 0 with value: 0.36328125.\u001b[0m\n\u001b[32m[I 2023-05-06 05:46:37,705]\u001b[0m Trial 1 finished with value: 0.675 and parameters: {'n_layers': 3, 'n_units_l0': 58, 'dropout_l0': 0.3434239491431565, 'n_units_l1': 37, 'dropout_l1': 0.36177869346210373, 'n_units_l2': 21, 'dropout_l2': 0.47519521082848265, 'optimizer': 'Adam', 'lr': 0.01323823964837023}. Best is trial 1 with value: 0.675.\u001b[0m\n\u001b[32m[I 2023-05-06 05:46:44,290]\u001b[0m Trial 2 finished with value: 0.0984375 and parameters: {'n_layers': 3, 'n_units_l0': 49, 'dropout_l0': 0.2529962395286904, 'n_units_l1': 20, 'dropout_l1': 0.39812772519229955, 'n_units_l2': 11, 'dropout_l2': 0.248615347933594, 'optimizer': 'SGD', 'lr': 0.0012390186800930814}. Best is trial 1 with value: 0.675.\u001b[0m\n\u001b[32m[I 2023-05-06 05:46:50,964]\u001b[0m Trial 3 finished with value: 0.57265625 and parameters: {'n_layers': 3, 'n_units_l0': 24, 'dropout_l0': 0.24819743752912835, 'n_units_l1': 50, 'dropout_l1': 0.27872064058307466, 'n_units_l2': 68, 'dropout_l2': 0.45331507217255856, 'optimizer': 'RMSprop', 'lr': 0.0001254540658015457}. Best is trial 1 with value: 0.675.\u001b[0m\n\u001b[32m[I 2023-05-06 05:46:57,961]\u001b[0m Trial 4 finished with value: 0.55859375 and parameters: {'n_layers': 3, 'n_units_l0': 63, 'dropout_l0': 0.3004360791248649, 'n_units_l1': 73, 'dropout_l1': 0.2663859430177572, 'n_units_l2': 103, 'dropout_l2': 0.4917770706569228, 'optimizer': 'Adam', 'lr': 0.03184347566209237}. Best is trial 1 with value: 0.675.\u001b[0m\n\u001b[32m[I 2023-05-06 05:46:59,362]\u001b[0m Trial 5 pruned. \u001b[0m\n\u001b[32m[I 2023-05-06 05:47:00,249]\u001b[0m Trial 6 pruned. \u001b[0m\n\u001b[32m[I 2023-05-06 05:47:01,116]\u001b[0m Trial 7 pruned. \u001b[0m\n\u001b[32m[I 2023-05-06 05:47:01,906]\u001b[0m Trial 8 pruned. \u001b[0m\n\u001b[32m[I 2023-05-06 05:47:08,491]\u001b[0m Trial 9 finished with value: 0.81875 and parameters: {'n_layers': 1, 'n_units_l0': 56, 'dropout_l0': 0.3805146417344712, 'optimizer': 'Adam', 'lr': 0.0011082147546270097}. Best is trial 9 with value: 0.81875.\u001b[0m\n\u001b[32m[I 2023-05-06 05:47:10,635]\u001b[0m Trial 10 pruned. \u001b[0m\n\u001b[32m[I 2023-05-06 05:47:17,475]\u001b[0m Trial 11 finished with value: 0.81484375 and parameters: {'n_layers': 2, 'n_units_l0': 82, 'dropout_l0': 0.36734341520809916, 'n_units_l1': 123, 'dropout_l1': 0.4548200302312283, 'optimizer': 'Adam', 'lr': 0.006398074842931445}. Best is trial 9 with value: 0.81875.\u001b[0m\n\u001b[32m[I 2023-05-06 05:47:24,446]\u001b[0m Trial 12 finished with value: 0.81875 and parameters: {'n_layers': 2, 'n_units_l0': 87, 'dropout_l0': 0.3932219531159423, 'n_units_l1': 126, 'dropout_l1': 0.48858001202142576, 'optimizer': 'Adam', 'lr': 0.004100062619115153}. Best is trial 9 with value: 0.81875.\u001b[0m\n\u001b[32m[I 2023-05-06 05:47:31,221]\u001b[0m Trial 13 finished with value: 0.8109375 and parameters: {'n_layers': 1, 'n_units_l0': 127, 'dropout_l0': 0.40893335768419226, 'optimizer': 'Adam', 'lr': 0.003075697320404236}. Best is trial 9 with value: 0.81875.\u001b[0m\n\u001b[32m[I 2023-05-06 05:47:32,190]\u001b[0m Trial 14 pruned. \u001b[0m\n\u001b[32m[I 2023-05-06 05:47:39,043]\u001b[0m Trial 15 finished with value: 0.83203125 and parameters: {'n_layers': 1, 'n_units_l0': 83, 'dropout_l0': 0.4926806699602896, 'optimizer': 'Adam', 'lr': 0.002328883621466294}. Best is trial 15 with value: 0.83203125.\u001b[0m\n\u001b[32m[I 2023-05-06 05:47:45,803]\u001b[0m Trial 16 finished with value: 0.80625 and parameters: {'n_layers': 1, 'n_units_l0': 122, 'dropout_l0': 0.49474431211592435, 'optimizer': 'RMSprop', 'lr': 0.000543720298749153}. Best is trial 15 with value: 0.83203125.\u001b[0m\n\u001b[32m[I 2023-05-06 05:47:46,592]\u001b[0m Trial 17 pruned. \u001b[0m\n\u001b[32m[I 2023-05-06 05:47:47,388]\u001b[0m Trial 18 pruned. \u001b[0m\n\u001b[32m[I 2023-05-06 05:47:54,066]\u001b[0m Trial 19 pruned. \u001b[0m\n\u001b[32m[I 2023-05-06 05:48:00,610]\u001b[0m Trial 20 finished with value: 0.80859375 and parameters: {'n_layers': 1, 'n_units_l0': 72, 'dropout_l0': 0.49884491902250905, 'optimizer': 'Adam', 'lr': 0.00741374995987576}. Best is trial 15 with value: 0.83203125.\u001b[0m\n\u001b[32m[I 2023-05-06 05:48:07,618]\u001b[0m Trial 21 finished with value: 0.82265625 and parameters: {'n_layers': 2, 'n_units_l0': 90, 'dropout_l0': 0.3916028309498644, 'n_units_l1': 96, 'dropout_l1': 0.4959458978843144, 'optimizer': 'Adam', 'lr': 0.0038268227215929322}. Best is trial 15 with value: 0.83203125.\u001b[0m\n\u001b[32m[I 2023-05-06 05:48:08,467]\u001b[0m Trial 22 pruned. \u001b[0m\n\u001b[32m[I 2023-05-06 05:48:09,296]\u001b[0m Trial 23 pruned. \u001b[0m\n\u001b[32m[I 2023-05-06 05:48:11,979]\u001b[0m Trial 24 pruned. \u001b[0m\n\u001b[32m[I 2023-05-06 05:48:18,612]\u001b[0m Trial 25 finished with value: 0.8171875 and parameters: {'n_layers': 1, 'n_units_l0': 73, 'dropout_l0': 0.41640643795753274, 'optimizer': 'Adam', 'lr': 0.004264760835945997}. Best is trial 15 with value: 0.83203125.\u001b[0m\n\u001b[32m[I 2023-05-06 05:48:19,426]\u001b[0m Trial 26 pruned. \u001b[0m\n\u001b[32m[I 2023-05-06 05:48:26,191]\u001b[0m Trial 27 finished with value: 0.8390625 and parameters: {'n_layers': 1, 'n_units_l0': 110, 'dropout_l0': 0.4117726574920157, 'optimizer': 'Adam', 'lr': 0.0020453615774186766}. Best is trial 27 with value: 0.8390625.\u001b[0m\n\u001b[32m[I 2023-05-06 05:48:26,989]\u001b[0m Trial 28 pruned. \u001b[0m\n\u001b[32m[I 2023-05-06 05:48:28,447]\u001b[0m Trial 29 pruned. \u001b[0m\n\u001b[32m[I 2023-05-06 05:48:29,270]\u001b[0m Trial 30 pruned. \u001b[0m\n\u001b[32m[I 2023-05-06 05:48:36,188]\u001b[0m Trial 31 finished with value: 0.8328125 and parameters: {'n_layers': 1, 'n_units_l0': 91, 'dropout_l0': 0.382038331361448, 'optimizer': 'Adam', 'lr': 0.001469980761937829}. Best is trial 27 with value: 0.8390625.\u001b[0m\n\u001b[32m[I 2023-05-06 05:48:38,301]\u001b[0m Trial 32 pruned. \u001b[0m\n\u001b[32m[I 2023-05-06 05:48:39,137]\u001b[0m Trial 33 pruned. \u001b[0m\n\u001b[32m[I 2023-05-06 05:48:45,895]\u001b[0m Trial 34 finished with value: 0.83828125 and parameters: {'n_layers': 1, 'n_units_l0': 86, 'dropout_l0': 0.40093340824496493, 'optimizer': 'Adam', 'lr': 0.004215053739018107}. Best is trial 27 with value: 0.8390625.\u001b[0m\n\u001b[32m[I 2023-05-06 05:48:46,691]\u001b[0m Trial 35 pruned. \u001b[0m\n\u001b[32m[I 2023-05-06 05:48:53,580]\u001b[0m Trial 36 finished with value: 0.84140625 and parameters: {'n_layers': 1, 'n_units_l0': 107, 'dropout_l0': 0.3650945557298434, 'optimizer': 'Adam', 'lr': 0.0047998328099101584}. Best is trial 36 with value: 0.84140625.\u001b[0m\n\u001b[32m[I 2023-05-06 05:48:54,349]\u001b[0m Trial 37 pruned. \u001b[0m\n\u001b[32m[I 2023-05-06 05:48:55,083]\u001b[0m Trial 38 pruned. \u001b[0m\n\u001b[32m[I 2023-05-06 05:48:55,851]\u001b[0m Trial 39 pruned. \u001b[0m\n\u001b[32m[I 2023-05-06 05:48:56,708]\u001b[0m Trial 40 pruned. \u001b[0m\n\u001b[32m[I 2023-05-06 05:49:03,500]\u001b[0m Trial 41 finished with value: 0.83203125 and parameters: {'n_layers': 1, 'n_units_l0': 86, 'dropout_l0': 0.37405642728442395, 'optimizer': 'Adam', 'lr': 0.00479554264925825}. Best is trial 36 with value: 0.84140625.\u001b[0m\n\u001b[32m[I 2023-05-06 05:49:05,561]\u001b[0m Trial 42 pruned. \u001b[0m\n\u001b[32m[I 2023-05-06 05:49:12,604]\u001b[0m Trial 43 finished with value: 0.8078125 and parameters: {'n_layers': 1, 'n_units_l0': 71, 'dropout_l0': 0.3527418232604062, 'optimizer': 'Adam', 'lr': 0.003690968386839238}. Best is trial 36 with value: 0.84140625.\u001b[0m\n\u001b[32m[I 2023-05-06 05:49:19,126]\u001b[0m Trial 44 finished with value: 0.815625 and parameters: {'n_layers': 1, 'n_units_l0': 66, 'dropout_l0': 0.38649367393731915, 'optimizer': 'Adam', 'lr': 0.011074292724578614}. Best is trial 36 with value: 0.84140625.\u001b[0m\n\u001b[32m[I 2023-05-06 05:49:19,959]\u001b[0m Trial 45 pruned. \u001b[0m\n\u001b[32m[I 2023-05-06 05:49:20,768]\u001b[0m Trial 46 pruned. \u001b[0m\n\u001b[32m[I 2023-05-06 05:49:21,571]\u001b[0m Trial 47 pruned. \u001b[0m\n\u001b[32m[I 2023-05-06 05:49:28,153]\u001b[0m Trial 48 finished with value: 0.809375 and parameters: {'n_layers': 1, 'n_units_l0': 56, 'dropout_l0': 0.37210610437637737, 'optimizer': 'Adam', 'lr': 0.0055563372958018584}. Best is trial 36 with value: 0.84140625.\u001b[0m\n\u001b[32m[I 2023-05-06 05:49:30,278]\u001b[0m Trial 49 pruned. \u001b[0m\n\u001b[32m[I 2023-05-06 05:49:37,143]\u001b[0m Trial 50 finished with value: 0.8296875 and parameters: {'n_layers': 1, 'n_units_l0': 116, 'dropout_l0': 0.4048291932533973, 'optimizer': 'Adam', 'lr': 0.0030599989911912267}. Best is trial 36 with value: 0.84140625.\u001b[0m\n\u001b[32m[I 2023-05-06 05:49:44,066]\u001b[0m Trial 51 finished with value: 0.8109375 and parameters: {'n_layers': 1, 'n_units_l0': 86, 'dropout_l0': 0.3813339931531027, 'optimizer': 'Adam', 'lr': 0.004784924903927502}. Best is trial 36 with value: 0.84140625.\u001b[0m\n\u001b[32m[I 2023-05-06 05:49:44,878]\u001b[0m Trial 52 pruned. \u001b[0m\n\u001b[32m[I 2023-05-06 05:49:51,802]\u001b[0m Trial 53 finished with value: 0.81875 and parameters: {'n_layers': 1, 'n_units_l0': 126, 'dropout_l0': 0.35081499140282435, 'optimizer': 'Adam', 'lr': 0.0034331541851019337}. Best is trial 36 with value: 0.84140625.\u001b[0m\n\u001b[32m[I 2023-05-06 05:49:52,592]\u001b[0m Trial 54 pruned. \u001b[0m\n\u001b[32m[I 2023-05-06 05:49:59,300]\u001b[0m Trial 55 finished with value: 0.8078125 and parameters: {'n_layers': 1, 'n_units_l0': 92, 'dropout_l0': 0.3582939067542582, 'optimizer': 'Adam', 'lr': 0.011476347515713376}. Best is trial 36 with value: 0.84140625.\u001b[0m\n\u001b[32m[I 2023-05-06 05:50:00,092]\u001b[0m Trial 56 pruned. \u001b[0m\n\u001b[32m[I 2023-05-06 05:50:06,941]\u001b[0m Trial 57 finished with value: 0.83515625 and parameters: {'n_layers': 1, 'n_units_l0': 99, 'dropout_l0': 0.4479359515763948, 'optimizer': 'Adam', 'lr': 0.007708001991514511}. Best is trial 36 with value: 0.84140625.\u001b[0m\n\u001b[32m[I 2023-05-06 05:50:13,787]\u001b[0m Trial 58 finished with value: 0.79921875 and parameters: {'n_layers': 1, 'n_units_l0': 111, 'dropout_l0': 0.4567249391369413, 'optimizer': 'Adam', 'lr': 0.007661807408221411}. Best is trial 36 with value: 0.84140625.\u001b[0m\n\u001b[32m[I 2023-05-06 05:50:14,616]\u001b[0m Trial 59 pruned. \u001b[0m\n\u001b[32m[I 2023-05-06 05:50:15,456]\u001b[0m Trial 60 pruned. \u001b[0m\n\u001b[32m[I 2023-05-06 05:50:16,260]\u001b[0m Trial 61 pruned. \u001b[0m\n\u001b[32m[I 2023-05-06 05:50:22,756]\u001b[0m Trial 62 finished with value: 0.81796875 and parameters: {'n_layers': 1, 'n_units_l0': 84, 'dropout_l0': 0.4129113903790576, 'optimizer': 'Adam', 'lr': 0.006389183147364721}. Best is trial 36 with value: 0.84140625.\u001b[0m\n\u001b[32m[I 2023-05-06 05:50:26,816]\u001b[0m Trial 63 pruned. \u001b[0m\n\u001b[32m[I 2023-05-06 05:50:27,639]\u001b[0m Trial 64 pruned. \u001b[0m\n\u001b[32m[I 2023-05-06 05:50:31,061]\u001b[0m Trial 65 pruned. \u001b[0m\n\u001b[32m[I 2023-05-06 05:50:31,843]\u001b[0m Trial 66 pruned. \u001b[0m\n\u001b[32m[I 2023-05-06 05:50:32,696]\u001b[0m Trial 67 pruned. \u001b[0m\n\u001b[32m[I 2023-05-06 05:50:33,504]\u001b[0m Trial 68 pruned. \u001b[0m\n\u001b[32m[I 2023-05-06 05:50:40,388]\u001b[0m Trial 69 finished with value: 0.8125 and parameters: {'n_layers': 1, 'n_units_l0': 116, 'dropout_l0': 0.40923239046861637, 'optimizer': 'Adam', 'lr': 0.002798343343581783}. Best is trial 36 with value: 0.84140625.\u001b[0m\n\u001b[32m[I 2023-05-06 05:50:42,522]\u001b[0m Trial 70 pruned. \u001b[0m\n\u001b[32m[I 2023-05-06 05:50:49,362]\u001b[0m Trial 71 finished with value: 0.8421875 and parameters: {'n_layers': 1, 'n_units_l0': 117, 'dropout_l0': 0.40746502244647825, 'optimizer': 'Adam', 'lr': 0.004546171411634709}. Best is trial 71 with value: 0.8421875.\u001b[0m\n\u001b[32m[I 2023-05-06 05:50:56,170]\u001b[0m Trial 72 finished with value: 0.81171875 and parameters: {'n_layers': 1, 'n_units_l0': 125, 'dropout_l0': 0.37800305071090357, 'optimizer': 'Adam', 'lr': 0.006104553959271837}. Best is trial 71 with value: 0.8421875.\u001b[0m\n\u001b[32m[I 2023-05-06 05:50:57,002]\u001b[0m Trial 73 pruned. \u001b[0m\n\u001b[32m[I 2023-05-06 05:50:57,785]\u001b[0m Trial 74 pruned. \u001b[0m\n\u001b[32m[I 2023-05-06 05:50:58,598]\u001b[0m Trial 75 pruned. \u001b[0m\n\u001b[32m[I 2023-05-06 05:50:59,461]\u001b[0m Trial 76 pruned. \u001b[0m\n\u001b[32m[I 2023-05-06 05:51:00,258]\u001b[0m Trial 77 pruned. \u001b[0m\n\u001b[32m[I 2023-05-06 05:51:01,688]\u001b[0m Trial 78 pruned. \u001b[0m\n\u001b[32m[I 2023-05-06 05:51:02,532]\u001b[0m Trial 79 pruned. \u001b[0m\n\u001b[32m[I 2023-05-06 05:51:03,341]\u001b[0m Trial 80 pruned. \u001b[0m\n\u001b[32m[I 2023-05-06 05:51:04,780]\u001b[0m Trial 81 pruned. \u001b[0m\n\u001b[32m[I 2023-05-06 05:51:08,899]\u001b[0m Trial 82 pruned. \u001b[0m\n\u001b[32m[I 2023-05-06 05:51:09,736]\u001b[0m Trial 83 pruned. \u001b[0m\n\u001b[32m[I 2023-05-06 05:51:10,610]\u001b[0m Trial 84 pruned. \u001b[0m\n\u001b[32m[I 2023-05-06 05:51:12,798]\u001b[0m Trial 85 pruned. \u001b[0m\n\u001b[32m[I 2023-05-06 05:51:13,598]\u001b[0m Trial 86 pruned. \u001b[0m\n\u001b[32m[I 2023-05-06 05:51:15,720]\u001b[0m Trial 87 pruned. \u001b[0m\n\u001b[32m[I 2023-05-06 05:51:16,541]\u001b[0m Trial 88 pruned. \u001b[0m\n\u001b[32m[I 2023-05-06 05:51:17,422]\u001b[0m Trial 89 pruned. \u001b[0m\n\u001b[32m[I 2023-05-06 05:51:19,545]\u001b[0m Trial 90 pruned. \u001b[0m\n\u001b[32m[I 2023-05-06 05:51:20,414]\u001b[0m Trial 91 pruned. \u001b[0m\n\u001b[32m[I 2023-05-06 05:51:21,329]\u001b[0m Trial 92 pruned. \u001b[0m\n\u001b[32m[I 2023-05-06 05:51:22,183]\u001b[0m Trial 93 pruned. \u001b[0m\n\u001b[32m[I 2023-05-06 05:51:24,320]\u001b[0m Trial 94 pruned. \u001b[0m\n\u001b[32m[I 2023-05-06 05:51:25,110]\u001b[0m Trial 95 pruned. \u001b[0m\n\u001b[32m[I 2023-05-06 05:51:28,600]\u001b[0m Trial 96 pruned. \u001b[0m\n\u001b[32m[I 2023-05-06 05:51:29,422]\u001b[0m Trial 97 pruned. \u001b[0m\n\u001b[32m[I 2023-05-06 05:51:30,265]\u001b[0m Trial 98 pruned. \u001b[0m\n\u001b[32m[I 2023-05-06 05:51:31,089]\u001b[0m Trial 99 pruned. \u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Study statistics: \n  Number of finished trials:  100\n  Number of pruned trials:  68\n  Number of complete trials:  32\nBest trial:\n  Value:  0.8421875\n  Params: \n    n_layers: 1\n    n_units_l0: 117\n    dropout_l0: 0.40746502244647825\n    optimizer: Adam\n    lr: 0.004546171411634709\n","output_type":"stream"}]}]}