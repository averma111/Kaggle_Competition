{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/averma111/pytorch-cafa-5-prediction?scriptVersionId=130469247\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"%%capture \n!pip install torchmetrics","metadata":{"execution":{"iopub.status.busy":"2023-05-22T01:07:35.500351Z","iopub.execute_input":"2023-05-22T01:07:35.500788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport gc\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom tqdm.notebook import tqdm\ntqdm.pandas()\nimport torch\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom sklearn.model_selection import train_test_split\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchmetrics import AUROC\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_dataframe(path):\n    return pd.read_csv(path,sep='\\t')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_terms = '/kaggle/input/cafa-5-protein-function-prediction/Train/train_terms.tsv'\ntrain_taxonomy ='/kaggle/input/cafa-5-protein-function-prediction/Train/train_taxonomy.tsv'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_dataframe(train_terms).head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_dataframe(train_taxonomy).head()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def summary(text, df):\n    print(f'{text} shape: {df.shape}')\n    summ = pd.DataFrame(df.dtypes, columns=['dtypes'])\n    summ['null'] = df.isnull().sum()\n    summ['unique'] = df.nunique()\n    summ['min'] = df.min()\n    summ['median'] = df.median()\n    summ['max'] = df.max()\n    summ['mean'] = df.mean()\n    summ['std'] = df.std()\n    summ['duplicate'] = df.duplicated().sum()\n    return summ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n    \n    return df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"summary('train_terms',reduce_mem_usage(get_dataframe(train_terms)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"summary('train_terms',reduce_mem_usage(get_dataframe(train_taxonomy)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.countplot(data=reduce_mem_usage(get_dataframe(train_terms)),x='aspect',color='r')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"terms = reduce_mem_usage(get_dataframe(train_terms)).groupby(['aspect', 'term'])['term'].count().reset_index(name='frequency')\nterms.groupby('aspect')['term'].nunique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fractions = (terms.groupby('aspect')['term'].nunique() / terms['term'].nunique() * 1500).apply(round)\nprint(fractions)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_terms = set()\nfor aspect, number in fractions.items():\n    final_terms = terms.loc[(terms.aspect == aspect)]\n    final_terms = final_terms.nlargest(number, columns='frequency', keep='first')\n    final_terms.update(final_terms.term.to_list())\n    \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def assign_labels(annotate,final_terms =set(final_terms)):\n    intersection = final_terms.intersection(annotate)\n    labels = np.isin(np.array(list(final_terms)), np.array(list(intersection)))\n    return list(labels.astype('int'))\n\nannotate = reduce_mem_usage(get_dataframe(train_terms)).groupby('EntryID')['term'].apply(set)\nlabels = annotate.progress_apply(assign_labels)\nlabels.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_features_labels():\n    train_ids = np.load('/kaggle/input/t5embeds/train_ids.npy')\n    X = np.load('/kaggle/input/t5embeds/train_embeds.npy')\n    y = np.array(labels[train_ids].to_list())\n    return X,y","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_test_dataset(features,labels):\n    return  train_test_split(features,labels,test_size=0.2,shuffle=True,random_state=42)\n\nX_train,X_val,y_train,y_val = train_test_dataset(*get_features_labels())\nprint(X_train.shape,X_val.shape,y_train.shape,y_val.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def convert_to_torch(value):\n    return torch.tensor(data=value,dtype=torch.float32,requires_grad=True,device=device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CAFA5Data(Dataset):\n    def __init__(self, X_data, y_data):\n        self.X_data = X_data\n        self.y_data = y_data\n        \n    def __getitem__(self, index):\n            return self.X_data[index], self.y_data[index]\n        \n    def __len__ (self):\n        return len(self.X_data)\n\nX_data = convert_to_torch(X_train)\ny_data = convert_to_torch(y_train)\nX_val = convert_to_torch(X_val)\ny_val = convert_to_torch(y_val)\ntrain_data = CAFA5Data(X_data,y_data)\ntest_data = CAFA5Data(X_val,y_val)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CAFA5NNetBase(torch.nn.Module):\n    \n    def training_step(self,batch):\n        features,labels = batch\n        out = self(features)\n        loss = F.binary_cross_entropy(out,labels)\n        return loss\n    \n    def validation_step(self, batch):\n        features, labels = batch \n        out = self(features)                    # Generate predictions\n        loss = F.binary_cross_entropy(out, labels)   # Calculate loss\n        acc = auroc(out, labels)           # Calculate accuracy\n        return {'Validation_loss': loss.detach(), 'Validation_acc': acc}\n        \n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['Validation_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n        batch_accs = [x['Validation_acc'] for x in outputs]\n        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n        return {'Validation_loss': epoch_loss.item(), 'Valdation_acc': epoch_acc.item()}\n    \n    def epoch_end(self, epoch, result):\n        print(\"Epoch [{}], Train_loss: {:.4f}, Validation_loss: {:.4f}, Validation_acc: {:.4f}\".format(\n            epoch, result['Train_loss'], result['Validation_loss'], result['Validation_acc']))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CAFA5NNet(CAFA5NNetBase):\n    def __init__(self,input_features,output_features):\n        super(CAFA5NNet,self).__init__()\n        self.network = torch.nn.Sequential(\n        torch.nn.Linear(input_features,256),\n        torch.nn.ReLU(),\n        torch.nn.Linear(256,128),    \n        torch.nn.ReLU(),\n        torch.nn.Linear(128,output_features),\n        torch.nn.Sigmoid()    \n        )\n    def forward(self,inputs):\n        return self.network(inputs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = CAFA5NNet(X_train.shape[1],y_train.shape[1])\nmodel.to(device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 32\nEPOCHS = 100\nLEARNING_RATE = 0.1\nMOMENTUM = 0.9\nOPT_FUNC = torch.optim.Adam","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_dataloaders(dataset_type,batch,shuffle):\n    if shuffle:\n         return DataLoader(dataset=dataset_type, batch_size=batch, shuffle=True)\n    else:\n        return DataLoader(dataset=dataset_type, batch_size=batch,shuffle=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def auroc(outputs, labels):\n    auroc = AUROC(task=\"multiclass\", num_classes=3)\n    return auroc(preds, target)\n\n  \n@torch.no_grad()\ndef evaluate(model, val_loader):\n    model.eval()\n    outputs = [model.validation_step(batch) for batch in val_loader]\n    return model.validation_epoch_end(outputs)\n\n  \ndef fit(epochs, lr, model, train_loader, val_loader, opt_func = OPT_FUNC):\n    \n    history = []\n    optimizer = opt_func(model.parameters(),lr)\n    for epoch in tqdm(range(epochs)):\n        \n        model.train()\n        train_losses = []\n        for batch in train_loader:\n            loss = model.training_step(batch)\n            train_losses.append(loss)\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n            \n        result = evaluate(model, val_loader)\n        result['Train_loss'] = torch.stack(train_losses).mean().item()\n        model.epoch_end(epoch, result)\n        history.append(result)\n    \n    return history","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dl = get_dataloaders(train_data,BATCH_SIZE,True)\nval_dl = get_dataloaders(test_data,BATCH_SIZE,False)\nhistory = fit(EPOCHS, LEARNING_RATE, model, train_dl, val_dl,OPT_FUNC)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_accuracies(history):\n    \"\"\" Plot the history of accuracies\"\"\"\n    accuracies = [x['val_acc'] for x in history]\n    plt.plot(accuracies, '-x')\n    plt.xlabel('Epoch')\n    plt.ylabel('Accuracy')\n    plt.title('Accuracy vs. No. of epochs');\n    \n\nplot_accuracies(history)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_losses(history):\n    \"\"\" Plot the losses in each epoch\"\"\"\n    train_losses = [x.get('Train_loss') for x in history]\n    val_losses = [x['Validation_loss'] for x in history]\n    plt.plot(train_losses, '-bx')\n    plt.plot(val_losses, '-rx')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend(['Training', 'Validation'])\n    plt.title('Loss vs. No. of epochs');\n\nplot_losses(history)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_ids = np.load('/kaggle/input/t5embeds/test_ids.npy')\nx_test = np.load('/kaggle/input/t5embeds/test_embeds.npy')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = model.predict(x_test)\ndel x_test\ngc.collect()\n\nchunk_size = 5_000\nchunks = [range(i, min(i + chunk_size, len(predictions))) for i in range(0, len(predictions), chunk_size)]\n\nfinal_sub = pd.DataFrame()  # Create an empty DataFrame to hold the final result\n\nprint(f\"processing {len(chunks)} chunks of {chunk_size} predictions each\")\n\nfor chunk in chunks:\n    print(f\"processing chunk {chunk}\")\n    sub = pd.DataFrame(data=predictions[chunk], columns=list(selected_terms), index=test_ids[chunk])\n    sub = sub.T.unstack().reset_index(name='prediction')\n    sub = sub.loc[sub['prediction'] > 0]\n    final_sub = pd.concat([final_sub, sub])  # Concatenate current chunk DataFrame to the final DataFrame\n\nfinal_sub.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}