{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/averma111/lightning-timeseries?scriptVersionId=136716199\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# Re-loads all imports every time the cell is ran. \n%reload_ext autoreload\n\nfrom time import time\n\nimport numpy as np\nimport pandas as pd\npd.options.display.float_format = '{:,.5f}'.format\n\nfrom IPython.display import display\n\n# Sklearn tools\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\n# Neural Networks\nimport torch\nimport torch.nn as nn\n\nfrom torch.utils.data import Dataset, DataLoader\n\nimport pytorch_lightning as pl\nfrom pytorch_lightning import Trainer, seed_everything\nfrom pytorch_lightning.loggers.csv_logs import CSVLogger\n\n# Plotting\n%matplotlib inline\nimport matplotlib.pyplot as plt\n\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"execution":{"iopub.status.busy":"2023-07-14T02:35:54.051049Z","iopub.execute_input":"2023-07-14T02:35:54.051428Z","iopub.status.idle":"2023-07-14T02:35:54.151078Z","shell.execute_reply.started":"2023-07-14T02:35:54.051401Z","shell.execute_reply":"2023-07-14T02:35:54.150029Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"/kaggle/input/playground-series-s3e19/sample_submission.csv\n/kaggle/input/playground-series-s3e19/train.csv\n/kaggle/input/playground-series-s3e19/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"class TimeseriesDataset(Dataset):   \n    def __init__(self, X: np.ndarray, y: np.ndarray, seq_len: int = 1):\n        self.X = torch.tensor(X).float()\n        self.y = torch.tensor(y).float()\n        self.seq_len = seq_len\n\n    def __len__(self):\n        return self.X.__len__() - (self.seq_len-1)\n\n    def __getitem__(self, index):\n        return (self.X[index:index+self.seq_len], self.y[index+self.seq_len-1])","metadata":{"execution":{"iopub.status.busy":"2023-07-14T02:35:54.15351Z","iopub.execute_input":"2023-07-14T02:35:54.153956Z","iopub.status.idle":"2023-07-14T02:35:54.164162Z","shell.execute_reply.started":"2023-07-14T02:35:54.153919Z","shell.execute_reply":"2023-07-14T02:35:54.162655Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"class TimeseriesDatasetTest(Dataset):   \n    def __init__(self, X: np.ndarray, seq_len: int = 1):\n        self.X = torch.tensor(X).float()\n        self.seq_len = seq_len\n\n    def __len__(self):\n        return self.X.__len__() - (self.seq_len-1)\n\n    def __getitem__(self, index):\n        return (self.X[index:index+self.seq_len])","metadata":{"execution":{"iopub.status.busy":"2023-07-14T02:35:54.165382Z","iopub.execute_input":"2023-07-14T02:35:54.165684Z","iopub.status.idle":"2023-07-14T02:35:54.179133Z","shell.execute_reply.started":"2023-07-14T02:35:54.165659Z","shell.execute_reply":"2023-07-14T02:35:54.178355Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"class FeatureGeneration:\n    \n    def datetime_features(self,df):\n        df['month'] = df['date'].dt.month\n        df['day'] = df['date'].dt.day\n        df['year'] = df['date'].dt.year\n        df['dayofweek'] = df['date'].dt.dayofweek\n        df['quarter'] = df['date'].dt.quarter\n        df['dayofmonth'] = df['date'].dt.day\n        df['weekofyear'] = df['date'].dt.weekofyear\n        return df\n    \n    def seasonality_features(df):\n        df['month_sin'] = np.sin(2*np.pi*df.month/12)\n        df['month_cos'] = np.cos(2*np.pi*df.month/12)\n        df['day_sin'] = np.sin(2*np.pi*df.day/24)\n        df['day_cos'] = np.cos(2*np.pi*df.day/24)\n        return df_temp","metadata":{"execution":{"iopub.status.busy":"2023-07-14T02:35:54.181125Z","iopub.execute_input":"2023-07-14T02:35:54.182128Z","iopub.status.idle":"2023-07-14T02:35:54.198601Z","shell.execute_reply.started":"2023-07-14T02:35:54.182081Z","shell.execute_reply":"2023-07-14T02:35:54.197109Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nclass ForecastingDataModule(pl.LightningDataModule):\n    \n    def __init__(self, seq_len = 1, batch_size = 128, num_workers=0):\n        super().__init__()\n        self.seq_len = seq_len\n        self.batch_size = batch_size\n        self.num_workers = num_workers\n        self.X_train = None\n        self.y_train = None\n        self.X_val = None\n        self.y_val = None\n        self.X_test = None\n        self.X_test = None\n        self.columns = None\n        self.preprocessing = None\n\n    def prepare_data(self):\n        path = '/kaggle/input/playground-series-s3e19/train.csv'\n        df = pd.read_csv(\n            path, \n            sep=',', \n            parse_dates=['date'], \n            infer_datetime_format=True, \n            low_memory=False\n        )\n\n        X = df.copy()\n        X['store'] =  LabelEncoder().fit_transform(X['store'])\n        X['product'] =  LabelEncoder().fit_transform(X['product'])\n        X['country'] =  LabelEncoder().fit_transform(X['country'])\n        X = X.loc[:, X.columns!='id']\n        y = X['num_sold']\n        X.drop(columns=['date','num_sold'],axis=1,inplace=True)\n        self.columns = X.columns\n        X_train, X_val, y_train, y_val = train_test_split(\n            X, y, test_size=0.25, shuffle=False\n        )\n        #print(X_train.shape,X_val.shape,y_train.shape,y_val.shape)\n        self.X_train=X_train\n        self.X_val = X_val\n        self.y_train = y_train\n        self.y_val = y_val\n\n    def setup(self, stage=None):\n        preprocessing = StandardScaler()\n        if stage == 'fit':\n            self.X_train = preprocessing.fit_transform(self.X_train)\n            self.y_train = self.y_train.values\n            self.X_val = preprocessing.fit_transform(self.X_val)\n            self.y_val = self.y_val.values\n\n        if stage == 'test':\n            self.X_test = preprocessing.fit_transform(self.X_test)\n            \n        \n\n    def train_dataloader(self):\n        train_dataset = TimeseriesDataset(self.X_train, \n                                          self.y_train, \n                                          seq_len=self.seq_len)\n        train_loader = DataLoader(train_dataset, \n                                  batch_size = self.batch_size, \n                                  shuffle = False, \n                                  num_workers = self.num_workers)\n        \n        return train_loader\n\n    def val_dataloader(self):\n        val_dataset = TimeseriesDataset(self.X_val, \n                                        self.y_val, \n                                        seq_len=self.seq_len)\n        val_loader = DataLoader(val_dataset, \n                                batch_size = self.batch_size, \n                                shuffle = False, \n                                num_workers = self.num_workers)\n\n        return val_loader\n    \n    \n    def prepare_data_test(self):\n        path = '/kaggle/input/playground-series-s3e19/test.csv'\n        df = pd.read_csv(\n            path, \n            sep=',', \n            parse_dates=['date'], \n            infer_datetime_format=True, \n            low_memory=False\n        )\n\n        X = df.copy()\n        X['store'] =  LabelEncoder().fit_transform(X['store'])\n        X['product'] =  LabelEncoder().fit_transform(X['product'])\n        X['country'] =  LabelEncoder().fit_transform(X['country'])\n        X = X.loc[:, X.columns!='id']\n        X.drop(columns=['date'],axis=1,inplace=True)\n        self.columns = X.columns\n        self.X_test = X\n\n    def test_dataloader(self):\n        test_dataset = TimeseriesDatasetTest(self.X_test,\n                                         seq_len=self.seq_len)\n        test_loader = DataLoader(test_dataset, \n                                 batch_size = self.batch_size, \n                                 shuffle = False, \n                                 num_workers = self.num_workers)\n\n        return test_loader","metadata":{"execution":{"iopub.status.busy":"2023-07-14T02:35:54.199729Z","iopub.execute_input":"2023-07-14T02:35:54.200135Z","iopub.status.idle":"2023-07-14T02:35:54.224733Z","shell.execute_reply.started":"2023-07-14T02:35:54.200099Z","shell.execute_reply":"2023-07-14T02:35:54.2234Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"class LSTMRegressor(pl.LightningModule):\n    def __init__(self, \n                 n_features, \n                 hidden_size, \n                 seq_len, \n                 batch_size,\n                 num_layers, \n                 #dropout, \n                 learning_rate,\n                 criterion):\n        super(LSTMRegressor, self).__init__()\n        self.n_features = n_features\n        self.hidden_size = hidden_size\n        self.seq_len = seq_len\n        self.batch_size = batch_size\n        self.num_layers = num_layers\n        #self.dropout = dropout\n        self.criterion = criterion\n        self.learning_rate = learning_rate\n\n        self.lstm = nn.LSTM(input_size=n_features, \n                            hidden_size=hidden_size,\n                            num_layers=num_layers, \n                            #dropout=dropout, \n                            batch_first=True)\n        self.linear = nn.Linear(hidden_size, 1)\n        \n    def forward(self, x):\n        lstm_out, _ = self.lstm(x)\n        y_pred = self.linear(lstm_out[:,-1])\n        return y_pred\n    \n    def configure_optimizers(self):\n        return torch.optim.SGD(self.parameters(), lr=self.learning_rate,momentum=0.9)\n\n    def training_step(self, batch, batch_idx):\n        x, y = batch\n        y_hat = self(x)\n        loss = self.criterion(y_hat, y)\n        self.log('Train_loss', loss)\n\n    def validation_step(self, batch, batch_idx):\n        x, y = batch\n        y_hat = self(x)\n        loss = self.criterion(y_hat, y)\n        self.log('Validation_loss', loss)\n    \n    def test_step(self, batch, batch_idx):\n        x, y = batch\n        y_hat = self(x)\n        loss = self.criterion(y_hat, y)\n        self.log('Test_loss', loss)","metadata":{"execution":{"iopub.status.busy":"2023-07-14T02:35:54.227177Z","iopub.execute_input":"2023-07-14T02:35:54.227543Z","iopub.status.idle":"2023-07-14T02:35:54.246116Z","shell.execute_reply.started":"2023-07-14T02:35:54.227512Z","shell.execute_reply":"2023-07-14T02:35:54.244884Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"p = dict(\n    seq_len = 24,\n    batch_size = 128, \n    criterion = nn.MSELoss(),\n    max_epochs = 10,\n    n_features = 3,\n    hidden_size = 1,\n    num_layers = 1,\n    #dropout = 0.2,\n    learning_rate = 0.001,\n)","metadata":{"execution":{"iopub.status.busy":"2023-07-14T02:35:54.247064Z","iopub.execute_input":"2023-07-14T02:35:54.247451Z","iopub.status.idle":"2023-07-14T02:35:54.267911Z","shell.execute_reply.started":"2023-07-14T02:35:54.247421Z","shell.execute_reply":"2023-07-14T02:35:54.266318Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"seed_everything(1)\ncsv_logger = CSVLogger('./', name='lstm', version='0'),\n\nmodel = LSTMRegressor(\n    n_features = p['n_features'],\n    hidden_size = p['hidden_size'],\n    seq_len = p['seq_len'],\n    batch_size = p['batch_size'],\n    criterion = p['criterion'],\n    num_layers = p['num_layers'],\n    #dropout = p['dropout'],\n    learning_rate = p['learning_rate']\n)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-07-14T02:35:54.269427Z","iopub.execute_input":"2023-07-14T02:35:54.269763Z","iopub.status.idle":"2023-07-14T02:35:54.29305Z","shell.execute_reply.started":"2023-07-14T02:35:54.269735Z","shell.execute_reply":"2023-07-14T02:35:54.292264Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"print(model)","metadata":{"execution":{"iopub.status.busy":"2023-07-14T02:35:54.294047Z","iopub.execute_input":"2023-07-14T02:35:54.294366Z","iopub.status.idle":"2023-07-14T02:35:54.30852Z","shell.execute_reply.started":"2023-07-14T02:35:54.294328Z","shell.execute_reply":"2023-07-14T02:35:54.307845Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"LSTMRegressor(\n  (criterion): MSELoss()\n  (lstm): LSTM(3, 1, batch_first=True)\n  (linear): Linear(in_features=1, out_features=1, bias=True)\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer = Trainer(\n    max_epochs=p['max_epochs'],\n    logger=csv_logger,\n    accelerator='auto',\n    log_every_n_steps=1\n)","metadata":{"execution":{"iopub.status.busy":"2023-07-14T02:35:54.309399Z","iopub.execute_input":"2023-07-14T02:35:54.309655Z","iopub.status.idle":"2023-07-14T02:35:54.384097Z","shell.execute_reply.started":"2023-07-14T02:35:54.309634Z","shell.execute_reply":"2023-07-14T02:35:54.382941Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"dm = ForecastingDataModule(\n    seq_len = p['seq_len'],\n    batch_size = p['batch_size']\n)\ndm.prepare_data()\n","metadata":{"execution":{"iopub.status.busy":"2023-07-14T02:35:54.388138Z","iopub.execute_input":"2023-07-14T02:35:54.388771Z","iopub.status.idle":"2023-07-14T02:35:54.591963Z","shell.execute_reply.started":"2023-07-14T02:35:54.388736Z","shell.execute_reply":"2023-07-14T02:35:54.590643Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"trainer.fit(model, dm)\n","metadata":{"execution":{"iopub.status.busy":"2023-07-14T02:35:54.593548Z","iopub.execute_input":"2023-07-14T02:35:54.593991Z"},"trusted":true},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Sanity Checking: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"281bf39909e9450d95a593438ccae302"}},"metadata":{}}]},{"cell_type":"code","source":"metrics = pd.read_csv('./lstm/0/metrics.csv')\ntrain_loss = metrics[['Train_loss', 'step', 'epoch']][~np.isnan(metrics['Train_loss'])]\nval_loss = metrics[['Validation_loss', 'epoch']][~np.isnan(metrics['Validation_loss'])]\n\nfig, axes = plt.subplots(1, 2, figsize=(16, 5), dpi=100)\naxes[0].set_title('Train loss per batch')\naxes[0].plot(train_loss['step'], train_loss['Train_loss'])\naxes[1].set_title('Validation loss per epoch')\naxes[1].plot(val_loss['epoch'], val_loss['Validation_loss'], color='orange')\nplt.show(block = True)\n\nprint('MSE:')\nprint(f\"Train loss: {train_loss['Train_loss'].iloc[-1]:.3f}\")\nprint(f\"Val loss:   {val_loss['Validation_loss'].iloc[-1]:.3f}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dm.prepare_data_test()\ntrainer.test(model, datamodule=dm)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metrics = pd.read_csv('./lstm/0/metrics.csv')\ntest_loss = metrics['Test_loss'].iloc[-1]\n\nfig, axes = plt.subplots(1, 1, figsize=(16, 5), dpi=100)\naxes[0].set_title('Test loss per batch')\naxes[0].plot(test_loss['step'], test_loss['Test_loss'])\nplt.show(block = True)\n\nprint('MSE:')\nprint(f'Test loss: {test_loss:.3f}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}