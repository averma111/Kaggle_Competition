{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/averma111/pytorch-hubmap-cnn?scriptVersionId=131946312\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"%%capture\n!pip install 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'","metadata":{"execution":{"iopub.status.busy":"2023-06-02T06:36:59.981186Z","iopub.execute_input":"2023-06-02T06:36:59.982168Z","iopub.status.idle":"2023-06-02T06:37:42.764304Z","shell.execute_reply.started":"2023-06-02T06:36:59.982117Z","shell.execute_reply":"2023-06-02T06:37:42.763002Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom glob import glob\nimport json\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchmetrics import AveragePrecision\nimport torch\nimport torchvision\nfrom torchvision.transforms import transforms\nimport os\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom tqdm.notebook import tqdm\nimport torch.nn.functional as F\nimport time\nimport base64\nfrom pycocotools import _mask as coco_mask\nimport typing as t\nimport zlib","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-06-02T06:37:45.432471Z","iopub.execute_input":"2023-06-02T06:37:45.432863Z","iopub.status.idle":"2023-06-02T06:37:45.500203Z","shell.execute_reply.started":"2023-06-02T06:37:45.432824Z","shell.execute_reply":"2023-06-02T06:37:45.498736Z"},"trusted":true},"execution_count":69,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[0;32mIn[69], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mbase64\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpycocotools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _mask \u001b[38;5;28;01mas\u001b[39;00m coco_mask\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mt\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mzlib\u001b[39;00m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pycocotools'"],"ename":"ModuleNotFoundError","evalue":"No module named 'pycocotools'","output_type":"error"}]},{"cell_type":"code","source":"class Config:\n    \n    batch_size= 64\n    n_epochs = 10\n    learning_rate = 0.001\n    \n    \n    \nconfig = Config()","metadata":{"execution":{"iopub.status.busy":"2023-06-02T05:56:55.050627Z","iopub.execute_input":"2023-06-02T05:56:55.050918Z","iopub.status.idle":"2023-06-02T05:56:55.055932Z","shell.execute_reply.started":"2023-06-02T05:56:55.050894Z","shell.execute_reply":"2023-06-02T05:56:55.055036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Acquisition:\n    \n    def get_datframe(self,path):\n        return pd.read_csv(path)\n    \n    def get_json_dataframe(self, json_file):\n        data = []\n        with open(json_file, 'r') as file:\n            for line in file:\n                item = json.loads(line)\n                data.append(item)\n        \n        json_df = pd.DataFrame(data)\n        return json_df\n    \n        \n        \nacq = Acquisition()      ","metadata":{"execution":{"iopub.status.busy":"2023-06-02T05:56:55.057876Z","iopub.execute_input":"2023-06-02T05:56:55.05832Z","iopub.status.idle":"2023-06-02T05:56:55.065701Z","shell.execute_reply.started":"2023-06-02T05:56:55.058191Z","shell.execute_reply":"2023-06-02T05:56:55.064554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"title=acq.get_datframe(path='/kaggle/input/hubmap-hacking-the-human-vasculature/tile_meta.csv')\ntitle.head()","metadata":{"execution":{"iopub.status.busy":"2023-06-02T05:56:55.093688Z","iopub.execute_input":"2023-06-02T05:56:55.094664Z","iopub.status.idle":"2023-06-02T05:56:55.115417Z","shell.execute_reply.started":"2023-06-02T05:56:55.094629Z","shell.execute_reply":"2023-06-02T05:56:55.114397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wsi = acq.get_datframe(path='/kaggle/input/hubmap-hacking-the-human-vasculature/wsi_meta.csv')\nwsi.head()","metadata":{"execution":{"iopub.status.busy":"2023-06-02T05:56:55.117714Z","iopub.execute_input":"2023-06-02T05:56:55.118166Z","iopub.status.idle":"2023-06-02T05:56:55.134607Z","shell.execute_reply.started":"2023-06-02T05:56:55.118114Z","shell.execute_reply":"2023-06-02T05:56:55.133635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2023-06-02T05:56:55.135839Z","iopub.execute_input":"2023-06-02T05:56:55.136697Z","iopub.status.idle":"2023-06-02T05:56:55.142081Z","shell.execute_reply.started":"2023-06-02T05:56:55.136666Z","shell.execute_reply":"2023-06-02T05:56:55.141098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"polygons_df = acq.get_json_dataframe('/kaggle/input/hubmap-hacking-the-human-vasculature/polygons.jsonl')\npolygons_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-06-02T05:56:55.143754Z","iopub.execute_input":"2023-06-02T05:56:55.144377Z","iopub.status.idle":"2023-06-02T05:56:59.990531Z","shell.execute_reply.started":"2023-06-02T05:56:55.14434Z","shell.execute_reply":"2023-06-02T05:56:59.989445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ImageHuBMAPDataset(Dataset):\n    \n    def __init__(self, image_dir, labels_file, transform=None):\n        \n        with open(labels_file, 'r') as json_file:\n            self.json_labels = [json.loads(line) for line in json_file]\n            \n        self.image_dir = image_dir\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.json_labels)\n\n    def __getitem__(self, idx):\n        image_path = os.path.join(self.image_dir, f\"{self.json_labels[idx]['id']}.tif\")\n        image = Image.open(image_path)\n\n        mask = np.zeros((512, 512), dtype=np.float32)\n\n        for annot in self.json_labels[idx]['annotations']:\n            cords = annot['coordinates']\n            if annot['type'] == \"blood_vessel\":\n                for cd in cords:\n                    rr, cc = np.array([i[1] for i in cd]), np.asarray([i[0] for i in cd])\n                    mask[rr, cc] = 1\n\n        image = torch.tensor(np.array(image), dtype=torch.float32,requires_grad=True).permute(2, 0, 1)  \n        mask = torch.tensor(mask, dtype=torch.float32)\n\n        if self.transform:\n            image = self.transform(image)\n\n        return image, mask","metadata":{"execution":{"iopub.status.busy":"2023-06-02T05:56:59.993891Z","iopub.execute_input":"2023-06-02T05:56:59.99434Z","iopub.status.idle":"2023-06-02T05:57:00.005655Z","shell.execute_reply.started":"2023-06-02T05:56:59.994303Z","shell.execute_reply":"2023-06-02T05:57:00.004252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class get_images_labels:\n    def __init__(self, root_path):\n        self.root_path = root_path\n    \n    def set_path(self,filename):\n        return os.path.join(self.root_path,filename)\n    \n    def get_test_path(self,filename):\n        return os.path.join(self.root_path,filename)\n        \n\n        \nimg_lble = get_images_labels(root_path='/kaggle/input/hubmap-hacking-the-human-vasculature')      \n\nimage_folder = img_lble.set_path(filename='train')\nlabels_file = img_lble.set_path(filename='polygons.jsonl')\ntest_image_folder =img_lble.get_test_path(filename='test')","metadata":{"execution":{"iopub.status.busy":"2023-06-02T05:57:00.007369Z","iopub.execute_input":"2023-06-02T05:57:00.00772Z","iopub.status.idle":"2023-06-02T05:57:00.015669Z","shell.execute_reply.started":"2023-06-02T05:57:00.007687Z","shell.execute_reply":"2023-06-02T05:57:00.014707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12, 8))\n\ndataset = ImageHuBMAPDataset(image_dir=image_folder, labels_file=labels_file)\nnum_samples = 8\n\nnum_rows = (num_samples + 3) // 4  \nnum_cols = min(num_samples, 4)\n\nfor i in range(num_samples):\n\n    image, mask = dataset[i]\n    image = image.permute(1, 2, 0).detach().numpy() / 255\n    subplot_index = i + 1\n\n    plt.subplot(num_rows, 2 * num_cols, 2 * subplot_index - 1)\n    plt.imshow(image)\n    plt.axis('off')\n    plt.title('Train_Image')\n\n    mask_subplot_index = (subplot_index - 1) % num_samples + 1\n\n    plt.subplot(num_rows, 2 * num_cols, 2 * subplot_index)\n    plt.imshow(mask, cmap='gray')\n    plt.axis('off')\n    plt.title('Train_Mask')\n\nplt.tight_layout(pad=0.2)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-06-02T05:57:00.017213Z","iopub.execute_input":"2023-06-02T05:57:00.017573Z","iopub.status.idle":"2023-06-02T05:57:04.845192Z","shell.execute_reply.started":"2023-06-02T05:57:00.017542Z","shell.execute_reply":"2023-06-02T05:57:04.844094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class HuBMAPClassificationNN(torch.nn.Module):\n    def __init__(self):\n        super(HuBMAPClassificationNN, self).__init__()\n        \n        self.network_1 = torch.nn.Sequential(\n            torch.nn.Conv2d(3, 32, kernel_size=3, padding=1),\n            torch.nn.ReLU(),\n            torch.nn.Conv2d(32, 32, kernel_size=3, padding=1),\n            torch.nn.ReLU(),\n            torch.nn.MaxPool2d(kernel_size=2, stride=2)\n        )\n\n        self.network_2 = torch.nn.Sequential(\n            torch.nn.Conv2d(32, 32, kernel_size=3, padding=1),\n            torch.nn.ReLU(),\n            torch.nn.Conv2d(32, 32, kernel_size=3, padding=1),\n            torch.nn.ReLU(),\n            torch.nn.ConvTranspose2d(32, 1, kernel_size=2, stride=2)\n        )\n\n    def forward(self, x):\n        x = self.network_1(x)\n        x = self.network_2(x)\n        x = torch.sigmoid(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2023-06-02T05:57:04.84666Z","iopub.execute_input":"2023-06-02T05:57:04.84722Z","iopub.status.idle":"2023-06-02T05:57:04.857027Z","shell.execute_reply.started":"2023-06-02T05:57:04.847187Z","shell.execute_reply":"2023-06-02T05:57:04.856265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = HuBMAPClassificationNN().to(device)\nprint(model)","metadata":{"execution":{"iopub.status.busy":"2023-06-02T05:57:04.858408Z","iopub.execute_input":"2023-06-02T05:57:04.859215Z","iopub.status.idle":"2023-06-02T05:57:04.87103Z","shell.execute_reply.started":"2023-06-02T05:57:04.859181Z","shell.execute_reply":"2023-06-02T05:57:04.870166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Trainer:\n    \n    def train_dataloader(self,image_folder,labels_file):\n        dataset = ImageHuBMAPDataset(image_folder,labels_file)\n        return DataLoader(dataset, batch_size=config.batch_size, shuffle=True)\n        \n  \n    def fit(self,epochs, lr, model, train_loader,opt_func):\n        history =[]\n        result = {}\n        \n        criterion = torch.nn.BCELoss() \n        optimizer = opt_func(model.parameters(), lr=lr)\n        \n        for epoch in range(epochs):\n            model.train() \n            running_loss = 0.0\n            start_time = time.time()\n            \n            for images, masks in train_loader:\n                images = images.to(device)\n                masks = masks.to(device)\n                optimizer.zero_grad()\n                outputs = model(images)\n                masks = masks.unsqueeze(1) \n                loss = criterion(outputs, masks)\n                loss.backward()\n                optimizer.step()\n                running_loss += loss.item()\n\n            epoch_loss = running_loss / len(train_loader)\n            epoch_time = time.time() - start_time\n            print(f\"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.4f}, Time: {epoch_time:.2f} seconds\")\n            result['Train_loss'] = epoch_loss\n            history.append(result)\n        return history \n        \n    \ntrainer = Trainer()","metadata":{"execution":{"iopub.status.busy":"2023-06-02T05:57:04.87257Z","iopub.execute_input":"2023-06-02T05:57:04.873647Z","iopub.status.idle":"2023-06-02T05:57:04.883323Z","shell.execute_reply.started":"2023-06-02T05:57:04.873613Z","shell.execute_reply":"2023-06-02T05:57:04.882405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history=trainer.fit(config.n_epochs, config.learning_rate, model, \n                    trainer.train_dataloader(image_folder,labels_file),\n                    torch.optim.Adam)","metadata":{"execution":{"iopub.status.busy":"2023-06-02T06:00:24.082507Z","iopub.execute_input":"2023-06-02T06:00:24.082865Z","iopub.status.idle":"2023-06-02T06:06:39.878443Z","shell.execute_reply.started":"2023-06-02T06:00:24.082835Z","shell.execute_reply":"2023-06-02T06:06:39.877421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_losses(history):\n    \"\"\" Plot the losses in each epoch\"\"\"\n    train_losses = [x.get('Train_loss') for x in history]\n    plt.plot(train_losses, '-bx')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend('Training')\n    plt.title('Loss vs. No. of epochs');\n\nplot_losses(history)","metadata":{"execution":{"iopub.status.busy":"2023-06-02T06:07:06.392406Z","iopub.execute_input":"2023-06-02T06:07:06.392775Z","iopub.status.idle":"2023-06-02T06:07:06.699987Z","shell.execute_reply.started":"2023-06-02T06:07:06.392745Z","shell.execute_reply":"2023-06-02T06:07:06.699057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ImageHuBMAPDatasetTest(Dataset):\n    def __init__(self, image_dir, transform=None):\n        self.image_dir = image_dir\n        self.transform = transform\n        self.image_files = sorted(os.listdir(image_dir))\n\n    def __len__(self):\n        return len(self.image_files)\n\n    def __getitem__(self, idx):\n        image_path = os.path.join(self.image_dir, self.image_files[idx])\n        image = Image.open(image_path)\n\n        if self.transform:\n            image = self.transform(image)\n\n        return image","metadata":{"execution":{"iopub.status.busy":"2023-06-02T06:07:48.991055Z","iopub.execute_input":"2023-06-02T06:07:48.99174Z","iopub.status.idle":"2023-06-02T06:07:48.998832Z","shell.execute_reply.started":"2023-06-02T06:07:48.991707Z","shell.execute_reply":"2023-06-02T06:07:48.997683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Test:\n    \n    def encode_binary_mask(mask: np.ndarray) -> t.Text:\n        if mask.dtype != bool:\n            raise ValueError(\n                \"encode_binary_mask expects a binary mask, received dtype == %s\" %\n                mask.dtype)\n\n        mask = np.squeeze(mask)\n        if len(mask.shape) != 2:\n            raise ValueError(\n                \"encode_binary_mask expects a 2d mask, received shape == %s\" %\n                mask.shape)\n\n        mask_to_encode = mask.reshape(mask.shape[0], mask.shape[1], 1)\n        mask_to_encode = mask_to_encode.astype(np.uint8)\n        mask_to_encode = np.asfortranarray(mask_to_encode)\n\n        encoded_mask = coco_mask.encode(mask_to_encode)[0][\"counts\"]\n\n        binary_str = zlib.compress(encoded_mask, zlib.Z_BEST_COMPRESSION)\n        base64_str = base64.b64encode(binary_str)\n        return base64_str\n\n    \n    \n    def mask_to_rle(self,mask):\n        pixels = mask.flatten(order=\"F\")\n        pixels = np.concatenate([[0], pixels, [0]])\n        runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n        runs[1::2] -= runs[::2]\n        rle = \" \".join(str(x) for x in runs)\n        return rle\n    \n    def get_test_transforms(self):\n        return transforms.Compose([transforms.ToTensor(),transforms.Normalize(\n            mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n        \n    \n    def test_dataloader(self,image_folder):\n        dataset = ImageHuBMAPDatasetTest(test_image_folder,self.get_test_transforms())\n        return DataLoader(dataset, batch_size=config.batch_size)\n    \n    \n\n    def evaluate(self,model):\n        model.eval()\n        predictions = []\n        with torch.no_grad():\n            for images in self.test_dataloader(test_image_folder):\n                images = images.to(device)\n                outputs = model(images)\n                predicted_masks = (outputs > 0.5).float()  \n                predictions.extend(predicted_masks.cpu().numpy())\n        return predictions\n    \n    \n        \ntest = Test()\n","metadata":{"execution":{"iopub.status.busy":"2023-06-02T06:31:15.910757Z","iopub.execute_input":"2023-06-02T06:31:15.911147Z","iopub.status.idle":"2023-06-02T06:31:16.019391Z","shell.execute_reply.started":"2023-06-02T06:31:15.911104Z","shell.execute_reply":"2023-06-02T06:31:16.018055Z"},"trusted":true},"execution_count":66,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[66], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mTest\u001b[39;00m:\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mencode_binary_mask\u001b[39m(mask: np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m t\u001b[38;5;241m.\u001b[39mText:\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n","Cell \u001b[0;32mIn[66], line 3\u001b[0m, in \u001b[0;36mTest\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mTest\u001b[39;00m:\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mencode_binary_mask\u001b[39m(mask: np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[43mt\u001b[49m\u001b[38;5;241m.\u001b[39mText:\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m      5\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m      6\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencode_binary_mask expects a binary mask, received dtype == \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m      7\u001b[0m                 mask\u001b[38;5;241m.\u001b[39mdtype)\n","\u001b[0;31mNameError\u001b[0m: name 't' is not defined"],"ename":"NameError","evalue":"name 't' is not defined","output_type":"error"}]},{"cell_type":"code","source":"class Submission:\n    \n    def submit_results(self,predictions,test_dataset):\n        submission = pd.DataFrame(columns=[\"id\", \"height\",\"width\",\"prediction_string\"])\n        image_ids = [os.path.splitext(file)[0] for file in test_dataset.image_files]\n        for image_id, prediction in zip(image_ids, predictions):\n            rle_encoded = test.mask_to_rle(prediction)\n            submission = submission.append({\"id\": image_id,\"height\":512,\"width\":512 ,\"prediction_string\": rle_encoded}, ignore_index=True)\n        submission.to_csv(\"submission.csv\", index=False)\n        \n        \nsubmit = Submission()\n\npredictions = test.evaluate(model)\ntest_dataset = ImageHuBMAPDatasetTest(test_image_folder,test.get_test_transforms())\nsubmit.submit_results(predictions,test_dataset,)","metadata":{"execution":{"iopub.status.busy":"2023-06-02T06:15:25.321635Z","iopub.execute_input":"2023-06-02T06:15:25.322317Z","iopub.status.idle":"2023-06-02T06:15:25.357482Z","shell.execute_reply.started":"2023-06-02T06:15:25.322267Z","shell.execute_reply":"2023-06-02T06:15:25.356422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.read_csv(\"/kaggle/working/submission.csv\")\ntest.head()","metadata":{"execution":{"iopub.status.busy":"2023-06-02T06:15:25.691022Z","iopub.execute_input":"2023-06-02T06:15:25.692106Z","iopub.status.idle":"2023-06-02T06:15:25.705413Z","shell.execute_reply.started":"2023-06-02T06:15:25.692061Z","shell.execute_reply":"2023-06-02T06:15:25.704401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}