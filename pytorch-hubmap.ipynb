{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/averma111/pytorch-hubmap-cnn?scriptVersionId=131277708\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"%%capture \n!pip install torchmetrics","metadata":{"execution":{"iopub.status.busy":"2023-05-28T02:31:53.856639Z","iopub.execute_input":"2023-05-28T02:31:53.857157Z","iopub.status.idle":"2023-05-28T02:32:09.052247Z","shell.execute_reply.started":"2023-05-28T02:31:53.857123Z","shell.execute_reply":"2023-05-28T02:32:09.050477Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"%%capture\n!pip install torchsummary","metadata":{"execution":{"iopub.status.busy":"2023-05-28T02:32:09.055069Z","iopub.execute_input":"2023-05-28T02:32:09.055776Z","iopub.status.idle":"2023-05-28T02:32:23.114834Z","shell.execute_reply.started":"2023-05-28T02:32:09.055735Z","shell.execute_reply":"2023-05-28T02:32:23.112466Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom glob import glob\nimport json\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchmetrics import AveragePrecision\nfrom torchmetrics.classification import BinaryF1Score\nfrom torchsummary import summary as torchsummary\nimport torch\nimport torchvision","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-28T02:40:46.259368Z","iopub.execute_input":"2023-05-28T02:40:46.25991Z","iopub.status.idle":"2023-05-28T02:40:46.268517Z","shell.execute_reply.started":"2023-05-28T02:40:46.259878Z","shell.execute_reply":"2023-05-28T02:40:46.266872Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"class Config:\n    batch_size= 128\n    n_epochs = 50\n    learning_rate = 0.001\n    opt_func = torch.optim.Adam\n    \n    \n    \nconfig = Config()","metadata":{"execution":{"iopub.status.busy":"2023-05-28T02:36:49.566629Z","iopub.execute_input":"2023-05-28T02:36:49.567294Z","iopub.status.idle":"2023-05-28T02:36:49.575782Z","shell.execute_reply.started":"2023-05-28T02:36:49.567252Z","shell.execute_reply":"2023-05-28T02:36:49.574101Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"class acquisition:\n    \n    def __init__(self,test_path,train_path):\n        self.test_path = test_path\n        self.train_path = train_path\n        \n    def get_datframe(self,path):\n        return pd.read_csv(path)\n    \n    def get_json_dataframe(self, json_file):\n        data = []\n        with open(json_file, 'r') as file:\n            for line in file:\n                item = json.loads(line)\n                data.append(item)\n        \n        json_df = pd.DataFrame(data)\n        \n        return json_df\n    \n    def get_image_path(self):\n        train_image_path = glob(self.train)\n        test_image_path = glob(self.test)\n        return train_image_path,test_image_path\n        \n        \n        ","metadata":{"execution":{"iopub.status.busy":"2023-05-28T02:32:41.28724Z","iopub.execute_input":"2023-05-28T02:32:41.288112Z","iopub.status.idle":"2023-05-28T02:32:41.301937Z","shell.execute_reply.started":"2023-05-28T02:32:41.288078Z","shell.execute_reply":"2023-05-28T02:32:41.300423Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class HuBMAPClassificationBaseNN(torch.nn.Module):\n    \n    def training_step(self,batch):\n        features,labels = batch\n        out = self(features)\n        loss = F.binary_cross_entropy(out,labels)\n        return loss\n    \n    def validation_step(self, batch):\n        features, labels = batch \n        out = self(features)                    # Generate predictions\n        loss = F.binary_cross_entropy(out, labels)   # Calculate loss\n        acc = aurpc(out, labels)           # Calculate accuracy\n        return {'Validation_loss': loss.detach(), 'Validation_acc': acc}\n        \n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['Validation_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n        batch_accs = [x['Validation_acc'] for x in outputs]\n        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n        return {'Validation_loss': epoch_loss.item(), 'Validation_acc': epoch_acc.item()}\n    \n    def epoch_end(self, epoch, result):\n        if epoch%5==0:\n            print(\"Epoch [{}], Train_loss: {:.4f}, Validation_loss: {:.4f}, Validation_acc: {:.4f}\".format(\n            epoch, result['Train_loss'], result['Validation_loss'], result['Validation_acc']))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class HuBMAPClassificationNN(torch.nn.Module):\n    def __init__(self):\n        super(HuBMAPClassificationBaseNN, self).__init__()\n        \n        self.network_1 = nn.Sequential(\n            torch.nn.Conv2d(3, 128, kernel_size=3, padding=1),\n            torch.nn.ReLU(),\n            torch.nn.Conv2d(128, 128, kernel_size=3, padding=1),\n            torch.nn.ReLU(),\n            torch.nn.MaxPool2d(kernel_size=2, stride=2)\n        )\n\n        self.network_2 = nn.Sequential(\n            torch.nn.Conv2d(128, 128, kernel_size=3, padding=1),\n            torch.nn.ReLU(),\n            torch.nn.Conv2d(128, 128, kernel_size=3, padding=1),\n            torch.nn.ReLU(),\n            torch.nn.ConvTranspose2d(128, 1, kernel_size=2, stride=2)\n        )\n\n    def forward(self, x):\n        x = self.network_1(x)\n        x = self.network_2(x)\n        x = torch.sigmoid(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2023-05-28T02:32:41.303977Z","iopub.execute_input":"2023-05-28T02:32:41.304484Z","iopub.status.idle":"2023-05-28T02:32:41.31936Z","shell.execute_reply.started":"2023-05-28T02:32:41.304444Z","shell.execute_reply":"2023-05-28T02:32:41.318147Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"model = HuBMAPClassificationNN().to(device)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torchsummary(model, X_data.size(), batch_size=-1, device='cuda')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Trainer:\n    \n    def aurpc(outputs, labels):\n        aurpc = AveragePrecision(task=\"binary\")\n        return aurpc(outputs, labels)\n\n  \n    @torch.no_grad()\n    def evaluate(model, val_loader):\n        model.eval()\n        outputs = [model.validation_step(batch) for batch in val_loader]\n        return model.validation_epoch_end(outputs)\n\n  \n    def fit(epochs, lr, model, train_loader, val_loader, opt_func = OPT_FUNC):\n    \n        history = []\n        optimizer = opt_func(model.parameters(),lr)\n        for epoch in tqdm(range(epochs)):\n        \n            model.train()\n            train_losses = []\n            for batch in train_loader:\n                loss = model.training_step(batch)\n                train_losses.append(loss)\n                loss.backward()\n                optimizer.step()\n                optimizer.zero_grad()\n            \n            result = evaluate(model, val_loader)\n            result['Train_loss'] = torch.stack(train_losses).mean().item()\n            model.epoch_end(epoch, result)\n            history.append(result)\n    \n        return history\n    \n    \ntrainer = Trainer()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = trainer.fit(config.n_epochsn, config.learning_rate, model, train_dl, val_dl, config.opt_func)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_accuracies(history):\n    \"\"\" Plot the history of accuracies\"\"\"\n    accuracies = [x['Validation_acc'] for x in history]\n    plt.plot(accuracies, '-x')\n    plt.xlabel('Epoch')\n    plt.ylabel('Accuracy')\n    plt.title('Accuracy vs. No. of epochs');\n    \n\nplot_accuracies(history)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_losses(history):\n    \"\"\" Plot the losses in each epoch\"\"\"\n    train_losses = [x.get('Train_loss') for x in history]\n    val_losses = [x['Validation_loss'] for x in history]\n    plt.plot(train_losses, '-bx')\n    plt.plot(val_losses, '-rx')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend(['Training', 'Validation'])\n    plt.title('Loss vs. No. of epochs');\n\nplot_losses(history)","metadata":{},"execution_count":null,"outputs":[]}]}