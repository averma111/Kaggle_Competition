{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/averma111/pytorch-hubmap-cnn?scriptVersionId=132080200\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom glob import glob\nimport json\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchmetrics import AveragePrecision\nimport torch\nimport torchvision\nfrom torchvision.transforms import transforms\nimport os\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom tqdm.notebook import tqdm\nimport torch.nn.functional as F\nimport time\nimport base64\nimport typing as t\nimport zlib","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-06-03T06:56:37.439182Z","iopub.execute_input":"2023-06-03T06:56:37.439589Z","iopub.status.idle":"2023-06-03T06:56:52.006409Z","shell.execute_reply.started":"2023-06-03T06:56:37.439508Z","shell.execute_reply":"2023-06-03T06:56:52.005429Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"%%capture\n!mkdir /kaggle/working/packages\n!cp -r /kaggle/input/pycocotools/* /kaggle/working/packages\nos.chdir(\"/kaggle/working/packages/pycocotools-2.0.6/\")\n!python setup.py install\n!pip install . --no-index --find-links /kaggle/working/packages/\nos.chdir(\"/kaggle/working\")\nfrom pycocotools import _mask as coco_mask","metadata":{"execution":{"iopub.status.busy":"2023-06-03T06:56:52.008297Z","iopub.execute_input":"2023-06-03T06:56:52.008615Z","iopub.status.idle":"2023-06-03T06:57:45.067994Z","shell.execute_reply.started":"2023-06-03T06:56:52.00859Z","shell.execute_reply":"2023-06-03T06:57:45.0668Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"class Config:\n    \n    batch_size= 64\n    n_epochs = 10\n    learning_rate = 0.001\n    \n    \n    \nconfig = Config()","metadata":{"execution":{"iopub.status.busy":"2023-06-03T06:57:45.07066Z","iopub.execute_input":"2023-06-03T06:57:45.071328Z","iopub.status.idle":"2023-06-03T06:57:45.078571Z","shell.execute_reply.started":"2023-06-03T06:57:45.071286Z","shell.execute_reply":"2023-06-03T06:57:45.076058Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"class Acquisition:\n    \n    def get_datframe(self,path):\n        return pd.read_csv(path)\n    \n    def get_json_dataframe(self, json_file):\n        data = []\n        with open(json_file, 'r') as file:\n            for line in file:\n                item = json.loads(line)\n                data.append(item)\n        \n        json_df = pd.DataFrame(data)\n        return json_df\n    \n        \n        \nacq = Acquisition()      ","metadata":{"execution":{"iopub.status.busy":"2023-06-03T06:57:45.082347Z","iopub.execute_input":"2023-06-03T06:57:45.082758Z","iopub.status.idle":"2023-06-03T06:57:45.095815Z","shell.execute_reply.started":"2023-06-03T06:57:45.082722Z","shell.execute_reply":"2023-06-03T06:57:45.094925Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"title=acq.get_datframe(path='/kaggle/input/hubmap-hacking-the-human-vasculature/tile_meta.csv')\ntitle.head()","metadata":{"execution":{"iopub.status.busy":"2023-06-03T06:57:45.098404Z","iopub.execute_input":"2023-06-03T06:57:45.099593Z","iopub.status.idle":"2023-06-03T06:57:45.139697Z","shell.execute_reply.started":"2023-06-03T06:57:45.09956Z","shell.execute_reply":"2023-06-03T06:57:45.13856Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"             id  source_wsi  dataset      i      j\n0  0006ff2aa7cd           2        2  16896  16420\n1  000e79e206b7           6        3  10240  29184\n2  00168d1b7522           2        2  14848  14884\n3  00176a88fdb0           7        3  14848  25088\n4  0033bbc76b6b           1        1  10240  43008","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>source_wsi</th>\n      <th>dataset</th>\n      <th>i</th>\n      <th>j</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0006ff2aa7cd</td>\n      <td>2</td>\n      <td>2</td>\n      <td>16896</td>\n      <td>16420</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000e79e206b7</td>\n      <td>6</td>\n      <td>3</td>\n      <td>10240</td>\n      <td>29184</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00168d1b7522</td>\n      <td>2</td>\n      <td>2</td>\n      <td>14848</td>\n      <td>14884</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00176a88fdb0</td>\n      <td>7</td>\n      <td>3</td>\n      <td>14848</td>\n      <td>25088</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0033bbc76b6b</td>\n      <td>1</td>\n      <td>1</td>\n      <td>10240</td>\n      <td>43008</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"wsi = acq.get_datframe(path='/kaggle/input/hubmap-hacking-the-human-vasculature/wsi_meta.csv')\nwsi.head()","metadata":{"execution":{"iopub.status.busy":"2023-06-03T06:57:45.141043Z","iopub.execute_input":"2023-06-03T06:57:45.141592Z","iopub.status.idle":"2023-06-03T06:57:45.162064Z","shell.execute_reply.started":"2023-06-03T06:57:45.141564Z","shell.execute_reply":"2023-06-03T06:57:45.160966Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"   source_wsi  age sex race  height  weight   bmi\n0           1   58   F    W   160.0    59.0  23.0\n1           2   56   F    W   175.2   139.6  45.5\n2           3   73   F    W   162.3    87.5  33.2\n3           4   53   M    B   166.0    73.0  26.5","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>source_wsi</th>\n      <th>age</th>\n      <th>sex</th>\n      <th>race</th>\n      <th>height</th>\n      <th>weight</th>\n      <th>bmi</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>58</td>\n      <td>F</td>\n      <td>W</td>\n      <td>160.0</td>\n      <td>59.0</td>\n      <td>23.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>56</td>\n      <td>F</td>\n      <td>W</td>\n      <td>175.2</td>\n      <td>139.6</td>\n      <td>45.5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>73</td>\n      <td>F</td>\n      <td>W</td>\n      <td>162.3</td>\n      <td>87.5</td>\n      <td>33.2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>53</td>\n      <td>M</td>\n      <td>B</td>\n      <td>166.0</td>\n      <td>73.0</td>\n      <td>26.5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2023-06-03T06:57:45.164244Z","iopub.execute_input":"2023-06-03T06:57:45.165355Z","iopub.status.idle":"2023-06-03T06:57:45.237544Z","shell.execute_reply.started":"2023-06-03T06:57:45.165317Z","shell.execute_reply":"2023-06-03T06:57:45.236498Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"cuda:0\n","output_type":"stream"}]},{"cell_type":"code","source":"polygons_df = acq.get_json_dataframe('/kaggle/input/hubmap-hacking-the-human-vasculature/polygons.jsonl')\npolygons_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-06-03T06:57:45.240624Z","iopub.execute_input":"2023-06-03T06:57:45.241884Z","iopub.status.idle":"2023-06-03T06:57:49.679803Z","shell.execute_reply.started":"2023-06-03T06:57:45.241692Z","shell.execute_reply":"2023-06-03T06:57:49.678762Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"             id                                        annotations\n0  0006ff2aa7cd  [{'type': 'glomerulus', 'coordinates': [[[167,...\n1  00168d1b7522  [{'type': 'glomerulus', 'coordinates': [[[511,...\n2  0033bbc76b6b  [{'type': 'blood_vessel', 'coordinates': [[[16...\n3  003504460b3a  [{'type': 'blood_vessel', 'coordinates': [[[40...\n4  004daf1cbe75  [{'type': 'blood_vessel', 'coordinates': [[[14...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>annotations</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0006ff2aa7cd</td>\n      <td>[{'type': 'glomerulus', 'coordinates': [[[167,...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>00168d1b7522</td>\n      <td>[{'type': 'glomerulus', 'coordinates': [[[511,...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0033bbc76b6b</td>\n      <td>[{'type': 'blood_vessel', 'coordinates': [[[16...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>003504460b3a</td>\n      <td>[{'type': 'blood_vessel', 'coordinates': [[[40...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>004daf1cbe75</td>\n      <td>[{'type': 'blood_vessel', 'coordinates': [[[14...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"class ImageHuBMAPDataset(Dataset):\n    \n    def __init__(self, image_dir, labels_file, transform=None):\n        \n        with open(labels_file, 'r') as json_file:\n            self.json_labels = [json.loads(line) for line in json_file]\n            \n        self.image_dir = image_dir\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.json_labels)\n\n    def __getitem__(self, idx):\n        image_path = os.path.join(self.image_dir, f\"{self.json_labels[idx]['id']}.tif\")\n        image = Image.open(image_path)\n\n        mask = np.zeros((512, 512), dtype=np.float32)\n\n        for annot in self.json_labels[idx]['annotations']:\n            cords = annot['coordinates']\n            if annot['type'] == \"blood_vessel\":\n                for cd in cords:\n                    rr, cc = np.array([i[1] for i in cd]), np.asarray([i[0] for i in cd])\n                    mask[rr, cc] = 1\n\n        image = torch.tensor(np.array(image), dtype=torch.float32,requires_grad=True).permute(2, 0, 1)  \n        mask = torch.tensor(mask, dtype=torch.float32)\n\n        if self.transform:\n            image = self.transform(image)\n\n        return image, mask","metadata":{"execution":{"iopub.status.busy":"2023-06-03T06:57:49.681127Z","iopub.execute_input":"2023-06-03T06:57:49.683796Z","iopub.status.idle":"2023-06-03T06:57:49.695113Z","shell.execute_reply.started":"2023-06-03T06:57:49.683757Z","shell.execute_reply":"2023-06-03T06:57:49.694004Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"class get_images_labels:\n    def __init__(self, root_path):\n        self.root_path = root_path\n    \n    def set_path(self,filename):\n        return os.path.join(self.root_path,filename)\n    \n    def get_test_path(self,filename):\n        return os.path.join(self.root_path,filename)\n        \n\n        \nimg_lble = get_images_labels(root_path='/kaggle/input/hubmap-hacking-the-human-vasculature')      \n\nimage_folder = img_lble.set_path(filename='train')\nlabels_file = img_lble.set_path(filename='polygons.jsonl')\ntest_image_folder =img_lble.get_test_path(filename='test')","metadata":{"execution":{"iopub.status.busy":"2023-06-03T06:57:49.700078Z","iopub.execute_input":"2023-06-03T06:57:49.700384Z","iopub.status.idle":"2023-06-03T06:57:49.710565Z","shell.execute_reply.started":"2023-06-03T06:57:49.700358Z","shell.execute_reply":"2023-06-03T06:57:49.709441Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def plot_image_mask():\n    plt.figure(figsize=(12, 8))\n    dataset = ImageHuBMAPDataset(image_dir=image_folder, labels_file=labels_file)\n    num_samples = 8\n    num_rows = (num_samples + 3) // 4  \n    num_cols = min(num_samples, 4)\n    for i in range(num_samples):\n        image, mask = dataset[i]\n        image = image.permute(1, 2, 0).detach().numpy() / 255\n        subplot_index = i + 1\n        plt.subplot(num_rows, 2 * num_cols, 2 * subplot_index - 1)\n        plt.imshow(image)\n        plt.axis('off')\n        plt.title('Train_Image')\n\n    mask_subplot_index = (subplot_index - 1) % num_samples + 1\n    plt.subplot(num_rows, 2 * num_cols, 2 * subplot_index)\n    plt.imshow(mask, cmap='gray')\n    plt.axis('off')\n    plt.title('Train_Mask')\n    plt.tight_layout(pad=0.2)\n    plt.show()\n        \n        \ndef plot_losses(history):\n    train_losses = [x.get('Train_loss') for x in history]\n    plt.plot(train_losses)\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend('Training')\n    plt.title('Loss vs. No. of epochs');","metadata":{"execution":{"iopub.status.busy":"2023-06-03T07:12:54.059281Z","iopub.execute_input":"2023-06-03T07:12:54.059728Z","iopub.status.idle":"2023-06-03T07:12:54.071771Z","shell.execute_reply.started":"2023-06-03T07:12:54.059694Z","shell.execute_reply":"2023-06-03T07:12:54.070583Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"plot_image_mask()","metadata":{"execution":{"iopub.status.busy":"2023-06-03T07:13:06.642477Z","iopub.execute_input":"2023-06-03T07:13:06.642861Z","iopub.status.idle":"2023-06-03T07:13:06.719814Z","shell.execute_reply.started":"2023-06-03T07:13:06.642834Z","shell.execute_reply":"2023-06-03T07:13:06.718451Z"},"trusted":true},"execution_count":31,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mplot_image_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[28], line 2\u001b[0m, in \u001b[0;36mplot_image_mask\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_image_mask\u001b[39m():\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m8\u001b[39m))\n\u001b[1;32m      3\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m ImageHuBMAPDataset(image_dir\u001b[38;5;241m=\u001b[39mimage_folder, labels_file\u001b[38;5;241m=\u001b[39mlabels_file)\n\u001b[1;32m      4\u001b[0m     num_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m\n","\u001b[0;31mAttributeError\u001b[0m: 'PlotMask' object has no attribute 'figure'"],"ename":"AttributeError","evalue":"'PlotMask' object has no attribute 'figure'","output_type":"error"}]},{"cell_type":"code","source":"class HuBMAPClassificationNN(torch.nn.Module):\n    def __init__(self):\n        super(HuBMAPClassificationNN, self).__init__()\n        \n        self.network_1 = torch.nn.Sequential(\n            torch.nn.Conv2d(3, 32, kernel_size=3, padding=1),\n            torch.nn.ReLU(),\n            torch.nn.Conv2d(32, 32, kernel_size=3, padding=1),\n            torch.nn.ReLU(),\n            torch.nn.MaxPool2d(kernel_size=2, stride=2)\n        )\n\n        self.network_2 = torch.nn.Sequential(\n            torch.nn.Conv2d(32, 32, kernel_size=3, padding=1),\n            torch.nn.ReLU(),\n            torch.nn.Conv2d(32, 32, kernel_size=3, padding=1),\n            torch.nn.ReLU(),\n            torch.nn.ConvTranspose2d(32, 1, kernel_size=2, stride=2)\n        )\n\n    def forward(self, x):\n        x = self.network_1(x)\n        x = self.network_2(x)\n        x = torch.sigmoid(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2023-06-03T06:57:49.729124Z","iopub.execute_input":"2023-06-03T06:57:49.729582Z","iopub.status.idle":"2023-06-03T06:57:49.742568Z","shell.execute_reply.started":"2023-06-03T06:57:49.729548Z","shell.execute_reply":"2023-06-03T06:57:49.741548Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"model = HuBMAPClassificationNN().to(device)\nprint(model)","metadata":{"execution":{"iopub.status.busy":"2023-06-03T06:57:49.746264Z","iopub.execute_input":"2023-06-03T06:57:49.746539Z","iopub.status.idle":"2023-06-03T06:57:55.503768Z","shell.execute_reply.started":"2023-06-03T06:57:49.746486Z","shell.execute_reply":"2023-06-03T06:57:55.502731Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"HuBMAPClassificationNN(\n  (network_1): Sequential(\n    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): ReLU()\n    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (3): ReLU()\n    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (network_2): Sequential(\n    (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): ReLU()\n    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (3): ReLU()\n    (4): ConvTranspose2d(32, 1, kernel_size=(2, 2), stride=(2, 2))\n  )\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"\"\"\"\nclass Mean_Average_Precision:\n    \n    def apk(self,actual, predicted, k=10):\n          return score / min(len(actual), k)\n \n    def mapk(self,actual, predicted, k=10):\n        return np.mean([apk(a,p,k) for a,p in zip(actual, predicted)])\n    \n    \nmapk = Mean_Average_Precision()\n\"\"\"\n","metadata":{"execution":{"iopub.status.busy":"2023-06-03T06:57:55.505301Z","iopub.execute_input":"2023-06-03T06:57:55.506764Z","iopub.status.idle":"2023-06-03T06:57:55.513815Z","shell.execute_reply.started":"2023-06-03T06:57:55.506728Z","shell.execute_reply":"2023-06-03T06:57:55.512833Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"'\\nclass Mean_Average_Precision:\\n    \\n    def apk(self,actual, predicted, k=10):\\n          return score / min(len(actual), k)\\n \\n    def mapk(self,actual, predicted, k=10):\\n        return np.mean([apk(a,p,k) for a,p in zip(actual, predicted)])\\n    \\n    \\nmapk = Mean_Average_Precision()\\n'"},"metadata":{}}]},{"cell_type":"code","source":"class Trainer:\n    \n    def train_dataloader(self,image_folder,labels_file):\n        dataset = ImageHuBMAPDataset(image_folder,labels_file)\n        return DataLoader(dataset, batch_size=config.batch_size, shuffle=True)\n        \n  \n    def fit(self,epochs, lr, model, train_loader,opt_func):\n        history =[]\n        result = {}\n        \n        criterion = torch.nn.BCELoss() \n        optimizer = opt_func(model.parameters(), lr=lr)\n        \n        for epoch in range(epochs):\n            model.train() \n            running_loss = 0.0\n            accuracy = 0.0\n            start_time = time.time()\n            \n            for images, masks in train_loader:\n                images = images.to(device)\n                masks = masks.to(device)\n                optimizer.zero_grad()\n                outputs = model(images)\n                masks = masks.unsqueeze(1) \n                loss = criterion(outputs, masks)\n                #accuracy = mapk.apk(outputs,masks)\n                loss.backward()\n                optimizer.step()\n                running_loss += loss.item()\n\n            epoch_loss = running_loss / len(train_loader)\n            epoch_time = time.time() - start_time\n            print(f\"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.4f}, Time: {epoch_time:.2f} seconds\")\n            result['Train_loss'] = epoch_loss\n            history.append(result)\n        return history \n        \n    \ntrainer = Trainer()","metadata":{"execution":{"iopub.status.busy":"2023-06-03T06:57:55.515673Z","iopub.execute_input":"2023-06-03T06:57:55.516289Z","iopub.status.idle":"2023-06-03T06:57:55.532904Z","shell.execute_reply.started":"2023-06-03T06:57:55.516258Z","shell.execute_reply":"2023-06-03T06:57:55.531951Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"history=trainer.fit(config.n_epochs, config.learning_rate, model, \n                    trainer.train_dataloader(image_folder,labels_file),\n                    torch.optim.Adam)","metadata":{"execution":{"iopub.status.busy":"2023-06-03T06:57:55.534313Z","iopub.execute_input":"2023-06-03T06:57:55.534966Z","iopub.status.idle":"2023-06-03T07:06:12.52661Z","shell.execute_reply.started":"2023-06-03T06:57:55.534932Z","shell.execute_reply":"2023-06-03T07:06:12.525494Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Epoch 1/10, Loss: 0.6910, Time: 68.26 seconds\nEpoch 2/10, Loss: 0.1454, Time: 47.49 seconds\nEpoch 3/10, Loss: 0.1062, Time: 46.33 seconds\nEpoch 4/10, Loss: 0.0364, Time: 47.33 seconds\nEpoch 5/10, Loss: 0.0319, Time: 47.36 seconds\nEpoch 6/10, Loss: 0.0314, Time: 47.39 seconds\nEpoch 7/10, Loss: 0.0310, Time: 46.96 seconds\nEpoch 8/10, Loss: 0.0308, Time: 47.07 seconds\nEpoch 9/10, Loss: 0.0305, Time: 47.47 seconds\nEpoch 10/10, Loss: 0.0306, Time: 47.41 seconds\n","output_type":"stream"}]},{"cell_type":"code","source":"plot_losses(history)","metadata":{"execution":{"iopub.status.busy":"2023-06-03T07:13:20.961195Z","iopub.execute_input":"2023-06-03T07:13:20.961576Z","iopub.status.idle":"2023-06-03T07:13:21.060915Z","shell.execute_reply.started":"2023-06-03T07:13:20.961545Z","shell.execute_reply":"2023-06-03T07:13:21.058365Z"},"trusted":true},"execution_count":32,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mplot_losses\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[28], line 27\u001b[0m, in \u001b[0;36mplot_losses\u001b[0;34m(history)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_losses\u001b[39m(history):\n\u001b[1;32m     26\u001b[0m     train_losses \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain_loss\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m history]\n\u001b[0;32m---> 27\u001b[0m     \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m(train_losses)\n\u001b[1;32m     28\u001b[0m     plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     29\u001b[0m     plt\u001b[38;5;241m.\u001b[39mylabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","\u001b[0;31mAttributeError\u001b[0m: 'PlotMask' object has no attribute 'plot'"],"ename":"AttributeError","evalue":"'PlotMask' object has no attribute 'plot'","output_type":"error"}]},{"cell_type":"code","source":"class ImageHuBMAPDatasetTest(Dataset):\n    def __init__(self, image_dir, transform=None):\n        self.image_dir = image_dir\n        self.transform = transform\n        self.image_files = sorted(os.listdir(image_dir))\n\n    def __len__(self):\n        return len(self.image_files)\n\n    def __getitem__(self, idx):\n        image_path = os.path.join(self.image_dir, self.image_files[idx])\n        image = Image.open(image_path)\n\n        if self.transform:\n            image = self.transform(image)\n\n        return image","metadata":{"execution":{"iopub.status.busy":"2023-06-03T07:13:25.209324Z","iopub.execute_input":"2023-06-03T07:13:25.209727Z","iopub.status.idle":"2023-06-03T07:13:25.216478Z","shell.execute_reply.started":"2023-06-03T07:13:25.209694Z","shell.execute_reply":"2023-06-03T07:13:25.215576Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"class Test:\n    \n    def encode_binary_mask(mask: np.ndarray) -> t.Text:\n        if mask.dtype != bool:\n            raise ValueError(\n                \"encode_binary_mask expects a binary mask, received dtype == %s\" %\n                mask.dtype)\n\n        mask = np.squeeze(mask)\n        if len(mask.shape) != 2:\n            raise ValueError(\n                \"encode_binary_mask expects a 2d mask, received shape == %s\" %\n                mask.shape)\n\n        mask_to_encode = mask.reshape(mask.shape[0], mask.shape[1], 1)\n        mask_to_encode = mask_to_encode.astype(np.uint8)\n        mask_to_encode = np.asfortranarray(mask_to_encode)\n\n        encoded_mask = coco_mask.encode(mask_to_encode)[0][\"counts\"]\n\n        binary_str = zlib.compress(encoded_mask, zlib.Z_BEST_COMPRESSION)\n        base64_str = base64.b64encode(binary_str)\n        return base64_str\n    \n    \n    def encode_output(outputs,idx):\n        blood_vessel = torch.argmax(outputs, 1) \n        blood_vessel = blood_vessel == 1\n        blood_vessel = blood_vessel * 1\n    \n        blood_vessel = blood_vessel.cpu().numpy()\n        all_encode = {} \n        for i in range(blood_vessel.shape[0]):\n            list_encode = []\n            sliceImage = blood_vessel[i,:,:]\n            binarized = sliceImage > 0\n            coded_len = encode_binary_mask(binarized)\n            list_encode.append(coded_len)\n            all_encode[idx[i]] =list_encode\n        return all_encode\n\n    \n   \n    def get_test_transforms(self):\n        return transforms.Compose([transforms.ToTensor(),transforms.Normalize(\n            mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n        \n    \n    def test_dataloader(self,image_folder):\n        dataset = ImageHuBMAPDatasetTest(test_image_folder,self.get_test_transforms())\n        return DataLoader(dataset, batch_size=config.batch_size)\n    \n    \n\n    def evaluate(self,model):\n        model.eval()\n        predictions = []\n        outputdict ={}\n        outputsoftmax = torch.nn.Softmax2d() \n        with torch.no_grad():\n            for idx,images in tqdm(self.test_dataloader(test_image_folder)):\n                images = images.to(device)\n                outputs = model(images)\n                outputs = outputsoftmax(output)\n                encoded = encode_output(outputs, idx)\n                for key in encoded: \n                    outputdict[key] = \" \".join([f\"0 1.0 {x.decode('utf-8')}\" for x in  encoded[key]])\n        return outputdict\n    \n    \n        \ntest = Test()\n","metadata":{"execution":{"iopub.status.busy":"2023-06-03T07:23:07.787438Z","iopub.execute_input":"2023-06-03T07:23:07.788176Z","iopub.status.idle":"2023-06-03T07:23:07.803048Z","shell.execute_reply.started":"2023-06-03T07:23:07.78814Z","shell.execute_reply":"2023-06-03T07:23:07.802095Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"class Submission:\n    \n    def submit_results(self,OutputDict):\n        submission = pd.DataFrame(OutputDict.items(), columns= [\"id\", \"prediction_string\"]) \n        submission[\"height\"] = 512\n        submission[\"width\"] = 512 \n        submission= submission[[\"id\",\"height\",\"width\",\"prediction_string\"]]\n        submission.to_csv(\"submission.csv\", index= False)\n        \n        \nsubmit = Submission()\n\nOutputDict = test.evaluate(model)\nsubmit.submit_results(OutputDict)","metadata":{"execution":{"iopub.status.busy":"2023-06-03T07:23:10.612949Z","iopub.execute_input":"2023-06-03T07:23:10.613336Z","iopub.status.idle":"2023-06-03T07:23:10.78605Z","shell.execute_reply.started":"2023-06-03T07:23:10.613304Z","shell.execute_reply":"2023-06-03T07:23:10.784252Z"},"trusted":true},"execution_count":36,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"182e847b865a433ea28aec7a3d2a9ede"}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[36], line 13\u001b[0m\n\u001b[1;32m      8\u001b[0m         submission\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubmission.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     11\u001b[0m submit \u001b[38;5;241m=\u001b[39m Submission()\n\u001b[0;32m---> 13\u001b[0m OutputDict \u001b[38;5;241m=\u001b[39m \u001b[43mtest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m submit\u001b[38;5;241m.\u001b[39msubmit_results(OutputDict)\n","Cell \u001b[0;32mIn[35], line 61\u001b[0m, in \u001b[0;36mTest.evaluate\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m     59\u001b[0m outputsoftmax \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mSoftmax2d() \n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx,images \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_dataloader(test_image_folder)):\n\u001b[1;32m     62\u001b[0m         images \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     63\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m model(images)\n","\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"],"ename":"ValueError","evalue":"not enough values to unpack (expected 2, got 1)","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2023-06-03T07:06:13.379304Z","iopub.status.idle":"2023-06-03T07:06:13.380213Z","shell.execute_reply.started":"2023-06-03T07:06:13.379938Z","shell.execute_reply":"2023-06-03T07:06:13.379963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}