{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/averma111/flaml-pytorch-sample?scriptVersionId=132150694\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"%%capture\n!pip install torchvision \"flaml[blendsearch,ray]\"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-06-03T17:40:53.319779Z","iopub.execute_input":"2023-06-03T17:40:53.32023Z","iopub.status.idle":"2023-06-03T17:41:07.494506Z","shell.execute_reply.started":"2023-06-03T17:40:53.320186Z","shell.execute_reply":"2023-06-03T17:41:07.493125Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import random_split\nimport torchvision \nimport torchvision.transforms as transforms","metadata":{"execution":{"iopub.status.busy":"2023-06-03T17:42:19.674381Z","iopub.execute_input":"2023-06-03T17:42:19.674815Z","iopub.status.idle":"2023-06-03T17:42:19.681453Z","shell.execute_reply.started":"2023-06-03T17:42:19.674769Z","shell.execute_reply":"2023-06-03T17:42:19.680055Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"class ClassificationNN(nn.Module):\n    def __init__(self,layer1=120,layer2=84):\n        super(ClassificationNN,self).__init__()\n        self.conv_1 = nn.Conv2d(3, 6, 5)\n        self.pool = nn.MaxPool2d(2,2)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.fc1 = nn.Linear(16 * 5 * 5, l1)\n        self.fc2 = nn.Linear(l1, l2)\n        self.fc3 = nn.Linear(l2, 10)\n\n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = x.view(-1, 16 * 5 * 5)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n    ","metadata":{"execution":{"iopub.status.busy":"2023-06-03T17:47:22.47444Z","iopub.execute_input":"2023-06-03T17:47:22.475409Z","iopub.status.idle":"2023-06-03T17:47:22.484224Z","shell.execute_reply.started":"2023-06-03T17:47:22.475371Z","shell.execute_reply":"2023-06-03T17:47:22.483373Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def load_data(data_dir=\"data\"):\n    transform = transforms.Compose([\n        transforms.ToTensor(),\n        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n    ])\n\n    trainset = torchvision.datasets.CIFAR10(\n        root=data_dir, train=True, download=True, transform=transform)\n\n    testset = torchvision.datasets.CIFAR10(\n        root=data_dir, train=False, download=True, transform=transform)\n\n    return trainset, testset","metadata":{"execution":{"iopub.status.busy":"2023-06-03T17:47:31.246177Z","iopub.execute_input":"2023-06-03T17:47:31.246546Z","iopub.status.idle":"2023-06-03T17:47:31.25383Z","shell.execute_reply.started":"2023-06-03T17:47:31.246518Z","shell.execute_reply":"2023-06-03T17:47:31.252889Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"from ray import tune\n\ndef train_cifar(config, checkpoint_dir=None, data_dir=None):\n    if \"l1\" not in config:\n        logger.warning(config)\n    net = Net(2**config[\"l1\"], 2**config[\"l2\"])\n\n    device = \"cpu\"\n    if torch.cuda.is_available():\n        device = \"cuda:0\"\n        if torch.cuda.device_count() > 1:\n            net = nn.DataParallel(net)\n    net.to(device)\n\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.SGD(net.parameters(), lr=config[\"lr\"], momentum=0.9)\n\n    if checkpoint_dir:\n        checkpoint = os.path.join(checkpoint_dir, \"checkpoint\")\n        model_state, optimizer_state = torch.load(checkpoint)\n        net.load_state_dict(model_state)\n        optimizer.load_state_dict(optimizer_state)\n\n    trainset, testset = load_data(data_dir)\n\n    test_abs = int(len(trainset) * 0.8)\n    train_subset, val_subset = random_split(\n        trainset, [test_abs, len(trainset) - test_abs])\n\n    trainloader = torch.utils.data.DataLoader(\n        train_subset,\n        batch_size=int(2**config[\"batch_size\"]),\n        shuffle=True,\n        num_workers=4)\n    valloader = torch.utils.data.DataLoader(\n        val_subset,\n        batch_size=int(2**config[\"batch_size\"]),\n        shuffle=True,\n        num_workers=4)\n\n    for epoch in range(int(round(config[\"num_epochs\"]))):  # loop over the dataset multiple times\n        running_loss = 0.0\n        epoch_steps = 0\n        for i, data in enumerate(trainloader, 0):\n            # get the inputs; data is a list of [inputs, labels]\n            inputs, labels = data\n            inputs, labels = inputs.to(device), labels.to(device)\n\n            # zero the parameter gradients\n            optimizer.zero_grad()\n\n            # forward + backward + optimize\n            outputs = net(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            # print statistics\n            running_loss += loss.item()\n            epoch_steps += 1\n            if i % 2000 == 1999:  # print every 2000 mini-batches\n                print(\"[%d, %5d] loss: %.3f\" % (epoch + 1, i + 1,\n                                                running_loss / epoch_steps))\n                running_loss = 0.0\n\n        # Validation loss\n        val_loss = 0.0\n        val_steps = 0\n        total = 0\n        correct = 0\n        for i, data in enumerate(valloader, 0):\n            with torch.no_grad():\n                inputs, labels = data\n                inputs, labels = inputs.to(device), labels.to(device)\n\n                outputs = net(inputs)\n                _, predicted = torch.max(outputs.data, 1)\n                total += labels.size(0)\n                correct += (predicted == labels).sum().item()\n\n                loss = criterion(outputs, labels)\n                val_loss += loss.cpu().numpy()\n                val_steps += 1\n\n        with tune.checkpoint_dir(step=epoch) as checkpoint_dir:\n            path = os.path.join(checkpoint_dir, \"checkpoint\")\n            torch.save(\n                (net.state_dict(), optimizer.state_dict()), path)\n\n        tune.report(loss=(val_loss / val_steps), accuracy=correct / total)\n    print(\"Finished Training\")","metadata":{"execution":{"iopub.status.busy":"2023-06-03T17:47:56.425998Z","iopub.execute_input":"2023-06-03T17:47:56.426447Z","iopub.status.idle":"2023-06-03T17:47:57.192587Z","shell.execute_reply.started":"2023-06-03T17:47:56.426413Z","shell.execute_reply":"2023-06-03T17:47:57.191202Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def _test_accuracy(net, device=\"cpu\"):\n    trainset, testset = load_data()\n\n    testloader = torch.utils.data.DataLoader(\n        testset, batch_size=4, shuffle=False, num_workers=2)\n\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for data in testloader:\n            images, labels = data\n            images, labels = images.to(device), labels.to(device)\n            outputs = net(images)\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n    return correct / total","metadata":{"execution":{"iopub.status.busy":"2023-06-03T17:48:06.802587Z","iopub.execute_input":"2023-06-03T17:48:06.803018Z","iopub.status.idle":"2023-06-03T17:48:06.811217Z","shell.execute_reply.started":"2023-06-03T17:48:06.802985Z","shell.execute_reply":"2023-06-03T17:48:06.810119Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport flaml\nimport os\n\ndata_dir = os.path.abspath(\"data\")\nload_data(data_dir)  # Download data for all trials before starting the run","metadata":{"execution":{"iopub.status.busy":"2023-06-03T17:48:13.385311Z","iopub.execute_input":"2023-06-03T17:48:13.385697Z","iopub.status.idle":"2023-06-03T17:48:28.055308Z","shell.execute_reply.started":"2023-06-03T17:48:13.385669Z","shell.execute_reply":"2023-06-03T17:48:28.054137Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /kaggle/working/data/cifar-10-python.tar.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 170498071/170498071 [00:05<00:00, 30750025.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting /kaggle/working/data/cifar-10-python.tar.gz to /kaggle/working/data\nFiles already downloaded and verified\n","output_type":"stream"},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"(Dataset CIFAR10\n     Number of datapoints: 50000\n     Root location: /kaggle/working/data\n     Split: Train\n     StandardTransform\n Transform: Compose(\n                ToTensor()\n                Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n            ),\n Dataset CIFAR10\n     Number of datapoints: 10000\n     Root location: /kaggle/working/data\n     Split: Test\n     StandardTransform\n Transform: Compose(\n                ToTensor()\n                Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n            ))"},"metadata":{}}]},{"cell_type":"code","source":"max_num_epoch = 100\nconfig = {\n    \"l1\": tune.randint(2, 9),   # log transformed with base 2\n    \"l2\": tune.randint(2, 9),   # log transformed with base 2\n    \"lr\": tune.loguniform(1e-4, 1e-1),\n    \"num_epochs\": tune.loguniform(1, max_num_epoch),\n    \"batch_size\": tune.randint(1, 5)    # log transformed with base 2\n}","metadata":{"execution":{"iopub.status.busy":"2023-06-03T17:48:36.546412Z","iopub.execute_input":"2023-06-03T17:48:36.546817Z","iopub.status.idle":"2023-06-03T17:48:36.553959Z","shell.execute_reply.started":"2023-06-03T17:48:36.546788Z","shell.execute_reply":"2023-06-03T17:48:36.552443Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"time_budget_s = 600     # time budget in seconds\ngpus_per_trial = 0.5    # number of gpus for each trial; 0.5 means two training jobs can share one gpu\nnum_samples = 500       # maximal number of trials\nnp.random.seed(7654321)","metadata":{"execution":{"iopub.status.busy":"2023-06-03T17:48:37.69733Z","iopub.execute_input":"2023-06-03T17:48:37.69858Z","iopub.status.idle":"2023-06-03T17:48:37.705297Z","shell.execute_reply.started":"2023-06-03T17:48:37.698525Z","shell.execute_reply":"2023-06-03T17:48:37.703736Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"import time\nstart_time = time.time()\nresult = flaml.tune.run(\n    tune.with_parameters(train_cifar, data_dir=data_dir),\n    config=config,\n    metric=\"loss\",\n    mode=\"min\",\n    low_cost_partial_config={\"num_epochs\": 1},\n    max_resource=max_num_epoch,\n    min_resource=1,\n    scheduler=\"asha\",  # Use asha scheduler to perform early stopping based on intermediate results reported\n    resources_per_trial={\"cpu\": 1, \"gpu\": gpus_per_trial},\n    local_dir='logs/',\n    num_samples=num_samples,\n    time_budget_s=time_budget_s,\n    use_ray=True)","metadata":{"execution":{"iopub.status.busy":"2023-06-03T17:48:50.218618Z","iopub.execute_input":"2023-06-03T17:48:50.219028Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"\u001b[32m[I 2023-06-03 17:48:50,226]\u001b[0m A new study created in memory with name: optuna\u001b[0m\n2023-06-03 17:48:53,981\tINFO services.py:1470 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n","output_type":"stream"},{"name":"stdout","text":"\u001b[2m\u001b[1m\u001b[36m(scheduler +1m0s)\u001b[0m Tip: use `ray status` to view detailed cluster status. To disable these messages, set RAY_SCHEDULER_EVENTS=0.\n\u001b[2m\u001b[1m\u001b[33m(scheduler +1m0s)\u001b[0m Error: No available node types can fulfill resource request {'GPU': 0.5, 'CPU': 1.0}. Add suitable node types to this cluster to resolve this issue.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"== Status ==<br>Current time: 2023-06-03 17:49:02 (running for 00:00:05.12)<br>Memory usage on this node: 2.5/31.4 GiB<br>Using AsyncHyperBand: num_stopped=0\nBracket: Iter 64.000: None | Iter 16.000: None | Iter 4.000: None | Iter 1.000: None<br>Resources requested: 0/4 CPUs, 0/0 GPUs, 0.0/17.83 GiB heap, 0.0/8.92 GiB objects<br>Result logdir: /kaggle/working/logs/train_cifar_2023-06-03_17-48-56<br>Number of trials: 1/500 (1 PENDING)<br><br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"== Status ==<br>Current time: 2023-06-03 17:49:07 (running for 00:00:10.13)<br>Memory usage on this node: 2.5/31.4 GiB<br>Using AsyncHyperBand: num_stopped=0\nBracket: Iter 64.000: None | Iter 16.000: None | Iter 4.000: None | Iter 1.000: None<br>Resources requested: 0/4 CPUs, 0/0 GPUs, 0.0/17.83 GiB heap, 0.0/8.92 GiB objects<br>Result logdir: /kaggle/working/logs/train_cifar_2023-06-03_17-48-56<br>Number of trials: 1/500 (1 PENDING)<br><br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"== Status ==<br>Current time: 2023-06-03 17:49:12 (running for 00:00:15.14)<br>Memory usage on this node: 2.5/31.4 GiB<br>Using AsyncHyperBand: num_stopped=0\nBracket: Iter 64.000: None | Iter 16.000: None | Iter 4.000: None | Iter 1.000: None<br>Resources requested: 0/4 CPUs, 0/0 GPUs, 0.0/17.83 GiB heap, 0.0/8.92 GiB objects<br>Result logdir: /kaggle/working/logs/train_cifar_2023-06-03_17-48-56<br>Number of trials: 1/500 (1 PENDING)<br><br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"== Status ==<br>Current time: 2023-06-03 17:49:17 (running for 00:00:20.14)<br>Memory usage on this node: 2.5/31.4 GiB<br>Using AsyncHyperBand: num_stopped=0\nBracket: Iter 64.000: None | Iter 16.000: None | Iter 4.000: None | Iter 1.000: None<br>Resources requested: 0/4 CPUs, 0/0 GPUs, 0.0/17.83 GiB heap, 0.0/8.92 GiB objects<br>Result logdir: /kaggle/working/logs/train_cifar_2023-06-03_17-48-56<br>Number of trials: 1/500 (1 PENDING)<br><br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"== Status ==<br>Current time: 2023-06-03 17:49:22 (running for 00:00:25.15)<br>Memory usage on this node: 2.5/31.4 GiB<br>Using AsyncHyperBand: num_stopped=0\nBracket: Iter 64.000: None | Iter 16.000: None | Iter 4.000: None | Iter 1.000: None<br>Resources requested: 0/4 CPUs, 0/0 GPUs, 0.0/17.83 GiB heap, 0.0/8.92 GiB objects<br>Result logdir: /kaggle/working/logs/train_cifar_2023-06-03_17-48-56<br>Number of trials: 1/500 (1 PENDING)<br><br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"== Status ==<br>Current time: 2023-06-03 17:49:27 (running for 00:00:30.15)<br>Memory usage on this node: 2.5/31.4 GiB<br>Using AsyncHyperBand: num_stopped=0\nBracket: Iter 64.000: None | Iter 16.000: None | Iter 4.000: None | Iter 1.000: None<br>Resources requested: 0/4 CPUs, 0/0 GPUs, 0.0/17.83 GiB heap, 0.0/8.92 GiB objects<br>Result logdir: /kaggle/working/logs/train_cifar_2023-06-03_17-48-56<br>Number of trials: 1/500 (1 PENDING)<br><br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"== Status ==<br>Current time: 2023-06-03 17:49:32 (running for 00:00:35.16)<br>Memory usage on this node: 2.5/31.4 GiB<br>Using AsyncHyperBand: num_stopped=0\nBracket: Iter 64.000: None | Iter 16.000: None | Iter 4.000: None | Iter 1.000: None<br>Resources requested: 0/4 CPUs, 0/0 GPUs, 0.0/17.83 GiB heap, 0.0/8.92 GiB objects<br>Result logdir: /kaggle/working/logs/train_cifar_2023-06-03_17-48-56<br>Number of trials: 1/500 (1 PENDING)<br><br>"},"metadata":{}},{"name":"stdout","text":"\u001b[2m\u001b[1m\u001b[33m(scheduler +1m35s)\u001b[0m Error: No available node types can fulfill resource request {'GPU': 0.5, 'CPU': 1.0}. Add suitable node types to this cluster to resolve this issue.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"== Status ==<br>Current time: 2023-06-03 17:49:37 (running for 00:00:40.16)<br>Memory usage on this node: 2.5/31.4 GiB<br>Using AsyncHyperBand: num_stopped=0\nBracket: Iter 64.000: None | Iter 16.000: None | Iter 4.000: None | Iter 1.000: None<br>Resources requested: 0/4 CPUs, 0/0 GPUs, 0.0/17.83 GiB heap, 0.0/8.92 GiB objects<br>Result logdir: /kaggle/working/logs/train_cifar_2023-06-03_17-48-56<br>Number of trials: 1/500 (1 PENDING)<br><br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"== Status ==<br>Current time: 2023-06-03 17:49:42 (running for 00:00:45.17)<br>Memory usage on this node: 2.5/31.4 GiB<br>Using AsyncHyperBand: num_stopped=0\nBracket: Iter 64.000: None | Iter 16.000: None | Iter 4.000: None | Iter 1.000: None<br>Resources requested: 0/4 CPUs, 0/0 GPUs, 0.0/17.83 GiB heap, 0.0/8.92 GiB objects<br>Result logdir: /kaggle/working/logs/train_cifar_2023-06-03_17-48-56<br>Number of trials: 1/500 (1 PENDING)<br><br>"},"metadata":{}}]},{"cell_type":"code","source":"print(f\"#trials={len(result.trials)}\")\nprint(f\"time={time.time()-start_time}\")\nbest_trial = result.get_best_trial(\"loss\", \"min\", \"all\")\nprint(\"Best trial config: {}\".format(best_trial.config))\nprint(\"Best trial final validation loss: {}\".format(\n    best_trial.metric_analysis[\"loss\"][\"min\"]))\nprint(\"Best trial final validation accuracy: {}\".format(\n    best_trial.metric_analysis[\"accuracy\"][\"max\"]))\n\nbest_trained_model = Net(2**best_trial.config[\"l1\"],\n                         2**best_trial.config[\"l2\"])\ndevice = \"cpu\"\nif torch.cuda.is_available():\n    device = \"cuda:0\"\n    if gpus_per_trial > 1:\n        best_trained_model = nn.DataParallel(best_trained_model)\nbest_trained_model.to(device)\n\ncheckpoint_value = getattr(best_trial.checkpoint, \"dir_or_data\", None) or best_trial.checkpoint.value\ncheckpoint_path = os.path.join(checkpoint_value, \"checkpoint\")\n\nmodel_state, optimizer_state = torch.load(checkpoint_path)\nbest_trained_model.load_state_dict(model_state)\n\ntest_acc = _test_accuracy(best_trained_model, device)\nprint(\"Best trial test set accuracy: {}\".format(test_acc))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}